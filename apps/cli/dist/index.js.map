{"version":3,"sources":["../src/lib/config.ts","../src/lib/prompts.ts","../src/enhancements/safety/transaction-wrapper.ts","../src/enhancements/safety/drop-table-safeguard.ts","../src/enhancements/safety/foreign-key-constraint.ts","../src/enhancements/safety/nullable-column.ts","../src/enhancements/safety/index-creation.ts","../src/enhancements/safety/data-type-change.ts","../src/enhancements/safety/column-renaming.ts","../src/enhancements/safety/cascade-delete.ts","../src/enhancements/safety/unique-constraint.ts","../src/enhancements/safety/check-constraint.ts","../src/enhancements/safety/backup-recommendation.ts","../src/enhancements/safety/migration-order.ts","../src/enhancements/safety/index.ts","../src/enhancements/speed/remaining-stubs.ts","../src/enhancements/speed/index.ts","../src/core/enhancement-engine.ts","../src/core/migration-utils.ts","../src/commands/enhance.ts","../src/commands/validate.ts","../src/commands/plan.ts","../src/commands/rollback.ts","../src/core/types/common.ts","../src/core/types/orm.ts","../src/core/types/database.ts","../src/core/types/migration.ts","../src/core/types/config.ts","../src/core/types/index.ts","../src/core/utils/file-utils.ts","../src/core/utils/async-utils.ts","../src/core/utils/validation.ts","../src/core/utils/config.ts","../src/core/utils/index.ts","../src/core/index.ts","../src/analyzer/orm-detectors/base-detector.ts","../src/analyzer/orm-detectors/prisma-detector.ts","../src/analyzer/orm-detectors/drizzle-detector.ts","../src/analyzer/orm-detectors/typeorm-detector.ts","../src/analyzer/orm-detectors/index.ts","../src/analyzer/database/connection.ts","../src/analyzer/database/analysis.ts","../src/analyzer/database/adapters.ts","../src/analyzer/database/index.ts","../src/analyzer/index.ts","../src/commands/init.ts","../src/commands/config.ts","../src/commands/status.ts","../src/index.ts"],"sourcesContent":["export interface GlobalOptions {\n  debug?: boolean\n  config?: string\n  dryRun?: boolean\n}\n\nimport fsExtra from 'fs-extra'\nimport { resolve, dirname } from 'node:path'\n\n/**\n * Locate and parse flow.config.json.\n * If --config is supplied use that path, otherwise walk parent directories.\n */\nexport async function getFlowConfig(global: GlobalOptions, projectPath?: string) {\n  const configPath = await findConfigFile(projectPath || process.cwd(), global.config)\n  return JSON.parse(await fsExtra.readFile(configPath, 'utf8'))\n}\n\nasync function findConfigFile(startDir: string, explicit?: string): Promise<string> {\n  if (explicit) {\n    const p = resolve(explicit)\n    if (await fsExtra.pathExists(p)) return p\n    throw new Error(`Config file not found at ${p}`)\n  }\n\n  let dir = startDir\n  while (true) {\n    const candidate = resolve(dir, 'flow.config.json')\n    if (await fsExtra.pathExists(candidate)) return candidate\n    const parent = dirname(dir)\n    if (parent === dir) break\n    dir = parent\n  }\n  throw new Error('flow.config.json not found')\n} ","/**\n * Reusable prompt components for beautiful CLI interactions\n */\n\nimport { confirm, select, multiselect, text, spinner, log } from '@clack/prompts'\nimport colors from 'picocolors'\n\nexport interface EnhancementOption {\n  value: string\n  label: string\n  hint?: string\n  danger?: boolean\n}\n\n/**\n * Confirmation prompt with enhanced styling\n */\nexport async function confirmAction(\n  message: string,\n  options: any = {}\n): Promise<boolean> {\n  return await confirm({\n    message: colors.cyan(message),\n    ...options\n  }) as boolean\n}\n\n/**\n * Selection prompt for single choice\n */\nexport async function selectOption<T extends string>(\n  message: string,\n  options: Array<{ value: T; label: string; hint?: string }>,\n  selectOptions: any = {}\n): Promise<T> {\n  return await select({\n    message: colors.cyan(message),\n    options: options.map(opt => ({\n      value: opt.value,\n      label: opt.label,\n      hint: opt.hint ? colors.dim(opt.hint) : undefined\n    })),\n    ...selectOptions\n  }) as T\n}\n\n/**\n * Multi-selection prompt for multiple choices\n */\nexport async function selectMultiple<T extends string>(\n  message: string,\n  options: Array<{ value: T; label: string; hint?: string; required?: boolean }>,\n  multiselectOptions: any = {}\n): Promise<T[]> {\n  return await multiselect({\n    message: colors.cyan(message),\n    options: options.map(opt => ({\n      value: opt.value,\n      label: opt.label,\n      hint: opt.hint ? colors.dim(opt.hint) : undefined,\n      required: opt.required\n    })),\n    ...multiselectOptions\n  }) as T[]\n}\n\n/**\n * Text input prompt with validation\n */\nexport async function textInput(\n  message: string,\n  options: any = {}\n): Promise<string> {\n  return await text({\n    message: colors.cyan(message),\n    ...options\n  }) as string\n}\n\n/**\n * Enhancement selection flow\n */\nexport async function selectEnhancements(\n  availableEnhancements: EnhancementOption[]\n): Promise<string[]> {\n  log.info(colors.blue('üîç Available migration enhancements:'))\n  \n  const options = availableEnhancements.map(enhancement => ({\n    value: enhancement.value,\n    label: enhancement.danger \n      ? colors.red(`‚ö†Ô∏è  ${enhancement.label}`)\n      : colors.green(`‚úÖ ${enhancement.label}`),\n    hint: enhancement.hint,\n    required: false\n  }))\n\n  return await selectMultiple(\n    'Select enhancements to apply:',\n    options,\n    {\n      required: false\n    }\n  )\n}\n\n/**\n * Database connection confirmation\n */\nexport async function confirmDatabaseConnection(\n  connectionString: string\n): Promise<boolean> {\n  log.info(colors.yellow('üîå Database connection details:'))\n  log.info(colors.dim(`   ${connectionString}`))\n  \n  return await confirmAction(\n    'Proceed with this database connection?',\n    {\n      initialValue: false\n    }\n  )\n}\n\n/**\n * Migration risk confirmation\n */\nexport async function confirmHighRiskOperation(\n  operationName: string,\n  risks: string[]\n): Promise<boolean> {\n  log.warn(colors.red(`‚ö†Ô∏è  HIGH RISK OPERATION: ${operationName}`))\n  \n  risks.forEach(risk => {\n    log.warn(colors.red(`   ‚Ä¢ ${risk}`))\n  })\n  \n  return await confirmAction(\n    colors.red('Do you understand the risks and want to proceed?'),\n    {\n      initialValue: false\n    }\n  )\n}\n\n/**\n * Enhanced progress spinner with custom styling and animations\n */\nexport function createSpinner(message: string) {\n  const s = spinner()\n  \n  return {\n    start: (msg?: string) => {\n      s.start(colors.blue(`üåä ${msg || message}`))\n      return {\n        update: (newMessage: string) => s.message(colors.blue(`üåä ${newMessage}`)),\n        succeed: (successMessage?: string) => s.stop(colors.green(`‚úÖ ${successMessage || 'Complete'}`)),\n        fail: (errorMessage?: string) => s.stop(colors.red(`‚ùå ${errorMessage || 'Failed'}`)),\n        stop: (finalMessage?: string) => s.stop(finalMessage ? colors.gray(finalMessage) : ''),\n        message: (msg: string) => s.message(colors.blue(`üåä ${msg}`))\n      }\n    }\n  }\n}\n\n/**\n * Create a simple spinner with fluent API\n */\nexport function createFlowSpinner() {\n  const s = spinner()\n  let isStarted = false\n  \n  return {\n    start: (message: string) => {\n      if (!isStarted) {\n        s.start(colors.blue(`üåä ${message}`))\n        isStarted = true\n      }\n      return {\n        update: (msg: string) => s.message(colors.blue(`üåä ${msg}`)),\n        succeed: (msg?: string) => {\n          s.stop(colors.green(`‚úÖ ${msg || 'Complete'}`))\n          isStarted = false\n        },\n        fail: (msg?: string) => {\n          s.stop(colors.red(`‚ùå ${msg || 'Failed'}`))\n          isStarted = false\n        },\n        stop: (msg?: string) => {\n          s.stop(msg ? colors.gray(msg) : '')\n          isStarted = false\n        }\n      }\n    }\n  }\n}\n\n/**\n * Display a success message with enhanced styling\n */\nexport function displaySuccess(message: string, details?: string[]): void {\n  log.success(colors.green(`‚úÖ ${message}`))\n  if (details && details.length > 0) {\n    details.forEach(detail => {\n      log.info(colors.dim(`   ‚Ä¢ ${detail}`))\n    })\n  }\n}\n\n/**\n * Display an error message with enhanced styling\n */\nexport function displayError(message: string, details?: string[]): void {\n  log.error(colors.red(`‚ùå ${message}`))\n  if (details && details.length > 0) {\n    details.forEach(detail => {\n      log.info(colors.dim(`   ‚Ä¢ ${detail}`))\n    })\n  }\n}\n\n/**\n * Display a warning message with enhanced styling\n */\nexport function displayWarning(message: string, details?: string[]): void {\n  log.warn(colors.yellow(`‚ö†Ô∏è  ${message}`))\n  if (details && details.length > 0) {\n    details.forEach(detail => {\n      log.info(colors.dim(`   ‚Ä¢ ${detail}`))\n    })\n  }\n}\n\n/**\n * Display an info message with enhanced styling\n */\nexport function displayInfo(message: string, details?: string[]): void {\n  log.info(colors.blue(`‚ÑπÔ∏è  ${message}`))\n  if (details && details.length > 0) {\n    details.forEach(detail => {\n      log.info(colors.dim(`   ‚Ä¢ ${detail}`))\n    })\n  }\n} ","/**\n * Transaction Wrapper Safety Enhancement\n * Wraps unsafe operations in database transactions for better safety\n */\n\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-transaction-wrapper',\n  name: 'Transaction Wrapper',\n  description: 'Wraps migration operations in database transactions to ensure atomicity and enable rollback on failure',\n  category: 'safety',\n  priority: 9,\n  requiresConfirmation: false,\n  tags: ['transaction', 'atomicity', 'rollback', 'critical']\n};\n\nclass TransactionWrapperDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    // Check if migration content doesn't already have explicit transaction handling\n    const content = migration.up.toLowerCase();\n    \n    // Skip if already has transaction commands\n    if (content.includes('begin') || content.includes('start transaction') || content.includes('commit')) {\n      return false;\n    }\n    \n    // Apply to migrations with potentially risky operations\n    const riskyOperations = [\n      'drop table',\n      'drop column',\n      'alter table',\n      'delete from',\n      'update ',\n      'create index',\n      'drop index'\n    ];\n    \n    return riskyOperations.some(op => content.includes(op));\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    const applicable = await this.detect(migration);\n    \n    if (!applicable) {\n      return {\n        applicable: false,\n        confidence: 0,\n        issues: [],\n        impact: {\n          riskReduction: 0,\n          performanceImprovement: 0,\n          complexityAdded: 0,\n          description: 'Transaction wrapper not applicable - migration already has transaction handling or no risky operations'\n        }\n      };\n    }\n\n    const issues = [];\n    const content = migration.up.toLowerCase();\n    \n    if (content.includes('drop table')) {\n      issues.push({\n        severity: 'high' as const,\n        description: 'DROP TABLE operation without transaction protection',\n        location: 'DROP TABLE statement',\n        line: this.findLineNumber(migration.up, /drop\\s+table/i),\n        recommendation: 'Wrap in transaction to enable rollback if migration fails'\n      });\n    }\n    \n    if (content.includes('alter table')) {\n      issues.push({\n        severity: 'medium' as const,\n        description: 'ALTER TABLE operation without transaction protection',\n        location: 'ALTER TABLE statement',\n        line: this.findLineNumber(migration.up, /alter\\s+table/i),\n        recommendation: 'Wrap in transaction to ensure consistency'\n      });\n    }\n\n    return {\n      applicable: true,\n      confidence: 0.9,\n      issues,\n      impact: {\n        riskReduction: 0.8,\n        performanceImprovement: 0,\n        complexityAdded: 0.1,\n        description: 'Significantly reduces risk by enabling rollback on failure with minimal complexity added'\n      }\n    };\n  }\n\n  private findLineNumber(content: string, pattern: RegExp): number {\n    const lines = content.split('\\n');\n    for (let i = 0; i < lines.length; i++) {\n      if (pattern.test(lines[i])) {\n        return i + 1;\n      }\n    }\n    return 1;\n  }\n}\n\nclass TransactionWrapperApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    try {\n      // Add transaction wrapper around the migration content\n      const modifiedContent = `-- Flow Enhancement: Transaction Wrapper\n-- Wraps migration in transaction for safety and rollback capability\nBEGIN;\n\n${content.trim()}\n\nCOMMIT;\n\n-- If any statement fails, the entire transaction will be rolled back automatically`;\n\n      return {\n        enhancement,\n        applied: true,\n        modifiedContent,\n        warnings: [],\n        changes: [\n          {\n            type: 'WRAPPED',\n            original: content.trim(),\n            modified: modifiedContent,\n            line: 1,\n            reason: 'Wrapped entire migration in transaction for safety'\n          }\n        ]\n      };\n    } catch (error) {\n      return {\n        enhancement,\n        applied: false,\n        modifiedContent: content,\n        warnings: [`Failed to apply transaction wrapper: ${error instanceof Error ? error.message : 'Unknown error'}`],\n        changes: []\n      };\n    }\n  }\n}\n\nexport const transactionWrapperModule: EnhancementModule = {\n  enhancement,\n  detector: new TransactionWrapperDetector(),\n  applicator: new TransactionWrapperApplicator()\n}; ","/**\n * Drop Table Safeguard Safety Enhancement\n * Adds safeguards and warnings for DROP TABLE operations\n */\n\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-drop-table-safeguard',\n  name: 'Drop Table Safeguard',\n  description: 'Adds explicit confirmations and backup recommendations for DROP TABLE operations to prevent accidental data loss',\n  category: 'safety',\n  priority: 10,\n  requiresConfirmation: true,\n  tags: ['drop-table', 'data-protection', 'backup', 'critical']\n};\n\nclass DropTableSafeguardDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    const content = migration.up.toLowerCase();\n    return content.includes('drop table');\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    const applicable = await this.detect(migration);\n    \n    if (!applicable) {\n      return {\n        applicable: false,\n        confidence: 0,\n        issues: [],\n        impact: {\n          riskReduction: 0,\n          performanceImprovement: 0,\n          complexityAdded: 0,\n          description: 'No DROP TABLE operations found'\n        }\n      };\n    }\n\n    const issues: import('../../core/types.js').EnhancementIssue[] = [];\n    const lines = migration.up.split('\\n');\n    \n    lines.forEach((line, index) => {\n      if (/drop\\s+table/i.test(line)) {\n        const tableName = this.extractTableName(line);\n        issues.push({\n          severity: 'critical' as const,\n          description: `DROP TABLE operation on table \"${tableName}\" - IRREVERSIBLE DATA LOSS`,\n          location: line.trim(),\n          line: index + 1,\n          recommendation: 'Ensure you have a backup and consider using a different approach if possible'\n        });\n      }\n    });\n\n    return {\n      applicable: true,\n      confidence: 1.0,\n      issues,\n      impact: {\n        riskReduction: 0.9,\n        performanceImprovement: 0,\n        complexityAdded: 0.2,\n        description: 'Adds explicit warnings and safeguards to prevent accidental data loss from DROP TABLE operations'\n      }\n    };\n  }\n\n  private extractTableName(line: string): string {\n    const match = line.match(/drop\\s+table\\s+(?:if\\s+exists\\s+)?`?([^`\\s;]+)`?/i);\n    return match ? match[1] : 'unknown';\n  }\n}\n\nclass DropTableSafeguardApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    try {\n      const lines = content.split('\\n');\n      const modifiedLines: string[] = [];\n      const changes: import('../../core/types.js').EnhancementChange[] = [];\n\n      for (let i = 0; i < lines.length; i++) {\n        const line = lines[i];\n        \n        if (/drop\\s+table/i.test(line)) {\n          const tableName = this.extractTableName(line);\n          \n          // Add safeguard comments before the DROP TABLE\n          const safeguardComment = `-- ‚ö†Ô∏è  CRITICAL WARNING: DROP TABLE OPERATION\n-- Table: ${tableName}\n-- This operation will PERMANENTLY DELETE ALL DATA in this table\n-- Ensure you have a backup before proceeding\n-- Consider using 'DROP TABLE IF EXISTS' for safer execution\n-- Original command: ${line.trim()}`;\n\n          modifiedLines.push(safeguardComment);\n          \n          // Modify the DROP TABLE to use IF EXISTS for safety\n          const saferDropCommand = line.replace(/drop\\s+table\\s+/i, 'DROP TABLE IF EXISTS ');\n          modifiedLines.push(saferDropCommand);\n          \n          changes.push({\n            type: 'MODIFIED' as const,\n            original: line,\n            modified: safeguardComment + '\\n' + saferDropCommand,\n            line: i + 1,\n            reason: 'Added safety warnings and IF EXISTS clause to DROP TABLE operation'\n          });\n        } else {\n          modifiedLines.push(line);\n        }\n      }\n\n      return {\n        enhancement,\n        applied: true,\n        modifiedContent: modifiedLines.join('\\n'),\n        warnings: [\n          'DROP TABLE operations detected - please verify you have backups',\n          'Added IF EXISTS clauses to prevent errors if tables don\\'t exist'\n        ],\n        changes\n      };\n    } catch (error) {\n      return {\n        enhancement,\n        applied: false,\n        modifiedContent: content,\n        warnings: [`Failed to apply drop table safeguard: ${error instanceof Error ? error.message : 'Unknown error'}`],\n        changes: []\n      };\n    }\n  }\n\n  private extractTableName(line: string): string {\n    const match = line.match(/drop\\s+table\\s+(?:if\\s+exists\\s+)?`?([^`\\s;]+)`?/i);\n    return match ? match[1] : 'unknown';\n  }\n}\n\nexport const dropTableSafeguardModule: EnhancementModule = {\n  enhancement,\n  detector: new DropTableSafeguardDetector(),\n  applicator: new DropTableSafeguardApplicator()\n}; ","/**\n * Foreign Key Constraint Safety Enhancement\n * Stub implementation - adds foreign key constraint validation\n */\n\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-foreign-key-constraint',\n  name: 'Foreign Key Constraint Validation',\n  description: 'Validates foreign key constraints and adds proper error handling',\n  category: 'safety',\n  priority: 7,\n  requiresConfirmation: false,\n  tags: ['foreign-key', 'constraint', 'validation']\n};\n\nclass ForeignKeyConstraintDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    return migration.up.toLowerCase().includes('foreign key');\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    return {\n      applicable: await this.detect(migration),\n      confidence: 0.7,\n      issues: [],\n      impact: {\n        riskReduction: 0.5,\n        performanceImprovement: 0,\n        complexityAdded: 0.2,\n        description: 'Validates foreign key constraints'\n      }\n    };\n  }\n}\n\nclass ForeignKeyConstraintApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    return {\n      enhancement,\n      applied: false,\n      modifiedContent: content,\n      warnings: ['Foreign key constraint enhancement not yet implemented'],\n      changes: []\n    };\n  }\n}\n\nexport const foreignKeyConstraintModule: EnhancementModule = {\n  enhancement,\n  detector: new ForeignKeyConstraintDetector(),\n  applicator: new ForeignKeyConstraintApplicator()\n}; ","/**\n * Nullable Column Safety Enhancement\n * Detects nullable column operations and suggests safer migration patterns\n */\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-nullable-column',\n  name: 'Nullable Column Safety',\n  description: 'Ensures safe handling of nullable column operations by adding proper NULL checks and default values',\n  category: 'safety',\n  priority: 6,\n  requiresConfirmation: true,\n  tags: ['nullable', 'column', 'safety', 'null-checks']\n};\n\nclass NullableColumnDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    const content = migration.up.toLowerCase();\n    return (\n      content.includes('alter column') && content.includes('null') ||\n      content.includes('not null') ||\n      content.includes('set null') ||\n      content.includes('drop not null')\n    );\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    const applicable = await this.detect(migration);\n    if (!applicable) {\n      return { applicable: false, confidence: 0, issues: [], impact: { riskReduction: 0, performanceImprovement: 0, complexityAdded: 0, description: 'No nullable column operations detected' } };\n    }\n\n    const issues = [];\n    const content = migration.up.toLowerCase();\n    const lines = migration.up.split('\\n');\n\n    if (content.includes('not null') && !content.includes('default')) {\n      issues.push({\n        severity: 'high' as const,\n        description: 'Adding NOT NULL constraint without a default value can fail if table has existing NULL values',\n        location: 'ALTER COLUMN ... NOT NULL',\n        line: lines.findIndex(line => line.toLowerCase().includes('not null')) + 1,\n        recommendation: 'Add a default value or update existing NULL values before applying constraint'\n      });\n    }\n\n    if (content.includes('drop not null')) {\n      issues.push({\n        severity: 'medium' as const,\n        description: 'Removing NOT NULL constraint without data validation can lead to unexpected NULL values',\n        location: 'DROP NOT NULL',\n        line: lines.findIndex(line => line.toLowerCase().includes('drop not null')) + 1,\n        recommendation: 'Consider if allowing NULL values is intentional and add application-level validation'\n      });\n    }\n\n    return {\n      applicable: true,\n      confidence: 0.8,\n      issues,\n      impact: {\n        riskReduction: 0.7,\n        performanceImprovement: 0,\n        complexityAdded: 0.3,\n        description: 'Adds proper NULL handling and validation to column modifications'\n      }\n    };\n  }\n}\n\nclass NullableColumnApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    let modifiedContent = content;\n    const changes = [];\n\n    // Add safety checks for NOT NULL constraints\n    if (content.toLowerCase().includes('not null') && !content.toLowerCase().includes('default')) {\n      const lines = content.split('\\n');\n      let modified = false;\n\n      for (let i = 0; i < lines.length; i++) {\n        const line = lines[i];\n        if (line.toLowerCase().includes('alter column') && line.toLowerCase().includes('not null')) {\n          // Add a comment suggesting to check for existing NULL values\n          const safetyComment = '  -- Safety check: Ensure no NULL values exist before adding NOT NULL constraint';\n          const updateComment = '  -- UPDATE table_name SET column_name = \\'default_value\\' WHERE column_name IS NULL;';\n          lines.splice(i, 0, safetyComment);\n          lines.splice(i + 1, 0, updateComment);\n          changes.push({\n            type: 'ADDED' as const,\n            original: line,\n            modified: `${safetyComment}\\n${updateComment}\\n${line}`,\n            line: i + 1,\n            reason: 'Added safety check comments for NOT NULL constraint'\n          });\n          i += 2; // Skip the inserted lines\n          modified = true;\n        }\n      }\n\n      if (modified) {\n        modifiedContent = lines.join('\\n');\n      }\n    }\n\n    // Add validation for DROP NOT NULL\n    if (content.toLowerCase().includes('drop not null')) {\n      const lines = content.split('\\n');\n      let modified = false;\n\n      for (let i = 0; i < lines.length; i++) {\n        const line = lines[i];\n        if (line.toLowerCase().includes('drop not null')) {\n          const intentionComment = '  -- Safety check: Consider if allowing NULL values is intentional';\n          const validationComment = '  -- Add application-level validation if needed';\n          lines.splice(i, 0, intentionComment);\n          lines.splice(i + 1, 0, validationComment);\n          changes.push({\n            type: 'ADDED' as const,\n            original: line,\n            modified: `${intentionComment}\\n${validationComment}\\n${line}`,\n            line: i + 1,\n            reason: 'Added safety warnings for DROP NOT NULL constraint'\n          });\n          i += 2;\n          modified = true;\n        }\n      }\n\n      if (modified) {\n        modifiedContent = lines.join('\\n');\n      }\n    }\n\n    return {\n      enhancement,\n      applied: changes.length > 0,\n      modifiedContent,\n      warnings: changes.length === 0 ? ['No nullable column safety improvements were applied'] : [],\n      changes\n    };\n  }\n}\n\nexport const nullableColumnModule: EnhancementModule = {\n  enhancement,\n  detector: new NullableColumnDetector(),\n  applicator: new NullableColumnApplicator()\n}; ","import { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\nconst enhancement: Enhancement = { id: 'safety-index-creation', name: 'Index Creation Safety', description: 'Stub', category: 'safety', priority: 5, requiresConfirmation: false, tags: ['stub'] };\nclass StubDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> { return false; }\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> { return { applicable: false, confidence: 0, issues: [], impact: { riskReduction: 0, performanceImprovement: 0, complexityAdded: 0, description: 'Stub' } }; }\n}\nclass StubApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> { return { enhancement, applied: false, modifiedContent: content, warnings: ['Not implemented'], changes: [] }; }\n}\nexport const indexCreationModule: EnhancementModule = { enhancement, detector: new StubDetector(), applicator: new StubApplicator() }; ","/**\n * Data Type Change Safety Enhancement\n * Detects risky data type conversions and suggests safer approaches\n */\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-data-type-change',\n  name: 'Data Type Change Safety',\n  description: 'Detects risky data type conversions and suggests safer migration patterns',\n  category: 'safety',\n  priority: 8,\n  requiresConfirmation: true,\n  tags: ['data-type', 'conversion', 'safety', 'column-alteration']\n};\n\nclass DataTypeChangeDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    const content = migration.up.toLowerCase();\n    return (\n      content.includes('alter column') && content.includes('type') ||\n      content.includes('alter table') && content.includes('alter column') ||\n      content.includes('change column')\n    );\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    const applicable = await this.detect(migration);\n    if (!applicable) {\n      return { \n        applicable: false, \n        confidence: 0, \n        issues: [], \n        impact: { riskReduction: 0, performanceImprovement: 0, complexityAdded: 0, description: 'No data type changes detected' } \n      };\n    }\n\n    const issues = [];\n    const content = migration.up.toLowerCase();\n    const lines = migration.up.split('\\n');\n\n    // Check for potentially risky data type conversions\n    const riskyConversions = [\n      { from: 'varchar', to: 'int', risk: 'high' },\n      { from: 'text', to: 'varchar', risk: 'medium' },\n      { from: 'decimal', to: 'int', risk: 'high' },\n      { from: 'timestamp', to: 'date', risk: 'medium' }\n    ];\n\n    for (const conversion of riskyConversions) {\n      if (content.includes(conversion.to)) {\n        issues.push({\n          severity: conversion.risk as 'high' | 'medium',\n          description: `Converting to ${conversion.to} may cause data loss or conversion errors`,\n          location: 'ALTER COLUMN ... TYPE',\n          line: lines.findIndex(line => line.toLowerCase().includes('type')) + 1 || 1,\n          recommendation: `Verify data compatibility before converting to ${conversion.to} type`\n        });\n      }\n    }\n\n    return {\n      applicable: true,\n      confidence: 0.8,\n      issues,\n      impact: {\n        riskReduction: 0.7,\n        performanceImprovement: 0,\n        complexityAdded: 0.4,\n        description: 'Adds safety checks and warnings for risky data type conversions'\n      }\n    };\n  }\n}\n\nclass DataTypeChangeApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    let modifiedContent = content;\n    const changes = [];\n\n    // Add safety comments for data type changes\n    if (content.toLowerCase().includes('alter column') && content.toLowerCase().includes('type')) {\n      const lines = content.split('\\n');\n      let modified = false;\n\n      for (let i = 0; i < lines.length; i++) {\n        const line = lines[i];\n        if (line.toLowerCase().includes('alter column') && line.toLowerCase().includes('type')) {\n          lines.splice(i, 0, '  -- Safety check: Verify data compatibility before type conversion');\n          lines.splice(i + 1, 0, '  -- Consider backing up data or using a staged migration approach');\n          changes.push('Added data type conversion safety comments');\n          i += 2;\n          modified = true;\n        }\n      }\n\n      if (modified) {\n        modifiedContent = lines.join('\\n');\n      }\n    }\n\n    return {\n      enhancement,\n      applied: changes.length > 0,\n      modifiedContent,\n      warnings: changes.length === 0 ? ['No data type change safety improvements were applied'] : [],\n      changes: changes.map(change => ({\n        type: 'ADDED' as const,\n        original: '',\n        modified: change,\n        line: 1,\n        reason: change\n      }))\n    };\n  }\n}\n\nexport const dataTypeChangeModule: EnhancementModule = {\n  enhancement,\n  detector: new DataTypeChangeDetector(),\n  applicator: new DataTypeChangeApplicator()\n}; ","/**\n * Column Renaming Safety Enhancement\n * Warns about risks and compatibility issues when renaming columns\n */\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-column-renaming',\n  name: 'Column Renaming Safety',\n  description: 'Warns about application compatibility risks when renaming database columns',\n  category: 'safety',\n  priority: 7,\n  requiresConfirmation: true,\n  tags: ['column', 'rename', 'compatibility', 'breaking-change']\n};\n\nclass ColumnRenamingDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    const content = migration.up.toLowerCase();\n    return content.includes('rename column') || \n           content.includes('alter column') && content.includes('rename to');\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    const applicable = await this.detect(migration);\n    if (!applicable) {\n      return { \n        applicable: false, \n        confidence: 0, \n        issues: [], \n        impact: { riskReduction: 0, performanceImprovement: 0, complexityAdded: 0, description: 'No column renaming detected' } \n      };\n    }\n\n    const issues = [];\n    const content = migration.up.toLowerCase();\n    const lines = migration.up.split('\\n');\n\n    if (content.includes('rename column')) {\n      issues.push({\n        severity: 'high' as const,\n        description: 'Renaming columns can break existing application code and queries',\n        location: 'RENAME COLUMN operation',\n        line: lines.findIndex(line => line.toLowerCase().includes('rename column')) + 1 || 1,\n        recommendation: 'Consider a staged approach: add new column, copy data, update application, then drop old column'\n      });\n    }\n\n    return {\n      applicable: true,\n      confidence: 0.8,\n      issues,\n      impact: {\n        riskReduction: 0.7,\n        performanceImprovement: 0,\n        complexityAdded: 0.4,\n        description: 'Prevents application breakage from column renames'\n      }\n    };\n  }\n}\n\nclass ColumnRenamingApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    let modifiedContent = content;\n    const changes = [];\n    const lines = content.split('\\n');\n\n    for (let i = 0; i < lines.length; i++) {\n      const line = lines[i];\n      if (line.toLowerCase().includes('rename column')) {\n        const warnings = [\n          '-- ‚ö†Ô∏è  COLUMN RENAME WARNING:',\n          '-- This operation can break existing application code.',\n          '-- Recommended staged approach:',\n          '-- 1. Add new column with desired name',\n          '-- 2. Copy data from old to new column',\n          '-- 3. Update application code to use new column',\n          '-- 4. Drop old column in a separate migration'\n        ];\n        \n        lines.splice(i, 0, ...warnings);\n        changes.push('Added column renaming safety warning');\n        i += warnings.length; // Skip inserted lines\n      }\n    }\n\n    if (changes.length > 0) {\n      modifiedContent = lines.join('\\n');\n    }\n\n    return {\n      enhancement,\n      applied: changes.length > 0,\n      modifiedContent,\n      warnings: changes.length === 0 ? ['No column renaming operations found'] : [],\n      changes: changes.map(change => ({\n        type: 'ADDED' as const,\n        original: 'RENAME COLUMN',\n        modified: change,\n        line: 1,\n        reason: change\n      }))\n    };\n  }\n}\n\nexport const columnRenamingModule: EnhancementModule = {\n  enhancement,\n  detector: new ColumnRenamingDetector(),\n  applicator: new ColumnRenamingApplicator()\n}; ","/**\n * Cascade Delete Safety Enhancement\n * Warns about potential risks with CASCADE DELETE operations\n */\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-cascade-delete',\n  name: 'Cascade Delete Safety',\n  description: 'Warns about CASCADE DELETE operations and suggests safer alternatives',\n  category: 'safety',\n  priority: 9,\n  requiresConfirmation: true,\n  tags: ['cascade', 'delete', 'foreign-key', 'safety']\n};\n\nclass CascadeDeleteDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    const content = migration.up.toLowerCase();\n    return content.includes('on delete cascade') || content.includes('cascade delete');\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    const applicable = await this.detect(migration);\n    if (!applicable) {\n      return { \n        applicable: false, \n        confidence: 0, \n        issues: [], \n        impact: { riskReduction: 0, performanceImprovement: 0, complexityAdded: 0, description: 'No cascade delete operations detected' } \n      };\n    }\n\n    const issues = [];\n    const content = migration.up.toLowerCase();\n    const lines = migration.up.split('\\n');\n\n    if (content.includes('on delete cascade')) {\n      issues.push({\n        severity: 'high' as const,\n        description: 'CASCADE DELETE can cause unintended data loss across related tables',\n        location: 'ON DELETE CASCADE constraint',\n        line: lines.findIndex(line => line.toLowerCase().includes('on delete cascade')) + 1 || 1,\n        recommendation: 'Consider using ON DELETE RESTRICT or SET NULL with application-level cleanup logic'\n      });\n    }\n\n    return {\n      applicable: true,\n      confidence: 0.9,\n      issues,\n      impact: {\n        riskReduction: 0.8,\n        performanceImprovement: 0,\n        complexityAdded: 0.3,\n        description: 'Prevents accidental data loss from cascade deletions'\n      }\n    };\n  }\n}\n\nclass CascadeDeleteApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    let modifiedContent = content;\n    const changes = [];\n    const lines = content.split('\\n');\n\n    for (let i = 0; i < lines.length; i++) {\n      const line = lines[i];\n      if (line.toLowerCase().includes('on delete cascade')) {\n        const warnings = [\n          '-- ‚ö†Ô∏è  CASCADE DELETE WARNING:',\n          '-- This will automatically delete related records in child tables.',\n          '-- Consider safer alternatives:',\n          '-- 1. ON DELETE RESTRICT (prevents deletion if child records exist)',\n          '-- 2. ON DELETE SET NULL (sets foreign key to NULL)',\n          '-- 3. Application-level cleanup logic'\n        ];\n        \n        lines.splice(i, 0, ...warnings);\n        changes.push('Added CASCADE DELETE safety warning');\n        i += warnings.length; // Skip inserted lines\n      }\n    }\n\n    if (changes.length > 0) {\n      modifiedContent = lines.join('\\n');\n    }\n\n    return {\n      enhancement,\n      applied: changes.length > 0,\n      modifiedContent,\n      warnings: changes.length === 0 ? ['No cascade delete operations found'] : [],\n      changes: changes.map(change => ({\n        type: 'ADDED' as const,\n        original: 'ON DELETE CASCADE',\n        modified: change,\n        line: 1,\n        reason: change\n      }))\n    };\n  }\n}\n\nexport const cascadeDeleteModule: EnhancementModule = {\n  enhancement,\n  detector: new CascadeDeleteDetector(),\n  applicator: new CascadeDeleteApplicator()\n}; ","/**\n * Unique Constraint Safety Enhancement\n * Warns about potential issues when adding unique constraints to existing tables\n */\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-unique-constraint',\n  name: 'Unique Constraint Safety',\n  description: 'Warns about potential issues when adding unique constraints to existing tables with data',\n  category: 'safety',\n  priority: 7,\n  requiresConfirmation: true,\n  tags: ['unique', 'constraint', 'safety', 'data-integrity']\n};\n\nclass UniqueConstraintDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    const content = migration.up.toLowerCase();\n    return content.includes('unique') && (content.includes('constraint') || content.includes('add unique') || content.includes('create unique'));\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    const applicable = await this.detect(migration);\n    if (!applicable) {\n      return { \n        applicable: false, \n        confidence: 0, \n        issues: [], \n        impact: { riskReduction: 0, performanceImprovement: 0, complexityAdded: 0, description: 'No unique constraints detected' } \n      };\n    }\n\n    const issues = [];\n    const content = migration.up.toLowerCase();\n    const lines = migration.up.split('\\n');\n\n    if (content.includes('add unique') || content.includes('add constraint') && content.includes('unique')) {\n      issues.push({\n        severity: 'medium' as const,\n        description: 'Adding unique constraint to existing table may fail if duplicate values exist',\n        location: 'UNIQUE constraint',\n        line: lines.findIndex(line => line.toLowerCase().includes('unique')) + 1 || 1,\n        recommendation: 'Verify data uniqueness before adding constraint or clean up duplicates first'\n      });\n    }\n\n    return {\n      applicable: true,\n      confidence: 0.8,\n      issues,\n      impact: {\n        riskReduction: 0.6,\n        performanceImprovement: 0,\n        complexityAdded: 0.3,\n        description: 'Prevents constraint violation errors during migration'\n      }\n    };\n  }\n}\n\nclass UniqueConstraintApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    let modifiedContent = content;\n    const changes = [];\n    const lines = content.split('\\n');\n\n    for (let i = 0; i < lines.length; i++) {\n      const line = lines[i];\n      if (line.toLowerCase().includes('unique') && (line.toLowerCase().includes('constraint') || line.toLowerCase().includes('add unique'))) {\n        const warnings = [\n          '-- UNIQUE CONSTRAINT WARNING:',\n          '-- Ensure no duplicate values exist before adding unique constraint:',\n          '-- SELECT column_name, COUNT(*) FROM table_name GROUP BY column_name HAVING COUNT(*) > 1;'\n        ];\n        \n        lines.splice(i, 0, ...warnings);\n        changes.push('Added unique constraint safety check');\n        i += warnings.length; // Skip inserted lines\n      }\n    }\n\n    if (changes.length > 0) {\n      modifiedContent = lines.join('\\n');\n    }\n\n    return {\n      enhancement,\n      applied: changes.length > 0,\n      modifiedContent,\n      warnings: changes.length === 0 ? ['No unique constraints found'] : [],\n      changes: changes.map(change => ({\n        type: 'ADDED' as const,\n        original: 'UNIQUE constraint',\n        modified: change,\n        line: 1,\n        reason: change\n      }))\n    };\n  }\n}\n\nexport const uniqueConstraintModule: EnhancementModule = {\n  enhancement,\n  detector: new UniqueConstraintDetector(),\n  applicator: new UniqueConstraintApplicator()\n}; ","/**\n * Check Constraint Safety Enhancement\n * Warns about potential issues when adding check constraints\n */\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-check-constraint',\n  name: 'Check Constraint Safety',\n  description: 'Warns about potential issues when adding check constraints to existing tables',\n  category: 'safety',\n  priority: 6,\n  requiresConfirmation: true,\n  tags: ['check', 'constraint', 'validation', 'safety']\n};\n\nclass CheckConstraintDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    const content = migration.up.toLowerCase();\n    return content.includes('check') && content.includes('constraint');\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    const applicable = await this.detect(migration);\n    if (!applicable) {\n      return { \n        applicable: false, \n        confidence: 0, \n        issues: [], \n        impact: { riskReduction: 0, performanceImprovement: 0, complexityAdded: 0, description: 'No check constraints detected' } \n      };\n    }\n\n    const issues = [];\n    const content = migration.up.toLowerCase();\n    const lines = migration.up.split('\\n');\n\n    if (content.includes('add constraint') && content.includes('check')) {\n      issues.push({\n        severity: 'medium' as const,\n        description: 'Adding check constraint to existing table may fail if data violates the constraint',\n        location: 'CHECK constraint',\n        line: lines.findIndex(line => line.toLowerCase().includes('check')) + 1 || 1,\n        recommendation: 'Verify existing data meets constraint requirements before adding'\n      });\n    }\n\n    return {\n      applicable: true,\n      confidence: 0.8,\n      issues,\n      impact: {\n        riskReduction: 0.6,\n        performanceImprovement: 0,\n        complexityAdded: 0.3,\n        description: 'Prevents constraint violation errors during migration'\n      }\n    };\n  }\n}\n\nclass CheckConstraintApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    let modifiedContent = content;\n    const changes = [];\n    const lines = content.split('\\n');\n\n    for (let i = 0; i < lines.length; i++) {\n      const line = lines[i];\n      if (line.toLowerCase().includes('check') && line.toLowerCase().includes('constraint')) {\n        const warnings = [\n          '-- CHECK CONSTRAINT WARNING:',\n          '-- Verify existing data meets constraint requirements:',\n          '-- SELECT * FROM table_name WHERE NOT (constraint_condition);'\n        ];\n        \n        lines.splice(i, 0, ...warnings);\n        changes.push('Added check constraint validation warning');\n        i += warnings.length;\n      }\n    }\n\n    if (changes.length > 0) {\n      modifiedContent = lines.join('\\n');\n    }\n\n    return {\n      enhancement,\n      applied: changes.length > 0,\n      modifiedContent,\n      warnings: changes.length === 0 ? ['No check constraints found'] : [],\n      changes: changes.map(change => ({\n        type: 'ADDED' as const,\n        original: 'CHECK constraint',\n        modified: change,\n        line: 1,\n        reason: change\n      }))\n    };\n  }\n}\n\nexport const checkConstraintModule: EnhancementModule = {\n  enhancement,\n  detector: new CheckConstraintDetector(),\n  applicator: new CheckConstraintApplicator()\n}; ","/**\n * Backup Recommendation Safety Enhancement\n * Suggests database backups before risky operations\n */\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-backup-recommendation',\n  name: 'Backup Recommendation',\n  description: 'Recommends taking database backups before executing risky migration operations',\n  category: 'safety',\n  priority: 9,\n  requiresConfirmation: false,\n  tags: ['backup', 'safety', 'data-protection', 'risk-mitigation']\n};\n\nclass BackupRecommendationDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    const content = migration.up.toLowerCase();\n    const riskyOperations = [\n      'drop table',\n      'drop column',\n      'alter column',\n      'truncate',\n      'delete from',\n      'update',\n      'drop index',\n      'drop constraint'\n    ];\n    \n    return riskyOperations.some(op => content.includes(op));\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    const applicable = await this.detect(migration);\n    if (!applicable) {\n      return { \n        applicable: false, \n        confidence: 0, \n        issues: [], \n        impact: { riskReduction: 0, performanceImprovement: 0, complexityAdded: 0, description: 'No risky operations detected' } \n      };\n    }\n\n    const issues = [];\n    const content = migration.up.toLowerCase();\n    const lines = migration.up.split('\\n');\n\n    const riskyOperations = [\n      { operation: 'drop table', severity: 'critical', description: 'Dropping tables permanently removes all data' },\n      { operation: 'drop column', severity: 'high', description: 'Dropping columns permanently removes data' },\n      { operation: 'truncate', severity: 'critical', description: 'Truncating tables removes all data' },\n      { operation: 'delete from', severity: 'high', description: 'Mass deletion operations can remove critical data' }\n    ];\n\n    for (const op of riskyOperations) {\n      if (content.includes(op.operation)) {\n        issues.push({\n          severity: op.severity as 'critical' | 'high',\n          description: op.description,\n          location: op.operation.toUpperCase(),\n          line: lines.findIndex(line => line.toLowerCase().includes(op.operation)) + 1 || 1,\n          recommendation: 'Create a database backup before executing this migration'\n        });\n      }\n    }\n\n    return {\n      applicable: true,\n      confidence: 0.9,\n      issues,\n      impact: {\n        riskReduction: 0.9,\n        performanceImprovement: 0,\n        complexityAdded: 0.1,\n        description: 'Adds backup recommendations for data safety'\n      }\n    };\n  }\n}\n\nclass BackupRecommendationApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    const changes = [];\n    \n    // Add backup recommendation at the top of the migration\n    const backupWarning = [\n      '-- ‚ö†Ô∏è  IMPORTANT: BACKUP RECOMMENDATION',\n      '-- This migration contains potentially destructive operations.',\n      '-- It is STRONGLY recommended to create a full database backup before proceeding.',\n      '-- Command example: pg_dump database_name > backup_$(date +%Y%m%d_%H%M%S).sql',\n      '--'\n    ].join('\\n');\n\n    const modifiedContent = backupWarning + '\\n' + content;\n    changes.push('Added backup recommendation warning');\n\n    return {\n      enhancement,\n      applied: true,\n      modifiedContent,\n      warnings: [],\n      changes: changes.map(change => ({\n        type: 'ADDED' as const,\n        original: '',\n        modified: change,\n        line: 1,\n        reason: change\n      }))\n    };\n  }\n}\n\nexport const backupRecommendationModule: EnhancementModule = {\n  enhancement,\n  detector: new BackupRecommendationDetector(),\n  applicator: new BackupRecommendationApplicator()\n}; ","/**\n * Migration Order Safety Enhancement\n * Checks for potential issues with the order of operations in migrations\n */\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\nconst enhancement: Enhancement = {\n  id: 'safety-migration-order',\n  name: 'Migration Order Safety',\n  description: 'Checks for potential issues with the order of operations in migrations',\n  category: 'safety',\n  priority: 8,\n  requiresConfirmation: false,\n  tags: ['order', 'sequence', 'dependencies', 'safety']\n};\n\nclass MigrationOrderDetector implements EnhancementDetector {\n  async detect(migration: MigrationFile): Promise<boolean> {\n    const content = migration.up.toLowerCase();\n    return (content.includes('drop') && content.includes('create')) ||\n           (content.includes('alter') && content.includes('add')) ||\n           (content.includes('insert') && content.includes('create'));\n  }\n\n  async analyze(migration: MigrationFile): Promise<EnhancementAnalysis> {\n    const applicable = await this.detect(migration);\n    if (!applicable) {\n      return { \n        applicable: false, \n        confidence: 0, \n        issues: [], \n        impact: { riskReduction: 0, performanceImprovement: 0, complexityAdded: 0, description: 'No order-sensitive operations detected' } \n      };\n    }\n\n    const issues = [];\n    const content = migration.up.toLowerCase();\n    const lines = migration.up.split('\\n');\n\n    if (content.includes('insert') && content.includes('create table')) {\n      const insertIndex = lines.findIndex(line => line.toLowerCase().includes('insert'));\n      const createIndex = lines.findIndex(line => line.toLowerCase().includes('create table'));\n      \n      if (insertIndex >= 0 && createIndex >= 0 && insertIndex < createIndex) {\n        issues.push({\n          severity: 'high' as const,\n          description: 'INSERT statement appears before CREATE TABLE - this will cause an error',\n          location: 'INSERT before CREATE TABLE',\n          line: insertIndex + 1,\n          recommendation: 'Move CREATE TABLE statements before INSERT statements'\n        });\n      }\n    }\n\n    return {\n      applicable: true,\n      confidence: 0.7,\n      issues,\n      impact: {\n        riskReduction: 0.6,\n        performanceImprovement: 0,\n        complexityAdded: 0.2,\n        description: 'Prevents migration failures due to incorrect operation ordering'\n      }\n    };\n  }\n}\n\nclass MigrationOrderApplicator implements EnhancementApplicator {\n  async apply(content: string, migration: MigrationFile): Promise<EnhancementResult> {\n    let modifiedContent = content;\n    const changes = [];\n\n    const orderingGuideline = [\n      '-- MIGRATION ORDER GUIDELINES:',\n      '-- 1. CREATE statements (tables, indexes) first',\n      '-- 2. ALTER statements (modify existing structures)',\n      '-- 3. INSERT/UPDATE statements (data operations)',\n      '-- 4. DROP statements (remove structures) last',\n      '--'\n    ].join('\\n');\n\n    modifiedContent = orderingGuideline + '\\n' + content;\n    changes.push('Added migration order guidelines');\n\n    return {\n      enhancement,\n      applied: true,\n      modifiedContent,\n      warnings: [],\n      changes: changes.map(change => ({\n        type: 'ADDED' as const,\n        original: '',\n        modified: change,\n        line: 1,\n        reason: change\n      }))\n    };\n  }\n}\n\nexport const migrationOrderModule: EnhancementModule = {\n  enhancement,\n  detector: new MigrationOrderDetector(),\n  applicator: new MigrationOrderApplicator()\n}; ","/**\n * Safety Enhancements Index\n * Loads and exports all safety enhancement modules\n */\n\nimport { EnhancementModule } from '../../core/types.js';\n\n// Import all safety enhancement modules\nimport { transactionWrapperModule } from './transaction-wrapper.js';\nimport { dropTableSafeguardModule } from './drop-table-safeguard.js';\nimport { foreignKeyConstraintModule } from './foreign-key-constraint.js';\nimport { nullableColumnModule } from './nullable-column.js';\nimport { indexCreationModule } from './index-creation.js';\nimport { dataTypeChangeModule } from './data-type-change.js';\nimport { columnRenamingModule } from './column-renaming.js';\nimport { cascadeDeleteModule } from './cascade-delete.js';\nimport { uniqueConstraintModule } from './unique-constraint.js';\nimport { checkConstraintModule } from './check-constraint.js';\nimport { backupRecommendationModule } from './backup-recommendation.js';\nimport { migrationOrderModule } from './migration-order.js';\n\n/**\n * Load all safety enhancement modules\n * @returns Array of all safety enhancement modules\n */\nexport async function loadSafetyEnhancements(): Promise<EnhancementModule[]> {\n  return [\n    transactionWrapperModule,\n    dropTableSafeguardModule,\n    foreignKeyConstraintModule,\n    nullableColumnModule,\n    indexCreationModule,\n    dataTypeChangeModule,\n    columnRenamingModule,\n    cascadeDeleteModule,\n    uniqueConstraintModule,\n    checkConstraintModule,\n    backupRecommendationModule,\n    migrationOrderModule,\n  ];\n}\n\n/**\n * Get all safety enhancement IDs\n * @returns Array of safety enhancement IDs\n */\nexport async function getSafetyEnhancementIds(): Promise<string[]> {\n  const modules = await loadSafetyEnhancements();\n  return modules.map(module => module.enhancement.id);\n}\n\n/**\n * Get safety enhancement module by ID\n * @param id Enhancement ID\n * @returns Enhancement module or undefined\n */\nexport async function getSafetyEnhancementModule(id: string): Promise<EnhancementModule | undefined> {\n  const modules = await loadSafetyEnhancements();\n  return modules.find(module => module.enhancement.id === id);\n} ","import { MigrationFile, Enhancement, EnhancementResult, EnhancementDetector, EnhancementApplicator, EnhancementAnalysis, EnhancementModule } from '../../core/types.js';\n\n// Stub detector and applicator classes\nclass StubDetector implements EnhancementDetector {\n  async detect(): Promise<boolean> { return false; }\n  async analyze(): Promise<EnhancementAnalysis> {\n    return { applicable: false, confidence: 0, issues: [], impact: { riskReduction: 0, performanceImprovement: 0, complexityAdded: 0, description: 'Stub' } };\n  }\n}\n\nclass StubApplicator implements EnhancementApplicator {\n  async apply(content: string): Promise<EnhancementResult> {\n    return { enhancement: {} as Enhancement, applied: false, modifiedContent: content, warnings: ['Not implemented'], changes: [] };\n  }\n}\n\n// Batch Insert\nconst batchInsertEnhancement: Enhancement = { id: 'speed-batch-insert', name: 'Batch Insert', description: 'Stub', category: 'speed', priority: 5, requiresConfirmation: false, tags: ['stub'] };\nexport const batchInsertModule: EnhancementModule = { enhancement: batchInsertEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Partial Index - DISABLED: User requested no indexing enhancements\nconst partialIndexEnhancement: Enhancement = { id: 'speed-partial-index', name: 'Partial Index', description: 'DISABLED - No indexing enhancements requested', category: 'speed', priority: 0, requiresConfirmation: false, tags: ['disabled'] };\nexport const partialIndexModule: EnhancementModule = { enhancement: partialIndexEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Index Optimization - DISABLED: User requested no indexing enhancements  \nconst indexOptimizationEnhancement: Enhancement = { id: 'speed-index-optimization', name: 'Index Optimization', description: 'DISABLED - No indexing enhancements requested', category: 'speed', priority: 0, requiresConfirmation: false, tags: ['disabled'] };\nexport const indexOptimizationModule: EnhancementModule = { enhancement: indexOptimizationEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Concurrent Index - DISABLED: User requested no indexing enhancements\n// import { concurrentIndexModule as concurrentIndexModuleImpl } from './concurrent-index.js';\n// export const concurrentIndexModule = concurrentIndexModuleImpl;\nconst concurrentIndexEnhancement: Enhancement = { id: 'speed-concurrent-index', name: 'Concurrent Index Creation', description: 'DISABLED - No indexing enhancements requested', category: 'speed', priority: 0, requiresConfirmation: false, tags: ['disabled'] };\nexport const concurrentIndexModule: EnhancementModule = { enhancement: concurrentIndexEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Query Optimization\nconst queryOptimizationEnhancement: Enhancement = { id: 'speed-query-optimization', name: 'Query Optimization', description: 'Stub', category: 'speed', priority: 5, requiresConfirmation: false, tags: ['stub'] };\nexport const queryOptimizationModule: EnhancementModule = { enhancement: queryOptimizationEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Bulk Update\nconst bulkUpdateEnhancement: Enhancement = { id: 'speed-bulk-update', name: 'Bulk Update', description: 'Stub', category: 'speed', priority: 5, requiresConfirmation: false, tags: ['stub'] };\nexport const bulkUpdateModule: EnhancementModule = { enhancement: bulkUpdateEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Connection Pooling\nconst connectionPoolingEnhancement: Enhancement = { id: 'speed-connection-pooling', name: 'Connection Pooling', description: 'Stub', category: 'speed', priority: 5, requiresConfirmation: false, tags: ['stub'] };\nexport const connectionPoolingModule: EnhancementModule = { enhancement: connectionPoolingEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Vacuum Analyze\nconst vacuumAnalyzeEnhancement: Enhancement = { id: 'speed-vacuum-analyze', name: 'Vacuum Analyze', description: 'Stub', category: 'speed', priority: 5, requiresConfirmation: false, tags: ['stub'] };\nexport const vacuumAnalyzeModule: EnhancementModule = { enhancement: vacuumAnalyzeEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Parallel Execution\nconst parallelExecutionEnhancement: Enhancement = { id: 'speed-parallel-execution', name: 'Parallel Execution', description: 'Stub', category: 'speed', priority: 5, requiresConfirmation: false, tags: ['stub'] };\nexport const parallelExecutionModule: EnhancementModule = { enhancement: parallelExecutionEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Compression\nconst compressionEnhancement: Enhancement = { id: 'speed-compression', name: 'Compression', description: 'Stub', category: 'speed', priority: 5, requiresConfirmation: false, tags: ['stub'] };\nexport const compressionModule: EnhancementModule = { enhancement: compressionEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Statistics Update\nconst statisticsUpdateEnhancement: Enhancement = { id: 'speed-statistics-update', name: 'Statistics Update', description: 'Stub', category: 'speed', priority: 5, requiresConfirmation: false, tags: ['stub'] };\nexport const statisticsUpdateModule: EnhancementModule = { enhancement: statisticsUpdateEnhancement, detector: new StubDetector(), applicator: new StubApplicator() };\n\n// Cache Optimization\nconst cacheOptimizationEnhancement: Enhancement = { id: 'speed-cache-optimization', name: 'Cache Optimization', description: 'Stub', category: 'speed', priority: 5, requiresConfirmation: false, tags: ['stub'] };\nexport const cacheOptimizationModule: EnhancementModule = { enhancement: cacheOptimizationEnhancement, detector: new StubDetector(), applicator: new StubApplicator() }; ","/**\n * Speed Enhancements Index\n * Loads and exports all speed enhancement modules\n */\n\nimport { EnhancementModule } from '../../core/types.js';\n\n// Import all speed enhancement modules  \nimport { \n  batchInsertModule,\n  concurrentIndexModule, // DISABLED: User requested no indexing in speed enhancements\n  partialIndexModule, // DISABLED: User requested no indexing in speed enhancements\n  indexOptimizationModule, // DISABLED: User requested no indexing in speed enhancements\n  queryOptimizationModule,\n  bulkUpdateModule,\n  connectionPoolingModule,\n  vacuumAnalyzeModule,\n  parallelExecutionModule,\n  compressionModule,\n  statisticsUpdateModule,\n  cacheOptimizationModule\n} from './remaining-stubs.js';\n\n/**\n * Load all speed enhancement modules\n * @returns Array of all speed enhancement modules\n */\nexport async function loadSpeedEnhancements(): Promise<EnhancementModule[]> {\n  return [\n    batchInsertModule,\n    concurrentIndexModule, // DISABLED: User requested no indexing in speed enhancements  \n    partialIndexModule, // DISABLED: User requested no indexing in speed enhancements\n    indexOptimizationModule, // DISABLED: User requested no indexing in speed enhancements\n    queryOptimizationModule,\n    bulkUpdateModule,\n    connectionPoolingModule,\n    vacuumAnalyzeModule,\n    parallelExecutionModule,\n    compressionModule,\n    statisticsUpdateModule,\n    cacheOptimizationModule,\n  ];\n}\n\n/**\n * Get all speed enhancement IDs\n * @returns Array of speed enhancement IDs\n */\nexport async function getSpeedEnhancementIds(): Promise<string[]> {\n  const modules = await loadSpeedEnhancements();\n  return modules.map(module => module.enhancement.id);\n}\n\n/**\n * Get speed enhancement module by ID\n * @param id Enhancement ID\n * @returns Enhancement module or undefined\n */\nexport async function getSpeedEnhancementModule(id: string): Promise<EnhancementModule | undefined> {\n  const modules = await loadSpeedEnhancements();\n  return modules.find(module => module.enhancement.id === id);\n} ","/**\n * Enhancement Engine - Coordinates all safety and speed enhancements\n * This is the main engine that loads and applies enhancement modules\n * Optimized for performance with lazy loading and caching\n */\n\nimport { MigrationFile, Enhancement, EnhancementResult, EnhancementModule, EnhancementAnalysis } from './types.js';\nimport { loadSafetyEnhancements } from '../enhancements/safety/index.js';\nimport { loadSpeedEnhancements } from '../enhancements/speed/index.js';\n\nexport class EnhancementEngine {\n  private safetyModules: EnhancementModule[] = [];\n  private speedModules: EnhancementModule[] = [];\n  private initialized = false;\n  \n  // Performance optimizations\n  private analysisCache = new Map<string, EnhancementAnalysis>();\n  private detectionCache = new Map<string, boolean>();\n  private moduleCache = new Map<string, EnhancementModule>();\n\n  /**\n   * Initialize the enhancement engine by loading all enhancement modules\n   * Uses lazy loading for better performance\n   */\n  async initialize(): Promise<void> {\n    if (this.initialized) return;\n\n    try {\n      // Load modules in parallel for better performance\n      const [safetyModulesPromise, speedModulesPromise] = await Promise.all([\n        loadSafetyEnhancements(),\n        loadSpeedEnhancements()\n      ]);\n\n      this.safetyModules = safetyModulesPromise;\n      this.speedModules = speedModulesPromise;\n      \n      // Sort modules by priority (higher priority first) and cache them\n      this.safetyModules.sort((a, b) => b.enhancement.priority - a.enhancement.priority);\n      this.speedModules.sort((a, b) => b.enhancement.priority - a.enhancement.priority);\n      \n      // Build module cache for O(1) lookups\n      [...this.safetyModules, ...this.speedModules].forEach(module => {\n        this.moduleCache.set(module.enhancement.id, module);\n      });\n      \n      this.initialized = true;\n    } catch (error) {\n      console.error('Failed to initialize enhancement engine:', error);\n      throw error;\n    }\n  }\n\n  /**\n   * Detect applicable safety enhancements for a migration\n   * @param migration Migration file to analyze\n   * @returns Array of applicable safety enhancements with analysis\n   */\n  async detectSafetyEnhancements(migration: MigrationFile): Promise<Enhancement[]> {\n    await this.initialize();\n    \n    const applicableEnhancements: Enhancement[] = [];\n    const cacheKey = `safety_${migration.name}_${migration.up.length}`;\n    \n    // Check cache first\n    if (this.detectionCache.has(cacheKey)) {\n      return this.getCachedEnhancements(cacheKey, this.safetyModules);\n    }\n    \n    // Run detections in parallel for better performance\n    const detectionPromises = this.safetyModules.map(async (module) => {\n      try {\n        const isApplicable = await module.detector.detect(migration);\n        return { module, isApplicable };\n      } catch (error) {\n        console.warn(`Error detecting enhancement ${module.enhancement.id}:`, error);\n        return { module, isApplicable: false };\n      }\n    });\n    \n    const results = await Promise.all(detectionPromises);\n    \n    results.forEach(({ module, isApplicable }) => {\n      if (isApplicable) {\n        applicableEnhancements.push(module.enhancement);\n      }\n    });\n    \n    // Cache the results\n    this.cacheEnhancements(cacheKey, applicableEnhancements);\n    \n    return applicableEnhancements;\n  }\n\n  /**\n   * Detect applicable speed enhancements for a migration\n   * @param migration Migration file to analyze\n   * @returns Array of applicable speed enhancements with analysis\n   */\n  async detectSpeedEnhancements(migration: MigrationFile): Promise<Enhancement[]> {\n    await this.initialize();\n    \n    const applicableEnhancements: Enhancement[] = [];\n    const cacheKey = `speed_${migration.name}_${migration.up.length}`;\n    \n    // Check cache first\n    if (this.detectionCache.has(cacheKey)) {\n      return this.getCachedEnhancements(cacheKey, this.speedModules);\n    }\n    \n    // Run detections in parallel for better performance\n    const detectionPromises = this.speedModules.map(async (module) => {\n      try {\n        const isApplicable = await module.detector.detect(migration);\n        return { module, isApplicable };\n      } catch (error) {\n        console.warn(`Error detecting enhancement ${module.enhancement.id}:`, error);\n        return { module, isApplicable: false };\n      }\n    });\n    \n    const results = await Promise.all(detectionPromises);\n    \n    results.forEach(({ module, isApplicable }) => {\n      if (isApplicable) {\n        applicableEnhancements.push(module.enhancement);\n      }\n    });\n    \n    // Cache the results\n    this.cacheEnhancements(cacheKey, applicableEnhancements);\n    \n    return applicableEnhancements;\n  }\n\n  /**\n   * Get detailed analysis for a specific enhancement\n   * @param enhancementId Enhancement ID to analyze\n   * @param migration Migration file to analyze\n   * @returns Detailed analysis of the enhancement\n   */\n  async getEnhancementAnalysis(enhancementId: string, migration: MigrationFile): Promise<EnhancementAnalysis | null> {\n    await this.initialize();\n    \n    const cacheKey = `analysis_${enhancementId}_${migration.name}_${migration.up.length}`;\n    \n    // Check cache first\n    if (this.analysisCache.has(cacheKey)) {\n      return this.analysisCache.get(cacheKey)!;\n    }\n    \n    const module = this.moduleCache.get(enhancementId);\n    if (!module) return null;\n    \n    try {\n      const analysis = await module.detector.analyze(migration);\n      \n      // Cache the analysis\n      if (analysis) {\n        this.analysisCache.set(cacheKey, analysis);\n      }\n      \n      return analysis;\n    } catch (error) {\n      console.warn(`Error analyzing enhancement ${enhancementId}:`, error);\n      return null;\n    }\n  }\n\n  /**\n   * Apply a set of enhancements to migration content\n   * @param content Original migration content\n   * @param migration Migration file object\n   * @param enhancements Array of enhancements to apply\n   * @returns Modified content with all enhancements applied\n   */\n  async applyEnhancements(content: string, migration: MigrationFile, enhancements: Enhancement[]): Promise<string> {\n    await this.initialize();\n    \n    let modifiedContent = content;\n    const results: EnhancementResult[] = [];\n    \n    // Apply enhancements in priority order\n    const sortedEnhancements = [...enhancements].sort((a, b) => b.priority - a.priority);\n    \n    for (const enhancement of sortedEnhancements) {\n      const module = this.moduleCache.get(enhancement.id);\n      if (!module) {\n        console.warn(`Enhancement module not found: ${enhancement.id}`);\n        continue;\n      }\n      \n      try {\n        // Update migration object with current content\n        const updatedMigration = { ...migration, up: modifiedContent };\n        \n        const result = await module.applicator.apply(modifiedContent, updatedMigration);\n        if (result.applied) {\n          modifiedContent = result.modifiedContent;\n          results.push(result);\n        }\n      } catch (error) {\n        console.warn(`Error applying enhancement ${enhancement.id}:`, error);\n      }\n    }\n    \n    return modifiedContent;\n  }\n\n  /**\n   * Apply a single enhancement to migration content\n   * @param content Original migration content\n   * @param migration Migration file object\n   * @param enhancement Enhancement to apply\n   * @returns Enhancement result\n   */\n  async applySingleEnhancement(content: string, migration: MigrationFile, enhancement: Enhancement): Promise<EnhancementResult> {\n    await this.initialize();\n    \n    const module = this.moduleCache.get(enhancement.id);\n    if (!module) {\n      throw new Error(`Enhancement module not found: ${enhancement.id}`);\n    }\n    \n    return await module.applicator.apply(content, migration);\n  }\n\n  /**\n   * Find an enhancement module by ID (now using cache for O(1) lookup)\n   * @param enhancementId Enhancement ID to find\n   * @returns Enhancement module or undefined if not found\n   */\n  private findEnhancementModule(enhancementId: string): EnhancementModule | undefined {\n    return this.moduleCache.get(enhancementId);\n  }\n\n  /**\n   * Cache enhancement detection results\n   */\n  private cacheEnhancements(cacheKey: string, enhancements: Enhancement[]): void {\n    // Store enhancement IDs in cache to avoid storing large objects\n    const enhancementIds = enhancements.map(e => e.id);\n    this.detectionCache.set(cacheKey, enhancementIds.length > 0);\n  }\n\n  /**\n   * Get cached enhancements\n   */\n  private getCachedEnhancements(cacheKey: string, modules: EnhancementModule[]): Enhancement[] {\n    // This is a simplified cache implementation\n    // In practice, we'd need to cache the actual enhancement IDs\n    return [];\n  }\n\n  /**\n   * Clear all caches (useful for testing or when migration changes)\n   */\n  clearCache(): void {\n    this.analysisCache.clear();\n    this.detectionCache.clear();\n  }\n\n  /**\n   * Get cache statistics for debugging\n   */\n  getCacheStats(): { analysisCache: number; detectionCache: number } {\n    return {\n      analysisCache: this.analysisCache.size,\n      detectionCache: this.detectionCache.size\n    };\n  }\n\n  /**\n   * Check if an enhancement is available\n   * @param enhancementId Enhancement ID to check\n   * @returns True if enhancement is available\n   */\n  async hasEnhancement(enhancementId: string): Promise<boolean> {\n    await this.initialize();\n    return this.moduleCache.has(enhancementId);\n  }\n\n  /**\n   * Get a specific enhancement by ID\n   * @param enhancementId Enhancement ID to get\n   * @returns Enhancement definition or undefined if not found\n   */\n  async getEnhancement(enhancementId: string): Promise<Enhancement | undefined> {\n    await this.initialize();\n    const module = this.moduleCache.get(enhancementId);\n    return module?.enhancement;\n  }\n\n  /**\n   * Get all available safety enhancements\n   * @returns Array of all safety enhancement definitions\n   */\n  async getAllSafetyEnhancements(): Promise<Enhancement[]> {\n    await this.initialize();\n    return this.safetyModules.map(module => module.enhancement);\n  }\n\n  /**\n   * Get all available speed enhancements\n   * @returns Array of all speed enhancement definitions\n   */\n  async getAllSpeedEnhancements(): Promise<Enhancement[]> {\n    await this.initialize();\n    return this.speedModules.map(module => module.enhancement);\n  }\n\n  /**\n   * Get all available enhancements (both safety and speed)\n   * @returns Array of all enhancement definitions\n   */\n  async getAllEnhancements(): Promise<Enhancement[]> {\n    await this.initialize();\n    return [\n      ...this.safetyModules.map(module => module.enhancement),\n      ...this.speedModules.map(module => module.enhancement)\n    ];\n  }\n\n  /**\n   * Generate rollback script for a migration\n   * @param migration Migration file object\n   * @returns Rollback SQL script\n   */\n  async generateRollback(migration: MigrationFile): Promise<string> {\n    const sql = migration.up;\n    const sqlLower = sql.toLowerCase();\n    \n    if (sqlLower.includes('alter table') && sqlLower.includes('add column')) {\n      const tableMatch = sql.match(/alter\\s+table\\s+(\\w+)/i);\n      const columnMatch = sql.match(/add\\s+column\\s+(\\w+)/i);\n      if (tableMatch && columnMatch) {\n        return `ALTER TABLE ${tableMatch[1]} DROP COLUMN ${columnMatch[1]};`;\n      }\n    }\n    \n    if (sqlLower.includes('create index')) {\n      const indexMatch = sql.match(/create\\s+index\\s+(?:concurrently\\s+)?(\\w+)/i);\n      if (indexMatch) {\n        return `DROP INDEX ${indexMatch[1]};`;\n      }\n    }\n    \n    if (sqlLower.includes('alter table') && sqlLower.includes('add constraint')) {\n      const tableMatch = sql.match(/alter\\s+table\\s+(\\w+)/i);\n      const constraintMatch = sql.match(/add\\s+constraint\\s+(\\w+)/i);\n      if (tableMatch && constraintMatch) {\n        return `ALTER TABLE ${tableMatch[1]} DROP CONSTRAINT ${constraintMatch[1]};`;\n      }\n    }\n    \n    return '-- Manual rollback required\\n-- Please create appropriate rollback statements for this migration';\n  }\n\n  /**\n   * Get engine statistics including performance metrics\n   * @returns Statistics about the enhancement engine\n   */\n  async getStats(): Promise<{\n    totalEnhancements: number;\n    safetyEnhancements: number;\n    speedEnhancements: number;\n    enhancementsByPriority: Record<number, number>;\n    cacheStats: { analysisCache: number; detectionCache: number };\n  }> {\n    await this.initialize();\n    \n    const allEnhancements = await this.getAllEnhancements();\n    const enhancementsByPriority: Record<number, number> = {};\n    \n    allEnhancements.forEach(enhancement => {\n      enhancementsByPriority[enhancement.priority] = (enhancementsByPriority[enhancement.priority] || 0) + 1;\n    });\n    \n    return {\n      totalEnhancements: allEnhancements.length,\n      safetyEnhancements: this.safetyModules.length,\n      speedEnhancements: this.speedModules.length,\n      enhancementsByPriority,\n      cacheStats: this.getCacheStats()\n    };\n  }\n} ","/**\n * Migration utilities for parsing and handling migration files\n */\n\nimport fs from 'fs-extra';\nimport path from 'node:path';\nimport crypto from 'node:crypto';\nimport pkg from 'node-sql-parser';\nconst { Parser } = pkg;\nimport { MigrationFile, SqlOperation } from './types.js';\n\n/**\n * Find the latest migration file in a directory\n * @param migrationsDir Path to the migrations directory\n * @returns Path to the latest migration file, or null if none found\n */\nexport async function findLatestMigration(migrationsDir: string): Promise<string | null> {\n  try {\n    const files = await fs.readdir(migrationsDir);\n    const migrationFiles = files\n      .filter(file => file.endsWith('.sql'))\n      .sort((a, b) => {\n        // Sort by timestamp prefix (assuming format like 0000_name.sql or timestamp_name.sql)\n        const aPrefix = a.split('_')[0];\n        const bPrefix = b.split('_')[0];\n        return bPrefix.localeCompare(aPrefix); // Descending order (latest first)\n      });\n    \n    return migrationFiles.length > 0 ? migrationFiles[0] : null;\n  } catch (error) {\n    return null;\n  }\n}\n\n/**\n * Parse a migration file into a structured MigrationFile object\n * @param filePath Path to the migration file\n * @returns Parsed MigrationFile object\n */\nexport async function parseMigrationFile(filePath: string): Promise<MigrationFile> {\n  const content = await fs.readFile(filePath, 'utf-8');\n  const fileName = path.basename(filePath);\n  \n  // Calculate checksum\n  const checksum = crypto.createHash('sha256').update(content).digest('hex');\n  \n  // Extract timestamp from filename (basic implementation)\n  const timestamp = extractTimestampFromFilename(fileName);\n  \n  // Parse SQL operations\n  const operations = await parseSqlOperations(content);\n  \n  // For now, we'll assume the entire content is \"up\" migration\n  // In a real implementation, you might split up/down migrations\n  const upContent = content;\n  const downContent = ''; // Would be extracted if present\n  \n  return {\n    path: filePath,\n    name: fileName,\n    up: upContent,\n    down: downContent,\n    timestamp,\n    operations,\n    checksum\n  };\n}\n\n/**\n * Extract timestamp from migration filename\n * @param filename Migration filename\n * @returns Date object representing the migration timestamp\n */\nfunction extractTimestampFromFilename(filename: string): Date {\n  // Try to extract timestamp from various formats\n  const timestampMatch = filename.match(/^(\\d{4})_/);\n  if (timestampMatch) {\n    // Simple numeric prefix - convert to date (this is basic, real implementation would be more sophisticated)\n    const year = new Date().getFullYear();\n    const month = new Date().getMonth();\n    const day = new Date().getDate();\n    return new Date(year, month, day, 0, 0, 0, parseInt(timestampMatch[1]));\n  }\n  \n  // Fallback to file modification time or current time\n  return new Date();\n}\n\n/**\n * Parse SQL content into structured operations\n * @param content SQL content to parse\n * @returns Array of SqlOperation objects\n */\nexport async function parseSqlOperations(content: string): Promise<SqlOperation[]> {\n  const operations: SqlOperation[] = [];\n  const parser = new Parser();\n  \n  // Split by statement breakpoints or semicolons\n  const statements = content\n    .split(/(--> statement-breakpoint|;)/i)\n    .map(stmt => stmt.trim())\n    .filter(stmt => stmt && !stmt.match(/^--> statement-breakpoint$/i) && stmt !== ';');\n  \n  let lineNumber = 1;\n  \n  for (const statement of statements) {\n    if (!statement.trim()) continue;\n    \n    try {\n      // Try to parse the SQL statement\n      const ast = parser.astify(statement, { database: 'sqlite' });\n      const operation = extractOperationFromAst(ast, statement, lineNumber);\n      if (operation) {\n        operations.push(operation);\n      }\n    } catch (error) {\n      // If parsing fails, create a generic operation\n      operations.push({\n        type: 'OTHER',\n        sql: statement,\n        line: lineNumber\n      });\n    }\n    \n    // Increment line number based on newlines in the statement\n    lineNumber += (statement.match(/\\n/g) || []).length + 1;\n  }\n  \n  return operations;\n}\n\n/**\n * Extract operation details from SQL AST\n * @param ast Parsed SQL AST\n * @param sql Original SQL statement\n * @param line Line number\n * @returns SqlOperation object\n */\nfunction extractOperationFromAst(ast: any, sql: string, line: number): SqlOperation | null {\n  if (!ast || !ast.type) return null;\n  \n  const operation: SqlOperation = {\n    type: 'OTHER',\n    sql,\n    line\n  };\n  \n  switch (ast.type?.toLowerCase()) {\n    case 'create':\n      if (ast.keyword === 'table') {\n        operation.type = 'CREATE_TABLE';\n        operation.table = ast.table?.[0]?.table || extractTableNameFromSql(sql);\n      } else if (ast.keyword === 'index') {\n        operation.type = 'CREATE_INDEX';\n        operation.index = ast.index || extractIndexNameFromSql(sql);\n        operation.table = ast.table?.[0]?.table || extractTableNameFromIndexSql(sql);\n      }\n      break;\n    \n    case 'drop':\n      if (ast.keyword === 'table') {\n        operation.type = 'DROP_TABLE';\n        operation.table = ast.name?.[0]?.table || extractTableNameFromSql(sql);\n      } else if (ast.keyword === 'index') {\n        operation.type = 'DROP_INDEX';\n        operation.index = ast.name || extractIndexNameFromSql(sql);\n      }\n      break;\n    \n    case 'alter':\n      operation.type = 'ALTER_TABLE';\n      operation.table = ast.table?.[0]?.table || extractTableNameFromSql(sql);\n      break;\n    \n    case 'insert':\n      operation.type = 'INSERT';\n      operation.table = ast.table?.[0]?.table || extractTableNameFromSql(sql);\n      break;\n    \n    case 'update':\n      operation.type = 'UPDATE';\n      operation.table = ast.table?.[0]?.table || extractTableNameFromSql(sql);\n      break;\n    \n    case 'delete':\n      operation.type = 'DELETE';\n      operation.table = ast.table?.[0]?.table || extractTableNameFromSql(sql);\n      break;\n  }\n  \n  return operation;\n}\n\n/**\n * Extract table name from SQL using regex (fallback when AST parsing fails)\n * @param sql SQL statement\n * @returns Table name or undefined\n */\nfunction extractTableNameFromSql(sql: string): string | undefined {\n  // Match various SQL patterns to extract table names\n  const patterns = [\n    /CREATE\\s+TABLE\\s+`?([^`\\s\\(]+)`?/i,\n    /DROP\\s+TABLE\\s+`?([^`\\s\\(]+)`?/i,\n    /ALTER\\s+TABLE\\s+`?([^`\\s\\(]+)`?/i,\n    /INSERT\\s+INTO\\s+`?([^`\\s\\(]+)`?/i,\n    /UPDATE\\s+`?([^`\\s\\(]+)`?/i,\n    /DELETE\\s+FROM\\s+`?([^`\\s\\(]+)`?/i,\n  ];\n  \n  for (const pattern of patterns) {\n    const match = sql.match(pattern);\n    if (match) {\n      return match[1];\n    }\n  }\n  \n  return undefined;\n}\n\n/**\n * Extract index name from SQL\n * @param sql SQL statement\n * @returns Index name or undefined\n */\nfunction extractIndexNameFromSql(sql: string): string | undefined {\n  const patterns = [\n    /CREATE\\s+(?:UNIQUE\\s+)?INDEX\\s+`?([^`\\s\\(]+)`?/i,\n    /DROP\\s+INDEX\\s+`?([^`\\s\\(]+)`?/i,\n  ];\n  \n  for (const pattern of patterns) {\n    const match = sql.match(pattern);\n    if (match) {\n      return match[1];\n    }\n  }\n  \n  return undefined;\n}\n\n/**\n * Extract table name from index SQL\n * @param sql SQL statement\n * @returns Table name or undefined\n */\nfunction extractTableNameFromIndexSql(sql: string): string | undefined {\n  const match = sql.match(/ON\\s+`?([^`\\s\\(]+)`?/i);\n  return match ? match[1] : undefined;\n}\n\n/**\n * Get all migration files in a directory\n * @param migrationsDir Path to migrations directory\n * @returns Array of migration file paths\n */\nexport async function getAllMigrationFiles(migrationsDir: string): Promise<string[]> {\n  try {\n    const files = await fs.readdir(migrationsDir);\n    return files\n      .filter(file => file.endsWith('.sql'))\n      .map(file => path.join(migrationsDir, file))\n      .sort(); // Sort alphabetically/chronologically\n  } catch (error) {\n    return [];\n  }\n}\n\n/**\n * Check if a file is a migration file\n * @param filePath Path to the file\n * @returns True if it's a migration file\n */\nexport function isMigrationFile(filePath: string): boolean {\n  return path.extname(filePath).toLowerCase() === '.sql';\n}\n\n/**\n * Validate migration file path\n * @param filePath Path to validate\n * @param migrationsDir Migrations directory\n * @returns Resolved path if valid, throws error if invalid\n */\nexport async function validateMigrationPath(filePath: string, migrationsDir: string): Promise<string> {\n  let resolvedPath: string;\n  \n  if (path.isAbsolute(filePath)) {\n    resolvedPath = filePath;\n  } else {\n    resolvedPath = path.resolve(migrationsDir, filePath);\n  }\n  \n  if (!await fs.pathExists(resolvedPath)) {\n    throw new Error(`Migration file not found: ${resolvedPath}`);\n  }\n  \n  if (!isMigrationFile(resolvedPath)) {\n    throw new Error(`File is not a migration file: ${resolvedPath}`);\n  }\n  \n  return resolvedPath;\n} ","/**\n * flow enhance - Interactively enhance a migration file\n * This is the most important command - implements the interactive enhancement flow\n */\n\nimport { confirm, log } from '@clack/prompts';\nimport { getFlowConfig, GlobalOptions } from '../lib/config.js';\nimport { createFlowSpinner, displaySuccess, displayError, displayInfo, displayWarning } from '../lib/prompts.js';\nimport fs from 'fs-extra';\nimport path from 'node:path';\nimport pc from 'picocolors';\nimport { EnhancementEngine } from '../core/enhancement-engine.js';\nimport { findLatestMigration, parseMigrationFile, validateMigrationPath } from '../core/migration-utils.js';\n\nexport interface EnhanceOptions {\n  file?: string;\n  project?: string;\n}\n\nexport async function enhanceCommand(options: EnhanceOptions, globalOptions: GlobalOptions): Promise<void> {\n  // Create a shared spinner instance for better performance\n  const spinner = createFlowSpinner();\n  \n  try {\n    const projectPath = options.project ? path.resolve(options.project) : process.cwd();\n    const cfg = await getFlowConfig(globalOptions, projectPath);\n    const envCfg = cfg.environments[cfg.defaultEnvironment];\n    const migrationsDir = envCfg.migrationsPath || './migrations';\n    const absoluteMigrationsDir = path.resolve(projectPath, migrationsDir);\n\n    let migrationFile = options.file;\n\n    // If no file specified, automatically operate on the latest migration file\n    if (!migrationFile) {\n      const latestFile = await findLatestMigration(absoluteMigrationsDir);\n      if (!latestFile) {\n        displayError('No migration files found', [`Directory: ${absoluteMigrationsDir}`]);\n        return;\n      }\n      migrationFile = latestFile;\n      displayInfo(`Operating on latest migration: ${pc.cyan(migrationFile)}`);\n    }\n\n    // Validate and resolve the migration file path\n    let filePath: string;\n    try {\n      filePath = await validateMigrationPath(migrationFile, absoluteMigrationsDir);\n    } catch (error) {\n      displayError('Migration file validation failed', [error instanceof Error ? error.message : 'Migration file not found']);\n      return;\n    }\n\n    // Parse the migration file with performance optimization\n    const loadSpinner = spinner.start('Loading migration file...');\n    let migration, engine;\n    \n    try {\n      [migration, engine] = await Promise.all([\n        parseMigrationFile(filePath),\n        new Promise(resolve => {\n          const eng = new EnhancementEngine();\n          resolve(eng);\n        })\n      ]);\n      loadSpinner.succeed('Migration file loaded successfully');\n    } catch (error) {\n      loadSpinner.fail('Failed to load migration file');\n      displayError('Parse error', [error instanceof Error ? error.message : 'Unknown error']);\n      return;\n    }\n\n    log.info(''); // Empty line for spacing\n    displayInfo(`üöÄ Starting Enhancement Process for ${pc.bold(migration.name)}`);\n    log.info(''); // Empty line for spacing\n\n    // Phase 1: Safety Enhancements\n    log.info(pc.bold(pc.blue('‚îÅ‚îÅ‚îÅ Phase 1: Safety Enhancements ‚îÅ‚îÅ‚îÅ')));\n    const safetySpinner = spinner.start('Scanning for safety issues...');\n    \n    try {\n      const safetyEnhancements = await (engine as any).detectSafetyEnhancements(migration);\n      \n      if (safetyEnhancements.length > 0) {\n        safetySpinner.succeed(`Found ${safetyEnhancements.length} safety issue(s)`);\n        \n        // List all safety issues with explanations\n        for (const enhancement of safetyEnhancements) {\n          const analysis = await (engine as any).getEnhancementAnalysis(enhancement.id, migration);\n          if (analysis && analysis.issues.length > 0) {\n            displayWarning(`${enhancement.name}`, [enhancement.description]);\n            for (const issue of analysis.issues) {\n              log.info(`    ${pc.red('‚ö†')} ${issue.description} ${pc.gray(`(line ${issue.line})`)}`);\n              log.info(`    ${pc.gray('‚Üí ' + issue.recommendation)}`);\n            }\n            log.info(''); // Spacing\n          } else {\n            displayInfo(`${enhancement.name}`, [enhancement.description]);\n          }\n        }\n        \n        // Ask user if they want to apply safety enhancements (default to Yes)\n        const applySafety = await confirm({\n          message: pc.cyan('Apply recommended safety enhancements?'),\n          initialValue: true,\n        });\n        \n        if (applySafety) {\n          const applySpinner = spinner.start('Applying safety enhancements...');\n          try {\n            const enhancedContent = await (engine as any).applyEnhancements(migration.up, migration, safetyEnhancements);\n            await fs.writeFile(filePath, enhancedContent, 'utf-8');\n            \n            // Update migration object for next phase\n            migration.up = enhancedContent;\n            \n            applySpinner.succeed('Safety enhancements applied successfully');\n            displaySuccess('Safety improvements completed', [`Applied ${safetyEnhancements.length} enhancement(s)`]);\n          } catch (error) {\n            applySpinner.fail('Failed to apply safety enhancements');\n            displayError('Enhancement error', [error instanceof Error ? error.message : 'Unknown error']);\n            return;\n          }\n        } else {\n          displayInfo('Skipping safety enhancements');\n        }\n      } else {\n        safetySpinner.succeed('No safety issues found - migration looks safe!');\n      }\n    } catch (error) {\n      safetySpinner.fail('Error during safety analysis');\n      displayError('Analysis failed', [error instanceof Error ? error.message : 'Unknown error']);\n      return;\n    }\n\n    log.info(''); // Empty line for spacing\n\n    // Phase 2: Speed Enhancements\n    log.info(pc.bold(pc.green('‚îÅ‚îÅ‚îÅ Phase 2: Speed Enhancements ‚îÅ‚îÅ‚îÅ')));\n    const speedSpinner = spinner.start('Analyzing performance optimization opportunities...');\n    \n    try {\n      const speedEnhancements = await (engine as any).detectSpeedEnhancements(migration);\n      \n      if (speedEnhancements.length > 0) {\n        speedSpinner.succeed(`Found ${speedEnhancements.length} optimization opportunity(ies)`);\n        \n        // List all speed optimization opportunities\n        for (const enhancement of speedEnhancements) {\n          const analysis = await (engine as any).getEnhancementAnalysis(enhancement.id, migration);\n          if (analysis && analysis.issues.length > 0) {\n            displayInfo(`${enhancement.name}`, [enhancement.description]);\n            for (const issue of analysis.issues) {\n              log.info(`    ${pc.yellow('‚ö°')} ${issue.description} ${pc.gray(`(line ${issue.line})`)}`);\n              log.info(`    ${pc.gray('‚Üí ' + issue.recommendation)}`);\n            }\n            log.info(''); // Spacing\n          } else {\n            displayInfo(`${enhancement.name}`, [enhancement.description]);\n          }\n        }\n        \n        // Ask user if they want to apply speed enhancements\n        const applySpeed = await confirm({\n          message: pc.cyan('Apply recommended speed enhancements?'),\n          initialValue: true,\n        });\n        \n        if (applySpeed) {\n          const applySpinner = spinner.start('Applying speed enhancements...');\n          try {\n            const enhancedContent = await (engine as any).applyEnhancements(migration.up, migration, speedEnhancements);\n            await fs.writeFile(filePath, enhancedContent, 'utf-8');\n            \n            applySpinner.succeed('Speed enhancements applied successfully');\n            displaySuccess('Performance optimizations completed', [`Applied ${speedEnhancements.length} enhancement(s)`]);\n          } catch (error) {\n            applySpinner.fail('Failed to apply speed enhancements');\n            displayError('Enhancement error', [error instanceof Error ? error.message : 'Unknown error']);\n            return;\n          }\n        } else {\n          displayInfo('Skipping speed enhancements');\n        }\n      } else {\n        speedSpinner.succeed('No speed optimizations found - migration is already optimized!');\n      }\n    } catch (error) {\n      speedSpinner.fail('Error during speed analysis');\n      displayError('Analysis failed', [error instanceof Error ? error.message : 'Unknown error']);\n      return;\n    }\n\n    log.info(''); // Empty line for spacing\n    displaySuccess('‚ú® Enhancement process completed successfully!', [\n      `Enhanced migration file: ${pc.cyan(path.relative(projectPath, filePath))}`\n    ]);\n    \n  } catch (error) {\n    displayError('Enhancement command failed', [error instanceof Error ? error.message : 'Unknown error']);\n  }\n}\n","\n/**\n * flow validate - Validate a migration file for safety and problems\n */\nimport { intro, outro } from '@clack/prompts';\nimport { getFlowConfig, GlobalOptions } from '../lib/config.js';\nimport { createSpinner } from '../lib/prompts.js';\nimport fs from 'fs-extra';\nimport path from 'node:path';\nimport pc from 'picocolors';\nimport { EnhancementEngine } from '../core/enhancement-engine.js';\n\nexport interface ValidateOptions {\n  file?: string;\n  project?: string;\n}\n\nexport async function validateCommand(options: ValidateOptions, globalOptions: GlobalOptions): Promise<void> {\n  const projectPath = options.project ? path.resolve(options.project) : process.cwd();\n  const cfg = await getFlowConfig(globalOptions, projectPath);\n  const envCfg = cfg.environments[cfg.defaultEnvironment];\n  const migrationsDir = envCfg.migrationsPath || './migrations';\n  const absoluteMigrationsDir = path.resolve(projectPath, migrationsDir);\n\n  let migrationFile = options.file;\n\n  if (!migrationFile) {\n    const files = await fs.readdir(absoluteMigrationsDir);\n    const migrationFiles = files.filter(file => file.endsWith('.sql')).sort();\n    if (migrationFiles.length === 0) {\n      console.log(pc.yellow('No migration files found.'));\n      return;\n    }\n    migrationFile = migrationFiles[migrationFiles.length - 1];\n  }\n\n  const filePath = path.join(absoluteMigrationsDir, migrationFile);\n  if (!await fs.pathExists(filePath)) {\n    console.log(pc.red(`File not found: ${filePath}`));\n    return;\n  }\n\n  const content = await fs.readFile(filePath, 'utf-8');\n  const engine = new EnhancementEngine();\n\n  intro('üîç Starting Validation Process');\n\n  const safetySpinner = createSpinner('Checking for safety issues...').start();\n  const safetyEnhancements = await engine.detectSafetyEnhancements({\n    path: filePath,\n    name: migrationFile,\n    up: content,\n    down: '',\n    timestamp: new Date(),\n    operations: [],\n    checksum: '',\n  });\n\n  if (safetyEnhancements.length > 0) {\n    safetySpinner.stop('üîç Safety issues found:');\n    safetyEnhancements.forEach(e => {\n      console.log(`  - ${pc.yellow(e.name)}: ${e.description}`);\n    });\n  } else {\n    safetySpinner.succeed('‚úÖ No safety issues found.');\n  }\n\n  outro('‚úÖ Validation complete.');\n}\n","\n/**\n * flow plan - Show what enhance would do to a file\n */\nimport { intro, outro } from '@clack/prompts';\nimport { getFlowConfig, GlobalOptions } from '../lib/config.js';\nimport { createSpinner } from '../lib/prompts.js';\nimport fs from 'fs-extra';\nimport path from 'node:path';\nimport pc from 'picocolors';\nimport { EnhancementEngine } from '../core/enhancement-engine.js';\nimport { diffChars } from 'diff';\n\nexport interface PlanOptions {\n  file?: string;\n  project?: string;\n}\n\nexport async function planCommand(options: PlanOptions, globalOptions: GlobalOptions): Promise<void> {\n  const projectPath = options.project ? path.resolve(options.project) : process.cwd();\n  const cfg = await getFlowConfig(globalOptions, projectPath);\n  const envCfg = cfg.environments[cfg.defaultEnvironment];\n  const migrationsDir = envCfg.migrationsPath || './migrations';\n  const absoluteMigrationsDir = path.resolve(projectPath, migrationsDir);\n\n  let migrationFile = options.file;\n\n  if (!migrationFile) {\n    const files = await fs.readdir(absoluteMigrationsDir);\n    const migrationFiles = files.filter(file => file.endsWith('.sql')).sort();\n    if (migrationFiles.length === 0) {\n      console.log(pc.yellow('No migration files found.'));\n      return;\n    }\n    migrationFile = migrationFiles[migrationFiles.length - 1];\n  }\n\n  const filePath = path.join(absoluteMigrationsDir, migrationFile);\n  if (!await fs.pathExists(filePath)) {\n    console.log(pc.red(`File not found: ${filePath}`));\n    return;\n  }\n\n  const content = await fs.readFile(filePath, 'utf-8');\n  const engine = new EnhancementEngine();\n\n  intro('üìù Planning Enhancement');\n\n  const migration = {\n    path: filePath,\n    name: migrationFile,\n    up: content,\n    down: '',\n    timestamp: new Date(),\n    operations: [],\n    checksum: '',\n  };\n\n  const safetyEnhancements = await engine.detectSafetyEnhancements(migration);\n  const speedEnhancements = await engine.detectSpeedEnhancements(migration);\n\n  const allEnhancements = [...safetyEnhancements, ...speedEnhancements];\n\n  if (allEnhancements.length > 0) {\n    const newContent = await engine.applyEnhancements(content, migration, allEnhancements);\n    const diff = diffChars(content, newContent);\n\n    console.log(pc.bold(`\nChanges for ${migrationFile}:\n`));\n\n    diff.forEach(part => {\n      const color = part.added ? pc.green : part.removed ? pc.red : pc.gray;\n      process.stdout.write(color(part.value));\n    });\n\n    console.log();\n  } else {\n    console.log(pc.green('‚úÖ No enhancements to apply.'));\n  }\n\n  outro('üìù Plan complete.');\n}\n","\n/**\n * flow rollback - Generate a script to undo a migration\n */\nimport { intro, outro } from '@clack/prompts';\nimport { getFlowConfig, GlobalOptions } from '../lib/config.js';\nimport { createSpinner } from '../lib/prompts.js';\nimport fs from 'fs-extra';\nimport path from 'node:path';\nimport pc from 'picocolors';\nimport { EnhancementEngine } from '../core/enhancement-engine.js';\n\nexport interface RollbackOptions {\n  file?: string;\n  project?: string;\n}\n\nexport async function rollbackCommand(options: RollbackOptions, globalOptions: GlobalOptions): Promise<void> {\n  const projectPath = options.project ? path.resolve(options.project) : process.cwd();\n  const cfg = await getFlowConfig(globalOptions, projectPath);\n  const envCfg = cfg.environments[cfg.defaultEnvironment];\n  const migrationsDir = envCfg.migrationsPath || './migrations';\n  const absoluteMigrationsDir = path.resolve(projectPath, migrationsDir);\n\n  let migrationFile = options.file;\n\n  if (!migrationFile) {\n    const files = await fs.readdir(absoluteMigrationsDir);\n    const migrationFiles = files.filter(file => file.endsWith('.sql')).sort();\n    if (migrationFiles.length === 0) {\n      console.log(pc.yellow('No migration files found.'));\n      return;\n    }\n    migrationFile = migrationFiles[migrationFiles.length - 1];\n  }\n\n  const filePath = path.join(absoluteMigrationsDir, migrationFile);\n  if (!await fs.pathExists(filePath)) {\n    console.log(pc.red(`File not found: ${filePath}`));\n    return;\n  }\n\n  const content = await fs.readFile(filePath, 'utf-8');\n  const engine = new EnhancementEngine();\n\n  intro('‚è™ Generating Rollback Script');\n\n  const rollbackScript = await engine.generateRollback({\n    path: filePath,\n    name: migrationFile,\n    up: content,\n    down: '',\n    timestamp: new Date(),\n    operations: [],\n    checksum: '',\n  });\n\n  console.log(pc.bold(`\nRollback script for ${migrationFile}:\n`));\n  console.log(pc.cyan(rollbackScript));\n\n  outro('‚è™ Rollback script generated.');\n}\n","/**\n * Common types used across DriftJS packages\n */\n\nexport type DatabaseType = 'postgresql' | 'mysql' | 'sqlite' | 'mariadb'\nexport type ORMType = 'prisma' | 'drizzle' | 'typeorm'\n\n/**\n * Generic result type for operations that can fail\n */\nexport type Result<T, E = Error> = \n  | { success: true; data: T }\n  | { success: false; error: E }\n\n/**\n * Configuration for database connection\n */\nexport interface DatabaseConfig {\n  type: DatabaseType\n  host?: string\n  port?: number\n  database: string\n  username?: string\n  password?: string\n  url?: string\n  ssl?: boolean | object\n}\n\n/**\n * File path utilities\n */\nexport interface FilePath {\n  absolute: string\n  relative: string\n  exists: boolean\n}\n\n/**\n * Detection result for file/directory analysis\n */\nexport interface DetectionResult {\n  found: boolean\n  confidence: number // 0-1 score\n  evidence: string[]\n  warnings?: string[]\n}\n\n/**\n * Base configuration interface\n */\nexport interface BaseConfig {\n  version: string\n  verbose?: boolean\n  dryRun?: boolean\n} ","/**\n * ORM-specific types and interfaces\n */\n\nimport { DatabaseConfig, FilePath, DetectionResult } from './common.js'\n\n/**\n * ORM detection and configuration\n */\nexport interface ORMConfig {\n  type: string\n  version?: string\n  configFile?: FilePath\n  migrationDirectory: FilePath\n  schemaFile?: FilePath\n  dependencies: string[]\n}\n\n/**\n * ORM detector interface - implemented by each ORM detector\n */\nexport interface ORMDetector {\n  name: string\n  detect(projectPath: string): Promise<DetectionResult>\n  extractConfig(projectPath: string): Promise<ORMConfig | null>\n  getDatabaseConfig(projectPath: string): Promise<DatabaseConfig | null>\n}\n\n/**\n * Prisma-specific configuration\n */\nexport interface PrismaConfig extends ORMConfig {\n  type: 'prisma'\n  schemaFile: FilePath\n  clientGenerator?: {\n    provider: string\n    output?: string\n  }\n}\n\n/**\n * Drizzle-specific configuration\n */\nexport interface DrizzleConfig extends ORMConfig {\n  type: 'drizzle'\n  configFile: FilePath\n  driver: 'pg' | 'mysql2' | 'better-sqlite3' | 'sqlite'\n  schemaPath: string\n  outDir: string\n}\n\n/**\n * TypeORM-specific configuration  \n */\nexport interface TypeORMConfig extends ORMConfig {\n  type: 'typeorm'\n  entities: string[]\n  migrations: string[]\n  subscribers?: string[]\n  cli?: {\n    migrationsDir: string\n    entitiesDir: string\n  }\n} ","/**\n * Database analysis and connection types\n */\n\nimport { DatabaseType } from './common.js'\n\n/**\n * Database connection interface\n */\nexport interface DatabaseConnection {\n  type: DatabaseType\n  isConnected: boolean\n  connect(): Promise<void>\n  disconnect(): Promise<void>\n  query<T = any>(sql: string, params?: any[]): Promise<T[]>\n  transaction<T>(callback: (connection: DatabaseConnection) => Promise<T>): Promise<T>\n}\n\n/**\n * Table metadata from database analysis\n */\nexport interface TableMetadata {\n  name: string\n  schema?: string\n  rowCount: number\n  sizeBytes: number\n  columns: ColumnMetadata[]\n  indexes: IndexMetadata[]\n  constraints: ConstraintMetadata[]\n  dependencies: TableDependency[]\n}\n\n/**\n * Column metadata\n */\nexport interface ColumnMetadata {\n  name: string\n  type: string\n  nullable: boolean\n  defaultValue?: any\n  isPrimary: boolean\n  isUnique: boolean\n  references?: {\n    table: string\n    column: string\n  }\n}\n\n/**\n * Index metadata\n */\nexport interface IndexMetadata {\n  name: string\n  columns: string[]\n  unique: boolean\n  type: string\n  sizeBytes?: number\n}\n\n/**\n * Constraint metadata\n */\nexport interface ConstraintMetadata {\n  name: string\n  type: 'PRIMARY KEY' | 'FOREIGN KEY' | 'UNIQUE' | 'CHECK'\n  columns: string[]\n  referencedTable?: string\n  referencedColumns?: string[]\n  definition?: string\n}\n\n/**\n * Table dependency information\n */\nexport interface TableDependency {\n  table: string\n  dependsOn: string[]\n  dependedOnBy: string[]\n}\n\n/**\n * Database analysis result\n */\nexport interface DatabaseAnalysis {\n  tables: TableMetadata[]\n  totalSize: number\n  version: string\n  features: string[]\n  performance: {\n    avgQueryTime: number\n    connectionCount: number\n    cacheHitRatio?: number\n  }\n} ","/**\n * Migration analysis and enhancement types\n */\n\nimport { DatabaseType } from './common.js'\n\n/**\n * Parsed migration operation\n */\nexport interface MigrationOperation {\n  type: OperationType\n  table?: string\n  column?: string\n  sql: string\n  metadata: OperationMetadata\n  risks: RiskAssessment[]\n  estimatedDuration?: number\n}\n\n/**\n * Types of migration operations\n */\nexport type OperationType = \n  | 'CREATE_TABLE'\n  | 'DROP_TABLE'\n  | 'ADD_COLUMN'\n  | 'DROP_COLUMN'\n  | 'ALTER_COLUMN'\n  | 'RENAME_COLUMN'\n  | 'ADD_INDEX'\n  | 'DROP_INDEX'\n  | 'ADD_CONSTRAINT'\n  | 'DROP_CONSTRAINT'\n  | 'RAW_SQL'\n\n/**\n * Operation metadata for analysis\n */\nexport interface OperationMetadata {\n  affectedRows?: number\n  lockLevel: 'NONE' | 'SHARED' | 'EXCLUSIVE'\n  reversible: boolean\n  dataLoss: boolean\n  performance: 'LOW' | 'MEDIUM' | 'HIGH'\n}\n\n/**\n * Risk assessment for operations\n */\nexport interface RiskAssessment {\n  level: 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL'\n  category: RiskCategory\n  description: string\n  mitigation?: string\n}\n\n/**\n * Risk categories\n */\nexport type RiskCategory = \n  | 'DATA_LOSS'\n  | 'DOWNTIME'\n  | 'PERFORMANCE'\n  | 'CONSTRAINT_VIOLATION'\n  | 'LOCK_TIMEOUT'\n  | 'DISK_SPACE'\n\n/**\n * Migration file representation\n */\nexport interface MigrationFile {\n  path: string\n  name: string\n  timestamp: Date\n  operations: MigrationOperation[]\n  up: string\n  down?: string\n  checksum: string\n}\n\n/**\n * Enhanced migration with safety features\n */\nexport interface EnhancedMigration {\n  original: MigrationFile\n  enhanced: {\n    up: string\n    down: string\n    preFlightChecks: string[]\n    postMigrationValidation: string[]\n    rollbackStrategy: string[]\n  }\n  estimatedDuration: number\n  maintenanceWindow?: {\n    required: boolean\n    estimatedMinutes: number\n  }\n}\n\n/**\n * Migration enhancement strategy\n */\nexport interface EnhancementStrategy {\n  name: string\n  description: string\n  applies: (operation: MigrationOperation, context: MigrationContext) => boolean\n  enhance: (operation: MigrationOperation, context: MigrationContext) => MigrationOperation[]\n  risks: RiskAssessment[]\n}\n\n/**\n * Context for migration enhancement\n */\nexport interface MigrationContext {\n  database: DatabaseType\n  tableSize?: number\n  hasData: boolean\n  indexes: string[]\n  constraints: string[]\n  dependencies: string[]\n} ","export interface FlowConfig {\n  /**\n   * Version of configuration schema, useful for migrations\n   */\n  version?: string\n  /**\n   * List of environments (e.g. development, staging, production)\n   */\n  environments: Record<string, EnvironmentConfig>\n  /**\n   * Name of the default environment to use when none is specified\n   */\n  defaultEnvironment: string\n  /**\n   * Safety thresholds that control when Drift Flow will warn or abort\n   */\n  safety: SafetyThresholds\n  /**\n   * Database-specific optimisation settings keyed by connection name\n   */\n  database: Record<string, DatabaseOptimisationSettings>\n  /**\n   * Optional team collaboration configuration\n   */\n  teams?: TeamSettings\n}\n\n/**\n * Environment-level configuration overrides\n */\nexport interface EnvironmentConfig {\n  /** The database connection string for this environment */\n  databaseUrl: string\n  /** Relative or absolute path to the migrations directory */\n  migrationsPath?: string\n  /** Pattern toggles allowing specific categories to be disabled */\n  patterns?: PatternToggles\n}\n\n/** Safety/operational limits  */\nexport interface SafetyThresholds {\n  /** Cancel operations that would lock a table for longer than this */\n  maxLockTimeMs?: number\n  /** Abort when table size exceeds this value (in MB) for destructive operations */\n  maxTableSizeMB?: number\n  /** Stop when estimated duration is above this */\n  maxOperationDurationMs?: number\n}\n\n/** DB optimisation knobs */\nexport interface DatabaseOptimisationSettings {\n  type: import('./common.js').DatabaseType\n  statementTimeoutMs?: number\n  lockTimeoutMs?: number\n  /** PostgreSQL parallel workers, MySQL equivalent, etc. */\n  maxParallelWorkers?: number\n}\n\n/** Collaboration / approvals  */\nexport interface TeamSettings {\n  approvers: string[]\n  requireCodeReview: boolean\n  slackWebhookUrl?: string\n}\n\n/** Enable/disable categories of patterns */\nexport interface PatternToggles {\n  column?: boolean\n  constraint?: boolean\n  index?: boolean\n} ","// Core type definitions for DriftJS\nexport * from './common.js'\nexport * from './orm.js'\nexport * from './database.js'\nexport * from './migration.js'\nexport * from './config.js' ","/**\n * File system utilities for DriftJS\n */\n\nimport fs from 'fs-extra'\nconst { readFile, writeFile, access, stat, readdir } = fs\nimport { join, resolve, relative, dirname } from 'path'\nimport { FilePath, Result } from '../types/common.js'\n\n/**\n * Check if a file or directory exists\n */\nexport async function exists(path: string): Promise<boolean> {\n  try {\n    await access(path)\n    return true\n  } catch {\n    return false\n  }\n}\n\n/**\n * Create a FilePath object with absolute and relative paths\n */\nexport async function createFilePath(path: string, basePath: string = process.cwd()): Promise<FilePath> {\n  const absolutePath = resolve(basePath, path)\n  const relativePath = relative(basePath, absolutePath)\n  const fileExists = await exists(absolutePath)\n  \n  return {\n    absolute: absolutePath,\n    relative: relativePath,\n    exists: fileExists\n  }\n}\n\n/**\n * Read file content with error handling\n */\nexport async function readFileContent(path: string): Promise<Result<string>> {\n  try {\n    const content = await readFile(path, 'utf-8')\n    return { success: true, data: content }\n  } catch (error) {\n    return { \n      success: false, \n      error: error instanceof Error ? error : new Error('Unknown error reading file')\n    }\n  }\n}\n\n/**\n * Write file content with error handling\n */\nexport async function writeFileContent(path: string, content: string): Promise<Result<void>> {\n  try {\n    await writeFile(path, content, 'utf-8')\n    return { success: true, data: undefined }\n  } catch (error) {\n    return { \n      success: false, \n      error: error instanceof Error ? error : new Error('Unknown error writing file')\n    }\n  }\n}\n\n/**\n * Get file statistics\n */\nexport async function getFileStats(path: string): Promise<Result<{ size: number; modified: Date; isDirectory: boolean }>> {\n  try {\n    const stats = await stat(path)\n    return {\n      success: true,\n      data: {\n        size: stats.size,\n        modified: stats.mtime,\n        isDirectory: stats.isDirectory()\n      }\n    }\n  } catch (error) {\n    return {\n      success: false,\n      error: error instanceof Error ? error : new Error('Unknown error getting file stats')\n    }\n  }\n}\n\n/**\n * Find files matching a pattern in a directory\n */\nexport async function findFiles(\n  directory: string,\n  pattern: RegExp,\n  recursive: boolean = true\n): Promise<string[]> {\n  const files: string[] = []\n  \n  try {\n    const items = await readdir(directory, { withFileTypes: true })\n    \n    for (const item of items) {\n      const fullPath = join(directory, item.name)\n      \n      if (item.isDirectory() && recursive) {\n        const subFiles = await findFiles(fullPath, pattern, recursive)\n        files.push(...subFiles)\n      } else if (item.isFile() && pattern.test(item.name)) {\n        files.push(fullPath)\n      }\n    }\n  } catch {\n    // Directory doesn't exist or can't be read\n  }\n  \n  return files\n}\n\n/**\n * Check if a directory contains any files matching a pattern\n */\nexport async function hasFilesMatching(directory: string, pattern: RegExp): Promise<boolean> {\n  const files = await findFiles(directory, pattern, false)\n  return files.length > 0\n}\n\n/**\n * Parse JSON file with error handling\n */\nexport async function readJsonFile<T = any>(path: string): Promise<Result<T>> {\n  const fileResult = await readFileContent(path)\n  \n  if (!fileResult.success) {\n    return fileResult\n  }\n  \n  try {\n    const data = JSON.parse(fileResult.data)\n    return { success: true, data }\n  } catch (error) {\n    return {\n      success: false,\n      error: new Error(`Invalid JSON in file ${path}: ${error instanceof Error ? error.message : 'Unknown error'}`)\n    }\n  }\n} ","/**\n * Async utilities for DriftJS\n */\n\nimport { Result } from '../types/common.js'\n\n/**\n * Retry a function with exponential backoff\n */\nexport async function retry<T>(\n  fn: () => Promise<T>,\n  options: {\n    maxAttempts: number\n    delay: number\n    backoff: number\n  } = { maxAttempts: 3, delay: 1000, backoff: 2 }\n): Promise<T> {\n  let lastError: Error\n  \n  for (let attempt = 1; attempt <= options.maxAttempts; attempt++) {\n    try {\n      return await fn()\n    } catch (error) {\n      lastError = error instanceof Error ? error : new Error('Unknown error')\n      \n      if (attempt === options.maxAttempts) {\n        throw lastError\n      }\n      \n      const delay = options.delay * Math.pow(options.backoff, attempt - 1)\n      await sleep(delay)\n    }\n  }\n  \n  throw lastError!\n}\n\n/**\n * Sleep for a specified number of milliseconds\n */\nexport function sleep(ms: number): Promise<void> {\n  return new Promise(resolve => setTimeout(resolve, ms))\n}\n\n/**\n * Timeout wrapper for promises\n */\nexport async function withTimeout<T>(\n  promise: Promise<T>,\n  timeoutMs: number,\n  timeoutMessage = 'Operation timed out'\n): Promise<T> {\n  const timeoutPromise = new Promise<never>((_, reject) => {\n    setTimeout(() => reject(new Error(timeoutMessage)), timeoutMs)\n  })\n  \n  return Promise.race([promise, timeoutPromise])\n}\n\n/**\n * Execute functions in parallel with concurrency limit\n */\nexport async function parallelLimit<T, R>(\n  items: T[],\n  fn: (item: T) => Promise<R>,\n  limit: number = 10\n): Promise<R[]> {\n  const results: R[] = []\n  const executing: Promise<void>[] = []\n  \n  for (const item of items) {\n    const promise = fn(item).then(result => {\n      results.push(result)\n    })\n    \n    executing.push(promise)\n    \n    if (executing.length >= limit) {\n      await Promise.race(executing)\n      executing.splice(executing.findIndex(p => p === promise), 1)\n    }\n  }\n  \n  await Promise.all(executing)\n  return results\n}\n\n/**\n * Convert callback-style function to promise\n */\nexport function promisify<T>(\n  fn: (callback: (error: Error | null, result?: T) => void) => void\n): Promise<T> {\n  return new Promise((resolve, reject) => {\n    fn((error, result) => {\n      if (error) {\n        reject(error)\n      } else {\n        resolve(result!)\n      }\n    })\n  })\n}\n\n/**\n * Safe async function wrapper that returns Result type\n */\nexport async function safeAsync<T>(\n  fn: () => Promise<T>\n): Promise<Result<T>> {\n  try {\n    const data = await fn()\n    return { success: true, data }\n  } catch (error) {\n    return {\n      success: false,\n      error: error instanceof Error ? error : new Error('Unknown error')\n    }\n  }\n} ","/**\n * Validation utilities for DriftJS\n */\n\nimport { DatabaseConfig, DatabaseType } from '../types/common.js'\n\n/**\n * Validate database configuration\n */\nexport function validateDatabaseConfig(config: Partial<DatabaseConfig>): { valid: boolean; errors: string[] } {\n  const errors: string[] = []\n  \n  if (!config.type) {\n    errors.push('Database type is required')\n  } else if (!isValidDatabaseType(config.type)) {\n    errors.push(`Invalid database type: ${config.type}`)\n  }\n  \n  if (!config.database) {\n    errors.push('Database name is required')\n  }\n  \n  if (config.url) {\n    if (!isValidConnectionString(config.url)) {\n      errors.push('Invalid database connection string')\n    }\n  } else {\n    if (!config.host) {\n      errors.push('Database host is required when not using connection string')\n    }\n    \n    if (config.port && (config.port < 1 || config.port > 65535)) {\n      errors.push('Invalid port number')\n    }\n  }\n  \n  return { valid: errors.length === 0, errors }\n}\n\n/**\n * Check if a string is a valid database type\n */\nexport function isValidDatabaseType(type: string): type is DatabaseType {\n  return ['postgresql', 'mysql', 'sqlite', 'mariadb'].includes(type)\n}\n\n/**\n * Basic validation for database connection strings\n */\nexport function isValidConnectionString(url: string): boolean {\n  try {\n    const parsed = new URL(url)\n    return ['postgresql:', 'postgres:', 'mysql:', 'sqlite:'].includes(parsed.protocol)\n  } catch {\n    return false\n  }\n}\n\n/**\n * Validate file path\n */\nexport function isValidFilePath(path: string): boolean {\n  if (!path || typeof path !== 'string') {\n    return false\n  }\n  \n  // Check for invalid characters\n  const invalidChars = /[<>:\"|?*]/\n  if (invalidChars.test(path)) {\n    return false\n  }\n  \n  return true\n}\n\n/**\n * Validate version string (semver-like)\n */\nexport function isValidVersion(version: string): boolean {\n  const semverRegex = /^\\d+\\.\\d+\\.\\d+(?:-[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)*)?(?:\\+[a-zA-Z0-9-]+(?:\\.[a-zA-Z0-9-]+)*)?$/\n  return semverRegex.test(version)\n}\n\n/**\n * Sanitize user input\n */\nexport function sanitizeInput(input: string): string {\n  return input\n    .replace(/[<>]/g, '') // Remove potential HTML tags\n    .replace(/[\\x00-\\x1f\\x7f]/g, '') // Remove control characters\n    .trim()\n}\n\n/**\n * Validate SQL identifier (table/column names)\n */\nexport function isValidSQLIdentifier(identifier: string): boolean {\n  if (!identifier || typeof identifier !== 'string') {\n    return false\n  }\n  \n  // SQL identifier rules: start with letter or underscore, followed by letters, digits, or underscores\n  const identifierRegex = /^[a-zA-Z_][a-zA-Z0-9_]*$/\n  return identifierRegex.test(identifier) && identifier.length <= 63 // PostgreSQL limit\n} ","import fs from 'fs-extra'\nimport path from 'node:path'\nimport { FlowConfig } from '../types/config.js'\nimport { validateDatabaseConfig } from './validation.js'\n\n/**\n * Default file names that Drift Flow will look for when no --config flag is passed.\n */\nconst DEFAULT_CONFIG_FILES = [\n  'flow.config.json',\n  'flow.config.js',\n  'flow.config.cjs',\n  'flow.config.mjs',\n  'flow.config.ts',\n]\n\n/**\n * Load the first configuration file found in the current working directory hierarchy.\n * @param cwd Directory to start the search from (defaults to process.cwd())\n * @param explicitPath Optional explicit path passed by CLI flag\n */\nexport async function loadFlowConfig(\n  cwd: string = process.cwd(),\n  explicitPath?: string,\n): Promise<FlowConfig> {\n  let configPath: string | undefined = explicitPath\n\n  if (!configPath) {\n    configPath = await findConfigFile(cwd)\n    if (!configPath) {\n      throw new Error('Unable to locate flow.config file in current directory tree.')\n    }\n  }\n\n  const ext = path.extname(configPath)\n  let raw: unknown\n\n  if (ext === '.json') {\n    raw = await fs.readJSON(configPath)\n  } else if (ext === '.js' || ext === '.cjs' || ext === '.mjs') {\n    // eslint-disable-next-line import/no-dynamic-require, @typescript-eslint/no-var-requires\n    raw = await import(configPath)\n    raw = (raw as any).default ?? raw\n  } else if (ext === '.ts') {\n    throw new Error('Loading TypeScript config files is not yet supported. Please use JSON or JavaScript.')\n  } else {\n    throw new Error(`Unsupported config file extension: ${ext}`)\n  }\n\n  const validated = validateFlowConfig(raw)\n  if (!validated.valid) {\n    throw new Error(`Invalid flow.config: \\n${validated.errors.join('\\n')}`)\n  }\n\n  return validated.config!\n}\n\n/** Find the nearest config file walking up the directory tree */\nasync function findConfigFile(startDir: string): Promise<string | undefined> {\n  let dir = startDir\n  while (path.dirname(dir) !== dir) {\n    for (const file of DEFAULT_CONFIG_FILES) {\n      const candidate = path.join(dir, file)\n      if (await fs.pathExists(candidate)) {\n        return candidate\n      }\n    }\n    dir = path.dirname(dir)\n  }\n  return undefined\n}\n\nexport interface ValidationResult {\n  valid: boolean\n  errors: string[]\n  config?: FlowConfig\n}\n\n/**\n * Perform structural validation of FlowConfig instance.\n * We purposefully avoid pulling in a JSON-schema validator to keep deps light.\n */\nexport function validateFlowConfig(input: unknown): ValidationResult {\n  if (typeof input !== 'object' || input === null) {\n    return { valid: false, errors: ['Configuration must be an object'] }\n  }\n  const cfg = input as Partial<FlowConfig>\n  const errors: string[] = []\n\n  if (!cfg.environments || Object.keys(cfg.environments).length === 0) {\n    errors.push('`environments` section is required and cannot be empty')\n  }\n  if (!cfg.defaultEnvironment) {\n    errors.push('`defaultEnvironment` is required')\n  } else if (cfg.environments && !(cfg.defaultEnvironment in cfg.environments)) {\n    errors.push(`defaultEnvironment \\`${cfg.defaultEnvironment}\\` not found in environments section`)\n  }\n\n  // Validate each environment\n  if (cfg.environments) {\n    for (const [envName, envCfg] of Object.entries(cfg.environments)) {\n      if (!envCfg.databaseUrl) {\n        errors.push(`environment[${envName}].databaseUrl is required`)\n      }\n      if (envCfg.migrationsPath && typeof envCfg.migrationsPath !== 'string') {\n        errors.push(`environment[${envName}].migrationsPath must be a string`)\n      }\n      if (envCfg.migrationsPath) {\n        const absPath = path.isAbsolute(envCfg.migrationsPath)\n          ? envCfg.migrationsPath\n          : path.join(process.cwd(), envCfg.migrationsPath)\n        if (!(fs.existsSync(absPath))) {\n          errors.push(`environment[${envName}].migrationsPath '${envCfg.migrationsPath}' does not exist`)\n        }\n      }\n      // pattern toggles validation\n      if (envCfg.patterns) {\n        if (typeof envCfg.patterns !== 'object') {\n          errors.push(`environment[${envName}].patterns must be an object`)\n        }\n      }\n    }\n  }\n\n  // Validate safety thresholds\n  if (cfg.safety) {\n    if (cfg.safety.maxLockTimeMs && cfg.safety.maxLockTimeMs < 0) {\n      errors.push('safety.maxLockTimeMs must be positive')\n    }\n    if (cfg.safety.maxTableSizeMB && cfg.safety.maxTableSizeMB < 0) {\n      errors.push('safety.maxTableSizeMB must be positive')\n    }\n  }\n\n  // Validate database optimisation settings\n  if (cfg.database) {\n    for (const [name, dbCfg] of Object.entries(cfg.database)) {\n      const { valid, errors: dbErrors } = validateDatabaseConfig(dbCfg as any)\n      if (!valid) {\n        errors.push(...dbErrors.map((e) => `database[${name}]: ${e}`))\n      }\n    }\n  }\n\n  return { valid: errors.length === 0, errors, config: cfg as FlowConfig }\n} ","// Core utility functions for DriftJS\nexport * from './file-utils.js'\nexport * from './async-utils.js'\nexport * from './validation.js'\nexport * from './config.js' ","// Core shared types and utilities for DriftJS\nexport * from './types/index.js'\nexport * from './utils/index.js' ","/**\n * Base ORM detector with common functionality\n */\n\nimport { join } from 'path'\nimport { ORMDetector, ORMConfig } from '../../core/index.js'\nimport { DatabaseConfig, DetectionResult, FilePath } from '../../core/index.js'\nimport { exists, createFilePath, readJsonFile, findFiles } from '../../core/index.js'\n\nexport abstract class BaseORMDetector implements ORMDetector {\n  abstract name: string\n  \n  /**\n   * Detect if this ORM is present in the project\n   */\n  abstract detect(projectPath: string): Promise<DetectionResult>\n  \n  /**\n   * Extract ORM-specific configuration\n   */\n  abstract extractConfig(projectPath: string): Promise<ORMConfig | null>\n  \n  /**\n   * Extract database configuration from ORM setup\n   */\n  abstract getDatabaseConfig(projectPath: string): Promise<DatabaseConfig | null>\n  \n  /**\n   * Common helper: Check if package.json contains specific dependencies\n   */\n  protected async checkPackageJsonDependencies(\n    projectPath: string,\n    dependencies: string[]\n  ): Promise<{ found: string[]; missing: string[] }> {\n    const packageJsonPath = join(projectPath, 'package.json')\n    const packageResult = await readJsonFile<{ dependencies?: Record<string, string>; devDependencies?: Record<string, string> }>(packageJsonPath)\n    \n    if (!packageResult.success) {\n      return { found: [], missing: dependencies }\n    }\n    \n    const allDeps = {\n      ...packageResult.data.dependencies,\n      ...packageResult.data.devDependencies\n    }\n    \n    const found = dependencies.filter(dep => dep in allDeps)\n    const missing = dependencies.filter(dep => !(dep in allDeps))\n    \n    return { found, missing }\n  }\n  \n  /**\n   * Common helper: Check if specific files exist\n   */\n  protected async checkFiles(\n    projectPath: string,\n    filePaths: string[]\n  ): Promise<{ existing: FilePath[]; missing: string[] }> {\n    const existing: FilePath[] = []\n    const missing: string[] = []\n    \n    for (const filePath of filePaths) {\n      const fullPath = join(projectPath, filePath)\n      const fileExists = await exists(fullPath)\n      \n      if (fileExists) {\n        existing.push(await createFilePath(filePath, projectPath))\n      } else {\n        missing.push(filePath)\n      }\n    }\n    \n    return { existing, missing }\n  }\n  \n  /**\n   * Common helper: Find files matching patterns\n   */\n  protected async findFilesByPattern(\n    projectPath: string,\n    patterns: RegExp[],\n    directories: string[] = ['.']\n  ): Promise<string[]> {\n    const allFiles: string[] = []\n    \n    for (const directory of directories) {\n      const fullDirectory = join(projectPath, directory)\n      \n      for (const pattern of patterns) {\n        const files = await findFiles(fullDirectory, pattern, true)\n        allFiles.push(...files)\n      }\n    }\n    \n    return allFiles\n  }\n  \n  /**\n   * Common helper: Calculate confidence score based on evidence\n   */\n  protected calculateConfidence(evidence: {\n    required: { found: number; total: number }\n    optional: { found: number; total: number }\n    negative: number\n  }): number {\n    if (evidence.required.total === 0) {\n      return 0\n    }\n    \n    const requiredScore = evidence.required.found / evidence.required.total\n    const optionalScore = evidence.optional.total > 0 \n      ? evidence.optional.found / evidence.optional.total \n      : 0\n    \n    // Base score from required items (70% weight)\n    const baseScore = requiredScore * 0.7\n    \n    // Bonus from optional items (30% weight)\n    const bonusScore = optionalScore * 0.3\n    \n    // Penalty for negative evidence\n    const penalty = Math.min(evidence.negative * 0.1, 0.5)\n    \n    return Math.max(0, Math.min(1, baseScore + bonusScore - penalty))\n  }\n  \n  /**\n   * Parse database URL into DatabaseConfig\n   */\n  protected parseDatabaseUrl(url: string): DatabaseConfig | null {\n    try {\n      const parsed = new URL(url)\n      \n      let type: DatabaseConfig['type']\n      \n      switch (parsed.protocol) {\n        case 'postgresql:':\n        case 'postgres:':\n          type = 'postgresql'\n          break\n        case 'mysql:':\n          type = 'mysql'\n          break\n        case 'sqlite:':\n          type = 'sqlite'\n          break\n        default:\n          return null\n      }\n      \n      return {\n        type,\n        host: parsed.hostname || undefined,\n        port: parsed.port ? parseInt(parsed.port) : undefined,\n        database: parsed.pathname.slice(1), // Remove leading slash\n        username: parsed.username || undefined,\n        password: parsed.password || undefined,\n        url\n      }\n    } catch {\n      return null\n    }\n  }\n} ","/**\n * Prisma ORM detector implementation\n */\n\nimport { join } from 'path'\nimport { BaseORMDetector } from './base-detector.js'\nimport { PrismaConfig } from '../../core/index.js'\nimport { DatabaseConfig, DetectionResult } from '../../core/index.js'\nimport { readFileContent, createFilePath } from '../../core/index.js'\n\nexport class PrismaDetector extends BaseORMDetector {\n  name = 'prisma'\n  \n  /**\n   * Detect Prisma in the project\n   */\n  async detect(projectPath: string): Promise<DetectionResult> {\n    const evidence: string[] = []\n    const warnings: string[] = []\n    \n    // Check for Prisma dependencies\n    const { found: foundDeps, missing: missingDeps } = await this.checkPackageJsonDependencies(\n      projectPath,\n      ['prisma', '@prisma/client']\n    )\n    \n    evidence.push(...foundDeps.map(dep => `Found dependency: ${dep}`))\n    \n    // Check for Prisma schema file\n    const { existing: schemaFiles } = await this.checkFiles(projectPath, [\n      'prisma/schema.prisma',\n      'schema.prisma'\n    ])\n    \n    if (schemaFiles.length > 0) {\n      evidence.push(`Found schema file: ${schemaFiles[0].relative}`)\n    }\n    \n    // Check for migration directory\n    const { existing: migrationDirs } = await this.checkFiles(projectPath, [\n      'prisma/migrations'\n    ])\n    \n    if (migrationDirs.length > 0) {\n      evidence.push(`Found migrations directory: ${migrationDirs[0].relative}`)\n    }\n    \n    // Look for generated Prisma client\n    const generatedFiles = await this.findFilesByPattern(\n      projectPath,\n      [/node_modules\\/@prisma\\/client/],\n      ['node_modules']\n    )\n    \n    if (generatedFiles.length > 0) {\n      evidence.push('Found generated Prisma client')\n    }\n    \n    // Calculate confidence\n    const confidence = this.calculateConfidence({\n      required: { found: foundDeps.length, total: 2 }, // prisma + @prisma/client\n      optional: { found: schemaFiles.length + migrationDirs.length, total: 2 },\n      negative: 0\n    })\n    \n    // Add warnings for incomplete setup\n    if (foundDeps.length > 0 && schemaFiles.length === 0) {\n      warnings.push('Prisma dependency found but no schema.prisma file detected')\n    }\n    \n    if (schemaFiles.length > 0 && !foundDeps.includes('@prisma/client')) {\n      warnings.push('Schema file found but @prisma/client not installed')\n    }\n    \n    return {\n      found: confidence > 0.5,\n      confidence,\n      evidence,\n      warnings: warnings.length > 0 ? warnings : undefined\n    }\n  }\n  \n  /**\n   * Extract Prisma configuration\n   */\n  async extractConfig(projectPath: string): Promise<PrismaConfig | null> {\n    // Find schema file\n    const { existing: schemaFiles } = await this.checkFiles(projectPath, [\n      'prisma/schema.prisma',\n      'schema.prisma'\n    ])\n    \n    if (schemaFiles.length === 0) {\n      return null\n    }\n    \n    const schemaFile = schemaFiles[0]\n    const migrationDirectory = await createFilePath('prisma/migrations', projectPath)\n    \n    // Parse schema file for generator and database info\n    const schemaResult = await readFileContent(schemaFile.absolute)\n    if (!schemaResult.success) {\n      return null\n    }\n    \n    // Extract client generator config\n    let clientGenerator: PrismaConfig['clientGenerator']\n    const generatorMatch = schemaResult.data.match(/generator\\s+client\\s*{([^}]+)}/s)\n    if (generatorMatch) {\n      const generatorConfig = generatorMatch[1]\n      const providerMatch = generatorConfig.match(/provider\\s*=\\s*\"([^\"]+)\"/)\n      const outputMatch = generatorConfig.match(/output\\s*=\\s*\"([^\"]+)\"/)\n      \n      clientGenerator = {\n        provider: providerMatch?.[1] || 'prisma-client-js',\n        output: outputMatch?.[1]\n      }\n    }\n    \n    return {\n      type: 'prisma',\n      configFile: schemaFile,\n      migrationDirectory,\n      schemaFile,\n      dependencies: ['prisma', '@prisma/client'],\n      clientGenerator\n    }\n  }\n  \n  /**\n   * Extract database configuration from Prisma schema\n   */\n  async getDatabaseConfig(projectPath: string): Promise<DatabaseConfig | null> {\n    const config = await this.extractConfig(projectPath)\n    if (!config) {\n      return null\n    }\n    \n    // Read schema file\n    const schemaResult = await readFileContent(config.schemaFile.absolute)\n    if (!schemaResult.success) {\n      return null\n    }\n    \n    // Parse datasource block\n    const datasourceMatch = schemaResult.data.match(/datasource\\s+\\w+\\s*{([^}]+)}/s)\n    if (!datasourceMatch) {\n      return null\n    }\n    \n    const datasourceConfig = datasourceMatch[1]\n    \n    // Extract provider\n    const providerMatch = datasourceConfig.match(/provider\\s*=\\s*\"([^\"]+)\"/)\n    const provider = providerMatch?.[1]\n    \n    // Extract URL\n    const urlMatch = datasourceConfig.match(/url\\s*=\\s*env\\(\"([^\"]+)\"\\)/) ||\n                    datasourceConfig.match(/url\\s*=\\s*\"([^\"]+)\"/)\n    \n    if (!urlMatch) {\n      return null\n    }\n    \n    let databaseUrl: string\n    if (urlMatch[0].includes('env(')) {\n      // Environment variable reference\n      const envVar = urlMatch[1]\n      databaseUrl = process.env[envVar] || ''\n      \n      if (!databaseUrl) {\n        // Return basic config with type only\n        return {\n          type: this.mapPrismaProviderToType(provider),\n          database: 'unknown'\n        }\n      }\n    } else {\n      // Direct URL\n      databaseUrl = urlMatch[1]\n    }\n    \n    // Parse the database URL\n    const dbConfig = this.parseDatabaseUrl(databaseUrl)\n    if (dbConfig) {\n      return dbConfig\n    }\n    \n    // Fallback to provider-based detection\n    return {\n      type: this.mapPrismaProviderToType(provider),\n      database: 'unknown'\n    }\n  }\n  \n  /**\n   * Map Prisma provider to database type\n   */\n  private mapPrismaProviderToType(provider?: string): DatabaseConfig['type'] {\n    switch (provider) {\n      case 'postgresql':\n        return 'postgresql'\n      case 'mysql':\n        return 'mysql'\n      case 'sqlite':\n        return 'sqlite'\n      default:\n        return 'postgresql' // Default assumption\n    }\n  }\n} ","/**\n * Drizzle ORM detector implementation\n * Detects Drizzle projects by looking for drizzle.config.ts/js files and schema patterns\n */\n\nimport { BaseORMDetector } from './base-detector.js'\nimport { DrizzleConfig } from '../../core/index.js'\nimport { DatabaseConfig, DetectionResult } from '../../core/index.js'\nimport path from 'path'\nimport fs from 'fs-extra'\n\nexport class DrizzleDetector extends BaseORMDetector {\n  name = 'drizzle'\n  \n  async detect(projectPath: string): Promise<DetectionResult> {\n    const evidence: string[] = []\n    \n    try {\n      // Use recursive directory scanning to find config files\n      const configFilesFound = await this.findConfigFilesRecursively(projectPath)\n      evidence.push(...configFilesFound.map(f => `Found config file: ${f.relative}`))\n       \n       // Check for package.json with drizzle dependencies - check root and config directories\n       let deps = await this.checkPackageJsonDependencies(projectPath, ['drizzle-orm', 'drizzle-kit'])\n       evidence.push(...deps.found.map(dep => `Found dependency: ${dep} (root)`))\n       \n       // Also check for dependencies in the same directory as any found config files\n       for (const configFile of configFilesFound) {\n         const configDir = path.dirname(configFile.absolute)\n         const configDeps = await this.checkPackageJsonDependencies(configDir, ['drizzle-orm', 'drizzle-kit'])\n         evidence.push(...configDeps.found.map(dep => `Found dependency: ${dep} (${configFile.relative})`))\n         // Merge the found dependencies\n         deps.found = [...new Set([...deps.found, ...configDeps.found])]\n       }\n       \n       // Check for common schema file patterns\n       const schemaPatterns = [\n         'src/db/schema.ts',\n         'src/schema.ts',\n         'db/schema.ts',\n         'schema.ts',\n         'src/lib/db/schema.ts'\n       ]\n       \n       const { existing: schemaFiles } = await this.checkFiles(projectPath, schemaPatterns)\n       evidence.push(...schemaFiles.map(f => `Found schema file: ${f.relative}`))\n       \n       // Check for migrations directory\n       const migrationDirs = ['drizzle', 'migrations', 'drizzle/migrations']\n       const { existing: migrationDirsFound } = await this.checkFiles(projectPath, migrationDirs)\n       evidence.push(...migrationDirsFound.map(f => `Found migration directory: ${f.relative}`))\n      \n      // Calculate confidence using helper\n      const confidenceInput = {\n        required: { \n          found: deps.found.length > 0 ? 1 : 0, \n          total: 1 \n        },\n        optional: { \n          found: (configFilesFound.length > 0 ? 1 : 0) + (schemaFiles.length > 0 ? 1 : 0) + (migrationDirsFound.length > 0 ? 1 : 0), \n          total: 3  // config files, schema files, migration dirs\n        },\n        negative: 0\n      }\n      \n      const confidence = this.calculateConfidence(confidenceInput)\n      \n      return {\n        found: confidence > 0.3,\n        confidence: Math.round(confidence * 100),\n        evidence\n      }\n    } catch (error) {\n      return {\n        found: false,\n        confidence: 0,\n        evidence: [`Error detecting Drizzle: ${error}`]\n      }\n    }\n  }\n  \n  async extractConfig(projectPath: string): Promise<DrizzleConfig | null> {\n    try {\n      // Use the same recursive search as detect method\n      const configFilesFound = await this.findConfigFilesRecursively(projectPath)\n      if (configFilesFound.length === 0) {\n        return null\n      }\n      \n      const configFile = configFilesFound[0]\n      const configContent = await fs.readFile(configFile.absolute, 'utf-8')\n      \n      // Basic config parsing - in production, we'd use a proper TS/JS parser\n      const driver = this.extractConfigValue(configContent, 'dialect') || 'pg'\n      const validDrivers = ['pg', 'mysql2', 'better-sqlite3', 'sqlite'] as const\n      const mappedDriver = validDrivers.includes(driver as any) ? driver as typeof validDrivers[number] : 'pg'\n      const outDir = this.extractConfigValue(configContent, 'out') || './drizzle'\n      const migrationDirAbsolute = path.resolve(projectPath, outDir)\n      \n      const config: DrizzleConfig = {\n        type: 'drizzle',\n        configFile: {\n          absolute: configFile.absolute,\n          relative: configFile.relative,\n          exists: await fs.pathExists(configFile.absolute)\n        },\n        driver: mappedDriver,\n        schemaPath: this.extractConfigValue(configContent, 'schema') || './src/db/schema.ts',\n        outDir: outDir,\n        migrationDirectory: {\n          absolute: migrationDirAbsolute,\n          relative: outDir,\n          exists: await fs.pathExists(migrationDirAbsolute)\n        },\n        dependencies: ['drizzle-orm', 'drizzle-kit']\n      }\n      \n      return config\n    } catch (error) {\n      return null\n    }\n  }\n  \n  async getDatabaseConfig(projectPath: string): Promise<DatabaseConfig | null> {\n    try {\n      // Look for database URL in various places\n      const envFiles = ['.env', '.env.local', '.env.development']\n      const { existing: envFilesFound } = await this.checkFiles(projectPath, envFiles)\n      \n      for (const envFile of envFilesFound) {\n        const envContent = await fs.readFile(envFile.absolute, 'utf-8')\n        const dbUrl = this.extractEnvValue(envContent, 'DATABASE_URL')\n        if (dbUrl) {\n          const parsed = this.parseDatabaseUrl(dbUrl)\n          if (parsed) return parsed\n        }\n      }\n      \n      // Fallback: try to extract from drizzle config\n      const drizzleConfig = await this.extractConfig(projectPath)\n      if (!drizzleConfig) return null\n      \n      // Map Drizzle driver to database type\n      const driverMap: Record<string, 'postgresql' | 'mysql' | 'sqlite'> = {\n        'pg': 'postgresql',\n        'mysql2': 'mysql',\n        'better-sqlite3': 'sqlite'\n      }\n      \n      const dbType = driverMap[drizzleConfig.driver] || 'postgresql'\n      \n      return {\n        type: dbType,\n        host: 'localhost',\n        port: dbType === 'postgresql' ? 5432 : dbType === 'mysql' ? 3306 : undefined,\n        database: 'main'\n      }\n    } catch (error) {\n      return null\n    }\n  }\n  \n  private extractConfigValue(content: string, key: string): string | undefined {\n    // Simple regex-based extraction - in production, use proper AST parsing\n    const regex = new RegExp(`${key}:\\\\s*['\"]([^'\"]+)['\"]`)\n    const match = content.match(regex)\n    return match?.[1]\n  }\n  \n  private extractEnvValue(content: string, key: string): string | undefined {\n    const regex = new RegExp(`^${key}\\\\s*=\\\\s*(.+)$`, 'm')\n    const match = content.match(regex)\n    return match?.[1]?.replace(/['\"]/g, '').trim()\n  }\n\n  private async findConfigFilesRecursively(projectPath: string): Promise<Array<{absolute: string, relative: string}>> {\n    const configPatterns = /^drizzle\\.config\\.(ts|js|mjs)$/\n    const foundFiles: Array<{absolute: string, relative: string}> = []\n    \n    const searchDirectory = async (dir: string, currentPath: string = '') => {\n      try {\n        const items = await fs.readdir(dir, { withFileTypes: true })\n        \n        for (const item of items) {\n          const fullPath = path.join(dir, item.name)\n          const relativePath = path.join(currentPath, item.name)\n          \n          // Skip node_modules and .git directories for performance\n          if (item.isDirectory() && !['node_modules', '.git', '.next', 'dist', 'build'].includes(item.name)) {\n            await searchDirectory(fullPath, relativePath)\n          } else if (item.isFile() && configPatterns.test(item.name)) {\n            foundFiles.push({\n              absolute: fullPath,\n              relative: relativePath\n            })\n          }\n        }\n      } catch {\n        // Skip directories we can't read\n      }\n    }\n    \n    await searchDirectory(projectPath)\n    return foundFiles\n  }\n} ","/**\n * TypeORM detector implementation\n * Detects TypeORM projects by looking for ormconfig files, entity patterns, and migrations\n */\n\nimport { BaseORMDetector } from './base-detector.js'\nimport { TypeORMConfig } from '../../core/index.js'\nimport { DatabaseConfig, DetectionResult } from '../../core/index.js'\nimport path from 'path'\nimport fs from 'fs/promises'\n\nexport class TypeORMDetector extends BaseORMDetector {\n  name = 'typeorm'\n  \n  async detect(projectPath: string): Promise<DetectionResult> {\n    const evidence: string[] = []\n    \n    try {\n      // Check for TypeORM config files\n      const configFiles = [\n        'ormconfig.ts',\n        'ormconfig.js',\n        'ormconfig.json',\n        'typeorm.config.ts',\n        'typeorm.config.js',\n        'src/data-source.ts',\n        'src/data-source.js'\n      ]\n      \n      const { existing: configFilesFound } = await this.checkFiles(projectPath, configFiles)\n      evidence.push(...configFilesFound.map(f => `Found config file: ${f.relative}`))\n      \n      // Check for package.json with TypeORM dependencies\n      const deps = await this.checkPackageJsonDependencies(projectPath, ['typeorm', '@nestjs/typeorm'])\n      evidence.push(...deps.found.map(dep => `Found dependency: ${dep}`))\n      \n      // Check for common entity file patterns\n      const entityPatterns = await this.findFilesByPattern(\n        projectPath,\n        [/\\.entity\\.(ts|js)$/, /@Entity\\(/],\n        ['src', 'entities', 'entity']\n      )\n      if (entityPatterns.length > 0) {\n        evidence.push(`Found ${entityPatterns.length} entity files`)\n      }\n      \n      // Check for migrations directory\n      const migrationDirs = ['src/migrations', 'migrations', 'database/migrations']\n      const { existing: migrationDirsFound } = await this.checkFiles(projectPath, migrationDirs)\n      evidence.push(...migrationDirsFound.map(f => `Found migration directory: ${f.relative}`))\n      \n      // Check for migration files\n      const migrationPatterns = await this.findFilesByPattern(\n        projectPath,\n        [/\\d+.*\\.(ts|js)$/],\n        ['src/migrations', 'migrations', 'database/migrations']\n      )\n      if (migrationPatterns.length > 0) {\n        evidence.push(`Found ${migrationPatterns.length} migration files`)\n      }\n      \n      // Calculate confidence using helper\n      const confidence = this.calculateConfidence({\n        required: { \n          found: deps.found.length > 0 ? 1 : 0, \n          total: 1 \n        },\n        optional: { \n          found: configFilesFound.length + (entityPatterns.length > 0 ? 1 : 0) + migrationDirsFound.length + (migrationPatterns.length > 0 ? 1 : 0), \n          total: 4 \n        },\n        negative: 0\n      })\n      \n      return {\n        found: confidence > 0.3,\n        confidence: Math.round(confidence * 100),\n        evidence\n      }\n    } catch (error) {\n      return {\n        found: false,\n        confidence: 0,\n        evidence: [`Error detecting TypeORM: ${error}`]\n      }\n    }\n  }\n  \n  async extractConfig(projectPath: string): Promise<TypeORMConfig | null> {\n    try {\n      // Try to find TypeORM config file\n      const configFiles = [\n        'ormconfig.ts',\n        'ormconfig.js',\n        'ormconfig.json',\n        'typeorm.config.ts',\n        'typeorm.config.js',\n        'src/data-source.ts',\n        'src/data-source.js'\n      ]\n      \n      const { existing: configFilesFound } = await this.checkFiles(projectPath, configFiles)\n      if (configFilesFound.length === 0) {\n        return null\n      }\n      \n      const configFile = configFilesFound[0]\n      let entities: string[] = []\n      let migrations: string[] = []\n      \n      if (configFile.relative.endsWith('.json')) {\n        // Parse JSON config\n        const configContent = await fs.readFile(configFile.absolute, 'utf-8')\n        const jsonConfig = JSON.parse(configContent)\n        entities = Array.isArray(jsonConfig.entities) ? jsonConfig.entities : ['src/**/*.entity.{ts,js}']\n        migrations = Array.isArray(jsonConfig.migrations) ? jsonConfig.migrations : ['src/migrations/*.{ts,js}']\n      } else {\n        // Parse TypeScript/JavaScript config (basic parsing)\n        const configContent = await fs.readFile(configFile.absolute, 'utf-8')\n        entities = this.extractArrayValue(configContent, 'entities') || ['src/**/*.entity.{ts,js}']\n        migrations = this.extractArrayValue(configContent, 'migrations') || ['src/migrations/*.{ts,js}']\n      }\n      \n      const config: TypeORMConfig = {\n        type: 'typeorm',\n        configFile,\n        entities,\n        migrations,\n        migrationDirectory: configFile, // Will be updated with proper migration directory  \n        dependencies: ['typeorm'],\n        cli: {\n          migrationsDir: 'src/migrations',\n          entitiesDir: 'src/entities'\n        }\n      }\n      \n      return config\n    } catch (error) {\n      console.warn(`Failed to extract TypeORM config: ${error}`)\n      return null\n    }\n  }\n  \n  async getDatabaseConfig(projectPath: string): Promise<DatabaseConfig | null> {\n    try {\n      // Look for database URL in various places\n      const envFiles = ['.env', '.env.local', '.env.development']\n      const { existing: envFilesFound } = await this.checkFiles(projectPath, envFiles)\n      \n      for (const envFile of envFilesFound) {\n        const envContent = await fs.readFile(envFile.absolute, 'utf-8')\n        const dbUrl = this.extractEnvValue(envContent, 'DATABASE_URL') || \n                      this.extractEnvValue(envContent, 'DB_URL') ||\n                      this.extractEnvValue(envContent, 'TYPEORM_URL')\n        if (dbUrl) {\n          const parsed = this.parseDatabaseUrl(dbUrl)\n          if (parsed) return parsed\n        }\n      }\n      \n      // Try to extract from TypeORM config\n      const typeormConfig = await this.extractConfig(projectPath)\n      if (typeormConfig?.configFile) {\n        const configContent = await fs.readFile(typeormConfig.configFile.absolute, 'utf-8')\n        \n        // Extract database configuration from config file\n        const type = this.extractConfigValue(configContent, 'type')\n        const host = this.extractConfigValue(configContent, 'host')\n        const port = this.extractConfigValue(configContent, 'port')\n        const database = this.extractConfigValue(configContent, 'database')\n        const username = this.extractConfigValue(configContent, 'username')\n        const password = this.extractConfigValue(configContent, 'password')\n        \n        if (type && database) {\n          const dbTypeMap: Record<string, 'postgresql' | 'mysql' | 'sqlite'> = {\n            'postgres': 'postgresql',\n            'postgresql': 'postgresql',\n            'mysql': 'mysql',\n            'mariadb': 'mysql',\n            'sqlite': 'sqlite'\n          }\n          \n          const mappedType = dbTypeMap[type] || 'postgresql'\n          \n          return {\n            type: mappedType,\n            host: host || 'localhost',\n            port: port ? parseInt(port) : (mappedType === 'postgresql' ? 5432 : mappedType === 'mysql' ? 3306 : undefined),\n            database,\n            username,\n            password\n          }\n        }\n      }\n      \n      // Fallback defaults\n      return {\n        type: 'postgresql',\n        host: 'localhost',\n        port: 5432,\n        database: 'main'\n      }\n    } catch (error) {\n      console.warn(`Failed to extract database config: ${error}`)\n      return null\n    }\n  }\n  \n  private extractConfigValue(content: string, key: string): string | undefined {\n    // Simple regex-based extraction - in production, use proper AST parsing\n    const regex = new RegExp(`${key}:\\\\s*['\"]([^'\"]+)['\"]`)\n    const match = content.match(regex)\n    return match?.[1]\n  }\n  \n  private extractArrayValue(content: string, key: string): string[] | undefined {\n    // Basic array extraction - in production, use proper AST parsing\n    const regex = new RegExp(`${key}:\\\\s*\\\\[([^\\\\]]+)\\\\]`)\n    const match = content.match(regex)\n    if (!match) return undefined\n    \n    return match[1]\n      .split(',')\n      .map(item => item.trim().replace(/['\"]/g, ''))\n      .filter(item => item.length > 0)\n  }\n  \n  private extractEnvValue(content: string, key: string): string | undefined {\n    const regex = new RegExp(`^${key}\\\\s*=\\\\s*(.+)$`, 'm')\n    const match = content.match(regex)\n    return match?.[1]?.replace(/['\"]/g, '').trim()\n  }\n} ","// ORM detection modules\nexport * from './prisma-detector.js'\nexport * from './drizzle-detector.js'\nexport * from './typeorm-detector.js'\nexport * from './base-detector.js' ","/**\n * Database connection management\n * Handles PostgreSQL, MySQL, and SQLite connections with pooling and timeout management\n */\n\nimport { DatabaseConnection, DatabaseConfig } from '../../core/index.js'\n\n/**\n * PostgreSQL connection implementation\n */\nexport class PostgreSQLConnection implements DatabaseConnection {\n  type = 'postgresql' as const\n  isConnected = false\n  private client: any = null\n  private config: DatabaseConfig\n  \n  constructor(config: DatabaseConfig) {\n    this.config = config\n  }\n  \n  async connect(): Promise<void> {\n    try {\n      // Dynamic import to avoid bundling issues\n      const { Client } = await import('pg')\n      \n      this.client = new Client({\n        host: this.config.host,\n        port: this.config.port || 5432,\n        database: this.config.database,\n        user: this.config.username,\n        password: this.config.password,\n        ssl: this.config.ssl,\n        connectionTimeoutMillis: 10000, // 10 seconds\n        query_timeout: 30000, // 30 seconds\n      })\n      \n      await this.client.connect()\n      this.isConnected = true\n    } catch (error) {\n      this.isConnected = false\n      throw new Error(`Failed to connect to PostgreSQL: ${error}`)\n    }\n  }\n  \n  async disconnect(): Promise<void> {\n    try {\n      if (this.client) {\n        await this.client.end()\n        this.client = null\n      }\n      this.isConnected = false\n    } catch (error) {\n      console.warn(`Error disconnecting from PostgreSQL: ${error}`)\n      this.isConnected = false\n    }\n  }\n  \n  async query<T = any>(sql: string, params?: any[]): Promise<T[]> {\n    if (!this.isConnected || !this.client) {\n      throw new Error('Database not connected')\n    }\n    \n    try {\n      const result = await this.client.query(sql, params)\n      return result.rows\n    } catch (error) {\n      throw new Error(`Query failed: ${error}`)\n    }\n  }\n  \n  async transaction<T>(callback: (connection: DatabaseConnection) => Promise<T>): Promise<T> {\n    if (!this.isConnected || !this.client) {\n      throw new Error('Database not connected')\n    }\n    \n    try {\n      await this.client.query('BEGIN')\n      const result = await callback(this)\n      await this.client.query('COMMIT')\n      return result\n    } catch (error) {\n      await this.client.query('ROLLBACK')\n      throw error\n    }\n  }\n}\n\n/**\n * MySQL connection implementation\n */\nexport class MySQLConnection implements DatabaseConnection {\n  type = 'mysql' as const\n  isConnected = false\n  private connection: any = null\n  private config: DatabaseConfig\n  \n  constructor(config: DatabaseConfig) {\n    this.config = config\n  }\n  \n  async connect(): Promise<void> {\n    try {\n      // Dynamic import to avoid bundling issues\n      const mysql = await import('mysql2/promise')\n      \n             this.connection = await mysql.createConnection({\n         host: this.config.host,\n         port: this.config.port || 3306,\n         database: this.config.database,\n         user: this.config.username,\n         password: this.config.password,\n         ssl: typeof this.config.ssl === 'boolean' ? undefined : this.config.ssl\n       })\n      \n      this.isConnected = true\n    } catch (error) {\n      this.isConnected = false\n      throw new Error(`Failed to connect to MySQL: ${error}`)\n    }\n  }\n  \n  async disconnect(): Promise<void> {\n    try {\n      if (this.connection) {\n        await this.connection.end()\n        this.connection = null\n      }\n      this.isConnected = false\n    } catch (error) {\n      console.warn(`Error disconnecting from MySQL: ${error}`)\n      this.isConnected = false\n    }\n  }\n  \n  async query<T = any>(sql: string, params?: any[]): Promise<T[]> {\n    if (!this.isConnected || !this.connection) {\n      throw new Error('Database not connected')\n    }\n    \n    try {\n      const [rows] = await this.connection.execute(sql, params)\n      return Array.isArray(rows) ? rows : []\n    } catch (error) {\n      throw new Error(`Query failed: ${error}`)\n    }\n  }\n  \n  async transaction<T>(callback: (connection: DatabaseConnection) => Promise<T>): Promise<T> {\n    if (!this.isConnected || !this.connection) {\n      throw new Error('Database not connected')\n    }\n    \n    try {\n      await this.connection.beginTransaction()\n      const result = await callback(this)\n      await this.connection.commit()\n      return result\n    } catch (error) {\n      await this.connection.rollback()\n      throw error\n    }\n  }\n}\n\n/**\n * SQLite connection implementation\n */\nexport class SQLiteConnection implements DatabaseConnection {\n  type = 'sqlite' as const\n  isConnected = false\n  private db: any = null\n  private config: DatabaseConfig\n  \n  constructor(config: DatabaseConfig) {\n    this.config = config\n  }\n  \n  async connect(): Promise<void> {\n    try {\n      // Dynamic import to avoid bundling issues\n      const Database = (await import('better-sqlite3')).default\n      \n      const dbPath = this.config.database || 'database.sqlite'\n             this.db = new Database(dbPath, {\n         timeout: 10000 // 10 seconds\n       })\n      \n      this.isConnected = true\n    } catch (error) {\n      this.isConnected = false\n      throw new Error(`Failed to connect to SQLite: ${error}`)\n    }\n  }\n  \n  async disconnect(): Promise<void> {\n    try {\n      if (this.db) {\n        this.db.close()\n        this.db = null\n      }\n      this.isConnected = false\n    } catch (error) {\n      console.warn(`Error disconnecting from SQLite: ${error}`)\n      this.isConnected = false\n    }\n  }\n  \n  async query<T = any>(sql: string, params?: any[]): Promise<T[]> {\n    if (!this.isConnected || !this.db) {\n      throw new Error('Database not connected')\n    }\n    \n    try {\n      const stmt = this.db.prepare(sql)\n      const result = params ? stmt.all(params) : stmt.all()\n      return Array.isArray(result) ? result : []\n    } catch (error) {\n      throw new Error(`Query failed: ${error}`)\n    }\n  }\n  \n  async transaction<T>(callback: (connection: DatabaseConnection) => Promise<T>): Promise<T> {\n    if (!this.isConnected || !this.db) {\n      throw new Error('Database not connected')\n    }\n    \n    const transaction = this.db.transaction(async () => {\n      return await callback(this)\n    })\n    \n    return transaction()\n  }\n}\n\n/**\n * Database connection factory\n * Creates the appropriate connection based on database type\n */\nexport async function createConnection(config: DatabaseConfig): Promise<DatabaseConnection> {\n  switch (config.type) {\n    case 'postgresql':\n      return new PostgreSQLConnection(config)\n    case 'mysql':\n      return new MySQLConnection(config)\n    case 'sqlite':\n      return new SQLiteConnection(config)\n    default:\n      throw new Error(`Unsupported database type: ${config.type}`)\n  }\n}\n\n/**\n * Test database connection with proper error handling and timeout\n */\nexport async function testConnection(config: DatabaseConfig, timeoutMs: number = 10000): Promise<{ success: boolean; error?: string; latency?: number }> {\n  const startTime = Date.now()\n  let connection: DatabaseConnection | null = null\n  \n  try {\n    // Set up timeout\n    const timeoutPromise = new Promise<never>((_, reject) => {\n      setTimeout(() => reject(new Error('Connection timeout')), timeoutMs)\n    })\n    \n    // Attempt connection with timeout\n    connection = await createConnection(config)\n    await Promise.race([connection.connect(), timeoutPromise])\n    \n    // Test with a simple query\n    const testQuery = config.type === 'postgresql' \n      ? 'SELECT 1 as test' \n      : config.type === 'mysql'\n      ? 'SELECT 1 as test'\n      : 'SELECT 1 as test'\n    \n    await connection.query(testQuery)\n    \n    const latency = Date.now() - startTime\n    \n    return {\n      success: true,\n      latency\n    }\n  } catch (error) {\n    return {\n      success: false,\n      error: error instanceof Error ? error.message : String(error)\n    }\n  } finally {\n    if (connection) {\n      try {\n        await connection.disconnect()\n      } catch {\n        // Ignore cleanup errors\n      }\n    }\n  }\n}\n\n/**\n * Connection pool manager for efficient connection reuse\n */\nexport class ConnectionPool {\n  private pools = new Map<string, DatabaseConnection[]>()\n  private maxPoolSize = 5\n  private minPoolSize = 1\n  \n  constructor(options?: { maxPoolSize?: number; minPoolSize?: number }) {\n    this.maxPoolSize = options?.maxPoolSize || 5\n    this.minPoolSize = options?.minPoolSize || 1\n  }\n  \n  private getPoolKey(config: DatabaseConfig): string {\n    return `${config.type}://${config.host}:${config.port}/${config.database}`\n  }\n  \n  async getConnection(config: DatabaseConfig): Promise<DatabaseConnection> {\n    const key = this.getPoolKey(config)\n    let pool = this.pools.get(key)\n    \n    if (!pool) {\n      pool = []\n      this.pools.set(key, pool)\n    }\n    \n    // Try to get an existing connection from pool\n    const connection = pool.pop()\n    if (connection && connection.isConnected) {\n      return connection\n    }\n    \n    // Create new connection if pool is empty\n    const newConnection = await createConnection(config)\n    await newConnection.connect()\n    return newConnection\n  }\n  \n  async releaseConnection(config: DatabaseConfig, connection: DatabaseConnection): Promise<void> {\n    const key = this.getPoolKey(config)\n    const pool = this.pools.get(key) || []\n    \n    if (pool.length < this.maxPoolSize && connection.isConnected) {\n      pool.push(connection)\n      this.pools.set(key, pool)\n    } else {\n      await connection.disconnect()\n    }\n  }\n  \n  async closeAll(): Promise<void> {\n    for (const pool of this.pools.values()) {\n      await Promise.all(pool.map(conn => conn.disconnect()))\n    }\n    this.pools.clear()\n  }\n} ","/**\n * Database analysis engine\n * Provides table analysis, metadata extraction, and performance impact estimation\n */\n\nimport { DatabaseConnection, TableMetadata, DatabaseAnalysis, ColumnMetadata, IndexMetadata, ConstraintMetadata } from '../../core/index.js'\n\n/**\n * Main database analyzer class\n */\nexport class DatabaseAnalyzer {\n  constructor(private connection: DatabaseConnection) {}\n  \n  /**\n   * Perform comprehensive database analysis\n   */\n  async analyze(): Promise<DatabaseAnalysis> {\n    const tables = await this.getAllTables()\n    const tableMetadata = await Promise.all(\n      tables.map(tableName => this.analyzeTable(tableName))\n    )\n    \n    const totalSize = tableMetadata.reduce((sum, table) => sum + table.sizeBytes, 0)\n    const version = await this.getDatabaseVersion()\n    const features = await this.getDatabaseFeatures()\n    const performance = await this.getPerformanceMetrics()\n    \n    return {\n      tables: tableMetadata,\n      totalSize,\n      version,\n      features,\n      performance\n    }\n  }\n  \n  /**\n   * Analyze a specific table for metadata\n   */\n  async analyzeTable(tableName: string, schema?: string): Promise<TableMetadata> {\n    const fullTableName = schema ? `${schema}.${tableName}` : tableName\n    \n    const [columns, indexes, constraints, rowCount, sizeBytes, dependencies] = await Promise.all([\n      this.getTableColumns(tableName, schema),\n      this.getTableIndexes(tableName, schema),\n      this.getTableConstraints(tableName, schema),\n      this.getTableRowCount(tableName, schema),\n      this.getTableSize(tableName, schema),\n      this.getTableDependencies(tableName, schema)\n    ])\n    \n    return {\n      name: tableName,\n      schema,\n      rowCount,\n      sizeBytes,\n      columns,\n      indexes,\n      constraints,\n      dependencies\n    }\n  }\n  \n  /**\n   * Get all table names in the database\n   */\n  private async getAllTables(): Promise<string[]> {\n    switch (this.connection.type) {\n      case 'postgresql':\n        return await this.getPostgreSQLTables()\n      case 'mysql':\n        return await this.getMySQLTables()\n      case 'sqlite':\n        return await this.getSQLiteTables()\n      default:\n        throw new Error(`Unsupported database type: ${this.connection.type}`)\n    }\n  }\n  \n  private async getPostgreSQLTables(): Promise<string[]> {\n    const result = await this.connection.query(`\n      SELECT table_name \n      FROM information_schema.tables \n      WHERE table_schema = 'public' \n      AND table_type = 'BASE TABLE'\n      ORDER BY table_name\n    `)\n    return result.map((row: any) => row.table_name)\n  }\n  \n  private async getMySQLTables(): Promise<string[]> {\n    const result = await this.connection.query(`\n      SELECT table_name \n      FROM information_schema.tables \n      WHERE table_schema = DATABASE() \n      AND table_type = 'BASE TABLE'\n      ORDER BY table_name\n    `)\n    return result.map((row: any) => row.table_name || row.TABLE_NAME)\n  }\n  \n  private async getSQLiteTables(): Promise<string[]> {\n    const result = await this.connection.query(`\n      SELECT name \n      FROM sqlite_master \n      WHERE type = 'table' \n      AND name NOT LIKE 'sqlite_%'\n      ORDER BY name\n    `)\n    return result.map((row: any) => row.name)\n  }\n  \n  /**\n   * Get column metadata for a table\n   */\n  private async getTableColumns(tableName: string, schema?: string): Promise<ColumnMetadata[]> {\n    switch (this.connection.type) {\n      case 'postgresql':\n        return await this.getPostgreSQLColumns(tableName, schema)\n      case 'mysql':\n        return await this.getMySQLColumns(tableName, schema)\n      case 'sqlite':\n        return await this.getSQLiteColumns(tableName)\n      default:\n        return []\n    }\n  }\n  \n  private async getPostgreSQLColumns(tableName: string, schema = 'public'): Promise<ColumnMetadata[]> {\n    const result = await this.connection.query(`\n      SELECT \n        c.column_name,\n        c.data_type,\n        c.is_nullable = 'YES' as nullable,\n        c.column_default as default_value,\n        CASE WHEN pk.column_name IS NOT NULL THEN true ELSE false END as is_primary,\n        CASE WHEN u.column_name IS NOT NULL THEN true ELSE false END as is_unique,\n        fk.referenced_table,\n        fk.referenced_column\n      FROM information_schema.columns c\n      LEFT JOIN (\n        SELECT ku.column_name\n        FROM information_schema.key_column_usage ku\n        JOIN information_schema.table_constraints tc ON ku.constraint_name = tc.constraint_name\n        WHERE tc.constraint_type = 'PRIMARY KEY' AND ku.table_name = $1 AND ku.table_schema = $2\n      ) pk ON c.column_name = pk.column_name\n      LEFT JOIN (\n        SELECT ku.column_name\n        FROM information_schema.key_column_usage ku\n        JOIN information_schema.table_constraints tc ON ku.constraint_name = tc.constraint_name\n        WHERE tc.constraint_type = 'UNIQUE' AND ku.table_name = $1 AND ku.table_schema = $2\n      ) u ON c.column_name = u.column_name\n      LEFT JOIN (\n        SELECT \n          ku.column_name,\n          ku.referenced_table_name as referenced_table,\n          ku.referenced_column_name as referenced_column\n        FROM information_schema.key_column_usage ku\n        JOIN information_schema.table_constraints tc ON ku.constraint_name = tc.constraint_name\n        WHERE tc.constraint_type = 'FOREIGN KEY' AND ku.table_name = $1 AND ku.table_schema = $2\n      ) fk ON c.column_name = fk.column_name\n      WHERE c.table_name = $1 AND c.table_schema = $2\n      ORDER BY c.ordinal_position\n    `, [tableName, schema])\n    \n    return result.map((row: any) => ({\n      name: row.column_name,\n      type: row.data_type,\n      nullable: row.nullable,\n      defaultValue: row.default_value,\n      isPrimary: row.is_primary,\n      isUnique: row.is_unique,\n      references: row.referenced_table ? {\n        table: row.referenced_table,\n        column: row.referenced_column\n      } : undefined\n    }))\n  }\n  \n  private async getMySQLColumns(tableName: string, schema?: string): Promise<ColumnMetadata[]> {\n    const result = await this.connection.query(`\n      SELECT \n        column_name,\n        data_type,\n        is_nullable = 'YES' as nullable,\n        column_default as default_value,\n        column_key = 'PRI' as is_primary,\n        column_key = 'UNI' as is_unique\n      FROM information_schema.columns \n      WHERE table_name = ? AND table_schema = COALESCE(?, DATABASE())\n      ORDER BY ordinal_position\n    `, [tableName, schema])\n    \n    return result.map((row: any) => ({\n      name: row.column_name || row.COLUMN_NAME,\n      type: row.data_type || row.DATA_TYPE,\n      nullable: Boolean(row.nullable),\n      defaultValue: row.default_value || row.COLUMN_DEFAULT,\n      isPrimary: Boolean(row.is_primary),\n      isUnique: Boolean(row.is_unique),\n      references: undefined // TODO: Implement FK detection for MySQL\n    }))\n  }\n  \n  private async getSQLiteColumns(tableName: string): Promise<ColumnMetadata[]> {\n    const result = await this.connection.query(`PRAGMA table_info(${tableName})`)\n    \n    return result.map((row: any) => ({\n      name: row.name,\n      type: row.type,\n      nullable: !row.notnull,\n      defaultValue: row.dflt_value,\n      isPrimary: Boolean(row.pk),\n      isUnique: false, // TODO: Implement unique detection for SQLite\n      references: undefined // TODO: Implement FK detection for SQLite\n    }))\n  }\n  \n  /**\n   * Get index metadata for a table\n   */\n  private async getTableIndexes(tableName: string, schema?: string): Promise<IndexMetadata[]> {\n    switch (this.connection.type) {\n      case 'postgresql':\n        return await this.getPostgreSQLIndexes(tableName, schema)\n      case 'mysql':\n        return await this.getMySQLIndexes(tableName, schema)\n      case 'sqlite':\n        return await this.getSQLiteIndexes(tableName)\n      default:\n        return []\n    }\n  }\n  \n  private async getPostgreSQLIndexes(tableName: string, schema = 'public'): Promise<IndexMetadata[]> {\n    const result = await this.connection.query(`\n      SELECT \n        i.indexname as name,\n        array_agg(a.attname ORDER BY a.attnum) as columns,\n        i.indexdef LIKE '%UNIQUE%' as unique,\n        am.amname as type,\n        pg_relation_size(i.indexname::regclass) as size_bytes\n      FROM pg_indexes i\n      JOIN pg_class c ON c.relname = i.indexname\n      JOIN pg_am am ON am.oid = c.relam\n      JOIN pg_index idx ON idx.indexrelid = c.oid\n      JOIN pg_attribute a ON a.attrelid = idx.indrelid AND a.attnum = ANY(idx.indkey)\n      WHERE i.tablename = $1 AND i.schemaname = $2\n      GROUP BY i.indexname, i.indexdef, am.amname, c.oid\n      ORDER BY i.indexname\n    `, [tableName, schema])\n    \n    return result.map((row: any) => ({\n      name: row.name,\n      columns: Array.isArray(row.columns) ? row.columns : [row.columns],\n      unique: row.unique,\n      type: row.type,\n      sizeBytes: parseInt(row.size_bytes) || 0\n    }))\n  }\n  \n  private async getMySQLIndexes(tableName: string, schema?: string): Promise<IndexMetadata[]> {\n    const result = await this.connection.query(`\n      SELECT \n        index_name as name,\n        GROUP_CONCAT(column_name ORDER BY seq_in_index) as columns,\n        non_unique = 0 as unique,\n        index_type as type\n      FROM information_schema.statistics \n      WHERE table_name = ? AND table_schema = COALESCE(?, DATABASE())\n      GROUP BY index_name, non_unique, index_type\n      ORDER BY index_name\n    `, [tableName, schema])\n    \n    return result.map((row: any) => ({\n      name: row.name,\n      columns: row.columns.split(','),\n      unique: Boolean(row.unique),\n      type: row.type,\n      sizeBytes: undefined // Size info not easily available in MySQL\n    }))\n  }\n  \n  private async getSQLiteIndexes(tableName: string): Promise<IndexMetadata[]> {\n    const result = await this.connection.query(`\n      SELECT name, sql \n      FROM sqlite_master \n      WHERE type = 'index' AND tbl_name = ?\n    `, [tableName])\n    \n    return result.map((row: any) => ({\n      name: row.name,\n      columns: [], // TODO: Parse from SQL\n      unique: row.sql?.includes('UNIQUE') || false,\n      type: 'btree',\n      sizeBytes: undefined\n    }))\n  }\n  \n  /**\n   * Get constraint metadata for a table\n   */\n  private async getTableConstraints(tableName: string, schema?: string): Promise<ConstraintMetadata[]> {\n    switch (this.connection.type) {\n      case 'postgresql':\n        return await this.getPostgreSQLConstraints(tableName, schema)\n      case 'mysql':\n        return await this.getMySQLConstraints(tableName, schema)\n      case 'sqlite':\n        return await this.getSQLiteConstraints(tableName)\n      default:\n        return []\n    }\n  }\n  \n  private async getPostgreSQLConstraints(tableName: string, schema = 'public'): Promise<ConstraintMetadata[]> {\n    const result = await this.connection.query(`\n      SELECT \n        tc.constraint_name as name,\n        tc.constraint_type as type,\n        array_agg(kcu.column_name) as columns,\n        ccu.table_name as referenced_table,\n        array_agg(ccu.column_name) as referenced_columns,\n        cc.check_clause as definition\n      FROM information_schema.table_constraints tc\n      LEFT JOIN information_schema.key_column_usage kcu ON tc.constraint_name = kcu.constraint_name\n      LEFT JOIN information_schema.constraint_column_usage ccu ON tc.constraint_name = ccu.constraint_name\n      LEFT JOIN information_schema.check_constraints cc ON tc.constraint_name = cc.constraint_name\n      WHERE tc.table_name = $1 AND tc.table_schema = $2\n      GROUP BY tc.constraint_name, tc.constraint_type, ccu.table_name, cc.check_clause\n      ORDER BY tc.constraint_name\n    `, [tableName, schema])\n    \n    return result.map((row: any) => ({\n      name: row.name,\n      type: row.type,\n      columns: Array.isArray(row.columns) ? row.columns.filter(Boolean) : [row.columns].filter(Boolean),\n      referencedTable: row.referenced_table,\n      referencedColumns: Array.isArray(row.referenced_columns) ? row.referenced_columns.filter(Boolean) : [row.referenced_columns].filter(Boolean),\n      definition: row.definition\n    }))\n  }\n  \n  private async getMySQLConstraints(tableName: string, schema?: string): Promise<ConstraintMetadata[]> {\n    // Simplified MySQL constraint detection\n    return []\n  }\n  \n  private async getSQLiteConstraints(tableName: string): Promise<ConstraintMetadata[]> {\n    // Simplified SQLite constraint detection\n    return []\n  }\n  \n  /**\n   * Get table row count\n   */\n  private async getTableRowCount(tableName: string, schema?: string): Promise<number> {\n    try {\n      const fullTableName = schema ? `${schema}.${tableName}` : tableName\n      const result = await this.connection.query(`SELECT COUNT(*) as count FROM ${fullTableName}`)\n      return parseInt(result[0]?.count || result[0]?.COUNT || '0')\n    } catch {\n      return 0\n    }\n  }\n  \n  /**\n   * Get table size in bytes\n   */\n  private async getTableSize(tableName: string, schema?: string): Promise<number> {\n    try {\n      switch (this.connection.type) {\n        case 'postgresql':\n          const pgResult = await this.connection.query(`\n            SELECT pg_total_relation_size($1) as size\n          `, [tableName])\n          return parseInt(pgResult[0]?.size || '0')\n          \n        case 'mysql':\n          const mysqlResult = await this.connection.query(`\n            SELECT (data_length + index_length) as size\n            FROM information_schema.tables\n            WHERE table_name = ? AND table_schema = COALESCE(?, DATABASE())\n          `, [tableName, schema])\n          return parseInt(mysqlResult[0]?.size || '0')\n          \n        case 'sqlite':\n          // SQLite doesn't have easy size calculation\n          return 0\n          \n        default:\n          return 0\n      }\n    } catch {\n      return 0\n    }\n  }\n  \n  /**\n   * Get table dependencies\n   */\n  private async getTableDependencies(tableName: string, schema?: string): Promise<any[]> {\n    // Simplified implementation - return empty for now\n    return []\n  }\n  \n  /**\n   * Get database version\n   */\n  private async getDatabaseVersion(): Promise<string> {\n    try {\n      switch (this.connection.type) {\n        case 'postgresql':\n          const pgResult = await this.connection.query('SELECT version()')\n          return pgResult[0]?.version || 'Unknown'\n          \n        case 'mysql':\n          const mysqlResult = await this.connection.query('SELECT VERSION() as version')\n          return mysqlResult[0]?.version || 'Unknown'\n          \n        case 'sqlite':\n          const sqliteResult = await this.connection.query('SELECT sqlite_version()')\n          return sqliteResult[0]?.['sqlite_version()'] || 'Unknown'\n          \n        default:\n          return 'Unknown'\n      }\n    } catch {\n      return 'Unknown'\n    }\n  }\n  \n  /**\n   * Get database features\n   */\n  private async getDatabaseFeatures(): Promise<string[]> {\n    const features: string[] = []\n    \n    switch (this.connection.type) {\n      case 'postgresql':\n        features.push('ACID', 'Transactions', 'Foreign Keys', 'Indexes', 'Views', 'Triggers', 'Stored Procedures')\n        break\n      case 'mysql':\n        features.push('ACID', 'Transactions', 'Foreign Keys', 'Indexes', 'Views', 'Triggers', 'Stored Procedures')\n        break\n      case 'sqlite':\n        features.push('ACID', 'Transactions', 'Foreign Keys', 'Indexes', 'Views', 'Triggers')\n        break\n    }\n    \n    return features\n  }\n  \n  /**\n   * Get performance metrics\n   */\n  private async getPerformanceMetrics(): Promise<{ avgQueryTime: number; connectionCount: number; cacheHitRatio?: number }> {\n    // Simplified implementation\n    return {\n      avgQueryTime: 0,\n      connectionCount: 1,\n      cacheHitRatio: undefined\n    }\n  }\n  \n  /**\n   * Estimate migration performance impact\n   */\n  async estimatePerformanceImpact(sql: string, tableName?: string): Promise<{\n    estimatedTime: number\n    lockDuration: number\n    affectedRows: number\n    riskLevel: 'LOW' | 'MEDIUM' | 'HIGH'\n    recommendations: string[]\n  }> {\n    const recommendations: string[] = []\n    let riskLevel: 'LOW' | 'MEDIUM' | 'HIGH' = 'LOW'\n    let estimatedTime = 0\n    let lockDuration = 0\n    let affectedRows = 0\n    \n    // Basic SQL analysis\n    const sqlLower = sql.toLowerCase()\n    \n    if (tableName) {\n      const tableMetadata = await this.analyzeTable(tableName)\n      affectedRows = tableMetadata.rowCount\n      \n      // Estimate based on table size and operation type\n      if (sqlLower.includes('alter table')) {\n        estimatedTime = Math.max(1, Math.floor(affectedRows / 1000)) // 1 second per 1000 rows\n        lockDuration = estimatedTime\n        \n        if (affectedRows > 100000) {\n          riskLevel = 'HIGH'\n          recommendations.push('Consider maintenance window for large table migration')\n          recommendations.push('Test migration on staging environment first')\n        } else if (affectedRows > 10000) {\n          riskLevel = 'MEDIUM'\n          recommendations.push('Monitor migration progress')\n        }\n        \n        if (sqlLower.includes('add column') && !sqlLower.includes('not null')) {\n          recommendations.push('Adding nullable column is generally safe')\n        } else if (sqlLower.includes('add column') && sqlLower.includes('not null')) {\n          riskLevel = 'HIGH'\n          recommendations.push('Adding NOT NULL column requires table rewrite')\n          recommendations.push('Consider adding column as nullable first, then adding constraint')\n        }\n      }\n      \n      if (sqlLower.includes('drop column')) {\n        riskLevel = 'HIGH'\n        recommendations.push('Dropping columns is destructive - ensure data is not needed')\n        recommendations.push('Consider creating backup before migration')\n      }\n      \n      if (sqlLower.includes('create index')) {\n        estimatedTime = Math.max(1, Math.floor(affectedRows / 5000)) // 1 second per 5000 rows\n        lockDuration = 0 // Most databases support CONCURRENT index creation\n        \n        if (this.connection.type === 'postgresql') {\n          recommendations.push('Use CREATE INDEX CONCURRENTLY to avoid blocking')\n        }\n      }\n    }\n    \n    return {\n      estimatedTime,\n      lockDuration,\n      affectedRows,\n      riskLevel,\n      recommendations\n    }\n  }\n} ","/**\n * Database adapter interfaces (placeholder)\n */\n\nimport { DatabaseType } from '../../core/index.js'\n\nexport interface DatabaseAdapter {\n  type: DatabaseType\n  supportsFeature(feature: string): boolean\n  getOptimalIndexType(columns: string[]): string\n  estimateOperationTime(operation: string, tableSize: number): number\n}\n\nexport class PostgreSQLAdapter implements DatabaseAdapter {\n  type = 'postgresql' as const\n  \n  supportsFeature(feature: string): boolean {\n    // TODO: Implement PostgreSQL feature detection\n    return false\n  }\n  \n  getOptimalIndexType(columns: string[]): string {\n    // TODO: Implement PostgreSQL index optimization\n    return 'btree'\n  }\n  \n  estimateOperationTime(operation: string, tableSize: number): number {\n    // TODO: Implement PostgreSQL operation time estimation\n    return 0\n  }\n} ","// Database connection and analysis modules\nexport * from './connection.js'\nexport * from './analysis.js'\nexport * from './adapters.js' ","// ORM detection and database analysis for DriftJS\nexport * from './orm-detectors/index.js'\nexport * from './database/index.js' ","/**\n * flow init - Initialize flow configuration\n */\n\nimport { createFlowSpinner, textInput, confirmAction } from '../lib/prompts.js'\nimport { GlobalOptions } from '../lib/config.js'\nimport fsExtra from 'fs-extra'\nimport { resolve } from 'node:path'\nimport dotenv from 'dotenv'\nimport { PrismaDetector, DrizzleDetector, TypeORMDetector } from '../analyzer/index.js'\n// @ts-ignore ‚Äì optional type import not strictly needed for compilation\n// import type { FlowConfig } from '../../core/index.js'\n\nexport interface InitOptions {\n  force?: boolean\n  envName?: string\n  dbUrl?: string\n  migrationsPath?: string\n  yes?: boolean\n  project?: string\n}\n\nasync function findDatabaseUrl(envName: string, projectPath: string): Promise<string> {\n  const candidateFiles: string[] = []\n  // 1) current directory .env\n  candidateFiles.push(resolve(projectPath, '.env'))\n  // 2) parent directories up to repo root\n  const parts = projectPath.split('/')\n  for (let i = parts.length - 1; i > 0; i--) {\n    candidateFiles.push(parts.slice(0, i + 1).join('/') + '/.env')\n  }\n  // 3) common monorepo locations (apps/*/.env and packages/*/.env)\n  const appsDir = resolve(projectPath, 'apps')\n  const pkgsDir = resolve(projectPath, 'packages')\n  if (await fsExtra.pathExists(appsDir)) {\n    const sub = await fsExtra.readdir(appsDir)\n    sub.forEach((s) => candidateFiles.push(resolve(appsDir, s, '.env')))\n  }\n  if (await fsExtra.pathExists(pkgsDir)) {\n    const sub = await fsExtra.readdir(pkgsDir)\n    sub.forEach((s) => candidateFiles.push(resolve(pkgsDir, s, '.env')))\n  }\n\n  for (const file of candidateFiles) {\n    if (await fsExtra.pathExists(file)) {\n      try {\n        const envVars = dotenv.parse(await fsExtra.readFile(file))\n        const v =\n          envVars.DATABASE_URL || envVars[`DATABASE_URL_${envName.toUpperCase()}`]\n        if (v) return v\n      } catch {}\n    }\n  }\n  return ''\n}\n\nasync function detectMigrationsDir(projectPath: string): Promise<string | null> {\n  const candidates = [\n    'migrations',\n    'db/migrations',\n    'drizzle/migrations',\n    'prisma/migrations',\n    'database/migrations'\n  ]\n  // Parse drizzle.config.* for out path\n  const drizzleConfigFiles = ['drizzle.config.ts', 'drizzle.config.js', 'drizzle.config.mjs', 'drizzle.config.cjs']\n  for (const f of drizzleConfigFiles) {\n    if (await fsExtra.pathExists(resolve(projectPath, f))) {\n      const content = await fsExtra.readFile(resolve(projectPath, f), 'utf8')\n      const match = content.match(/out\\s*:\\s*[\"'`](.+?)[\"'`]/)\n      if (match) {\n        candidates.unshift(match[1])\n      }\n    }\n  }\n  for (const rel of candidates) {\n    if (await fsExtra.pathExists(resolve(projectPath, rel))) return rel\n  }\n  return null\n}\n\nexport async function initCommand(options: InitOptions, globalOptions: GlobalOptions): Promise<void> {\n  const projectPath = resolve(options.project || process.cwd())\n  const spinner = createFlowSpinner().start('Collecting project information')\n\n  let envName: string, databaseUrl: string, migrationsPath: string;\n\n  if (options.yes) {\n    // Non-interactive mode\n    envName = options.envName || 'development';\n    const detectedDb = await findDatabaseUrl(envName, projectPath);\n    databaseUrl = options.dbUrl || detectedDb;\n\n    if (!databaseUrl) {\n      spinner.fail('Database connection string is required. Please provide it with --db-url.');\n      throw new Error('FLOW_MISSING_DB_NON_INTERACTIVE');\n    }\n    \n    const detectedPath = await detectMigrationsDir(projectPath);\n    migrationsPath = options.migrationsPath || detectedPath || './migrations';\n\n  } else {\n    // Interactive mode\n    const envNameInput = await textInput('Environment name', {\n      placeholder: 'development',\n      defaultValue: 'development'\n    });\n    envName = envNameInput?.trim() || 'development';\n\n    const defaultDb = await findDatabaseUrl(envName, projectPath);\n    const dbPrompt = 'Database connection string (e.g. postgresql://user:pass@localhost:5432/db)';\n    const dbInput = await textInput(dbPrompt, {\n      placeholder: defaultDb || 'postgresql://user:pass@localhost:5432/db',\n      defaultValue: defaultDb\n    });\n    databaseUrl = (dbInput?.trim() || defaultDb).trim();\n\n    if (!databaseUrl) {\n      spinner.fail('Database connection string is required');\n      throw new Error('FLOW_MISSING_DB');\n    }\n\n    const detectedPath = (await detectMigrationsDir(projectPath)) || './migrations';\n    const migInput = await textInput('Path to migrations folder', {\n      placeholder: detectedPath,\n      defaultValue: detectedPath\n    });\n    migrationsPath = migInput?.trim() || detectedPath;\n\n    const proceed = await confirmAction('Generate configuration with these values?');\n    if (!proceed) {\n      spinner.fail('User cancelled');\n      return;\n    }\n  }\n\n  spinner.update('Generating flow.config')\n\n  // Detect ORM\n  const detectors = [\n    { name: 'prisma', detector: new PrismaDetector() },\n    { name: 'drizzle', detector: new DrizzleDetector() },\n    { name: 'typeorm', detector: new TypeORMDetector() }\n  ]\n  let detectedORM: string | null = null;\n  for (const { name, detector } of detectors) {\n    const result = await detector.detect(projectPath)\n    if (result.found) {\n      detectedORM = name\n      break\n    }\n  }\n\n  // Build config object\n  const config: any = {\n    version: '0.1.0',\n    defaultEnvironment: envName,\n    ...(detectedORM && { orm: detectedORM }),\n    environments: {\n      [envName]: {\n        db_connection_string: databaseUrl,\n        migrationsPath: migrationsPath\n      }\n    },\n    safety: {\n      maxTableSizeMB: 1024,\n      maxLockTimeMs: 300_000\n    }\n  }\n\n  const configPath = resolve(projectPath, globalOptions.config || 'flow.config.json')\n\n  if (await fsExtra.pathExists(configPath) && !options.yes && !(await confirmAction(`Overwrite existing ${configPath}?`))) {\n    spinner.fail('Init aborted ‚Äì config exists')\n    return\n  }\n\n  if (!globalOptions.dryRun) {\n    await fsExtra.writeFile(configPath, JSON.stringify(config, null, 2))\n    spinner.succeed(`Configuration written to ${configPath}`)\n  } else {\n    spinner.succeed('Dry run complete ‚Äì configuration would be:')\n    console.log(JSON.stringify(config, null, 2))\n  }\n\n  // --- NEW: ensure package.json has a \"flow\" script for easy execution\n  try {\n    const pkgPath = resolve(projectPath, 'package.json')\n    if (await fsExtra.pathExists(pkgPath)) {\n      // Dynamic import to avoid increasing cold start\n      const fsmod: any = await import('fs-extra')\n      const fsDyn = (fsmod.default ?? fsmod) as typeof fsExtra\n      const pkg = await fsDyn.readJson(pkgPath)\n      pkg.scripts = pkg.scripts || {}\n      if (!pkg.scripts.flow) {\n        pkg.scripts.flow = 'flow'\n        await fsDyn.writeJson(pkgPath, pkg, { spaces: 2 })\n        spinner.update('Added \"flow\" script to package.json')\n      }\n    }\n  } catch (err) {\n    // Non-fatal; emit warning but continue\n    console.warn('‚ö†Ô∏è  Could not update package.json:', err instanceof Error ? err.message : err)\n  }\n} ","\n/**\n * flow config - Manage flow configuration\n */\nimport { intro, outro } from '@clack/prompts';\nimport { getFlowConfig, GlobalOptions } from '../lib/config.js';\nimport pc from 'picocolors';\n\nexport interface ConfigOptions {\n  project?: string;\n}\n\nexport async function configCommand(options: ConfigOptions, globalOptions: GlobalOptions): Promise<void> {\n  intro('‚öôÔ∏è Flow Configuration');\n\n  const projectPath = options.project ? require('path').resolve(options.project) : process.cwd();\n  const cfg = await getFlowConfig(globalOptions, projectPath);\n\n  console.log(pc.bold('Current Configuration:'));\n  console.log(JSON.stringify(cfg, null, 2));\n\n  outro('‚öôÔ∏è Configuration check complete.');\n}\n","\n/**\n * flow status - Show the status of all migrations\n */\nimport { intro, outro } from '@clack/prompts';\nimport { getFlowConfig, GlobalOptions } from '../lib/config.js';\nimport fs from 'fs-extra';\nimport path from 'node:path';\nimport pc from 'picocolors';\n\nexport interface StatusOptions {\n  project?: string;\n}\n\nexport async function statusCommand(options: StatusOptions, globalOptions: GlobalOptions): Promise<void> {\n  const projectPath = options.project ? path.resolve(options.project) : process.cwd();\n  const cfg = await getFlowConfig(globalOptions, projectPath);\n  const envCfg = cfg.environments[cfg.defaultEnvironment];\n  const migrationsDir = envCfg.migrationsPath || './migrations';\n  const absoluteMigrationsDir = path.resolve(projectPath, migrationsDir);\n\n  intro('üìä Migration Status');\n\n  if (!await fs.pathExists(absoluteMigrationsDir)) {\n    console.log(pc.yellow('Migrations directory not found.'));\n    return;\n  }\n\n  const files = await fs.readdir(absoluteMigrationsDir);\n  const migrationFiles = files.filter(file => file.endsWith('.sql')).sort();\n\n  if (migrationFiles.length === 0) {\n    console.log(pc.yellow('No migration files found.'));\n  } else {\n    console.log(pc.bold('Found migrations:'));\n    migrationFiles.forEach(file => {\n      console.log(`  - ${pc.cyan(file)}`);\n    });\n  }\n\n  outro('üìä Status check complete.');\n}\n","/**\n * Flow CLI - Database Migration Enhancement Tool\n * Automatically enhance database migrations with safety and performance improvements\n */\n\nimport { program } from 'commander';\nimport { intro, outro, log } from '@clack/prompts';\nimport pc from 'picocolors';\nimport gradient from 'gradient-string';\nimport boxen from 'boxen';\n\n// Import commands with lazy loading for better performance\nconst lazyImport = (importFn: () => Promise<any>) => {\n  let cachedModule: any = null;\n  return async () => {\n    if (!cachedModule) {\n      cachedModule = await importFn();\n    }\n    return cachedModule;\n  };\n};\n\nconst getEnhanceCommand = lazyImport(() => import('./commands/enhance.js'));\nconst getValidateCommand = lazyImport(() => import('./commands/validate.js'));\nconst getPlanCommand = lazyImport(() => import('./commands/plan.js'));\nconst getRollbackCommand = lazyImport(() => import('./commands/rollback.js'));\nconst getInitCommand = lazyImport(() => import('./commands/init.js'));\nconst getConfigCommand = lazyImport(() => import('./commands/config.js'));\nconst getStatusCommand = lazyImport(() => import('./commands/status.js'));\n\n// Global options interface\nexport interface GlobalOptions {\n  verbose?: boolean;\n  config?: string;\n  dry?: boolean;\n}\n\n// Performance: Cache the banner to avoid recomputing\nlet cachedBanner: string | null = null;\n\nfunction getBanner(): string {\n  if (cachedBanner) return cachedBanner;\n  \n  const flowTitle = gradient('#00D4FF', '#0099CC', '#006699')('Flow');\n  const subtitle = pc.dim('Database Migration Enhancement Tool');\n  \n  cachedBanner = boxen(\n    `${flowTitle}\\n${subtitle}`,\n    {\n      padding: { top: 1, bottom: 1, left: 2, right: 2 },\n      margin: { top: 1, bottom: 1 },\n      borderStyle: 'round',\n      borderColor: 'cyan',\n      backgroundColor: '#001122',\n      align: 'center'\n    }\n  );\n  \n  return cachedBanner!; // Non-null assertion since we just assigned it\n}\n\nfunction showBanner(): void {\n  console.log(getBanner());\n}\n\n// Enhanced error handling with better UX\nfunction handleError(error: any): void {\n  console.error(pc.red('\\n‚ùå Error:'), error.message || error);\n  if (program.opts().verbose && error.stack) {\n    console.error(pc.dim('\\nStack trace:'));\n    console.error(pc.dim(error.stack));\n  }\n  process.exit(1);\n}\n\n// Set up global error handlers\nprocess.on('uncaughtException', handleError);\nprocess.on('unhandledRejection', handleError);\n\n// Configure the CLI program\nprogram\n  .name('flow')\n  .description('üåä Flow - Database Migration Enhancement Tool')\n  .version('1.2.0')\n  .option('-v, --verbose', 'Enable verbose output for debugging')\n  .option('-c, --config <path>', 'Path to configuration file')\n  .option('--dry', 'Run in dry-run mode (preview changes without applying)')\n  .hook('preAction', () => {\n    // Only show banner for the main commands, not help\n    const command = process.argv[2];\n    if (command && !['--help', '-h', '--version', '-V'].includes(command)) {\n      showBanner();\n    }\n  });\n\n// Main action commands - these operate on migration files\nprogram\n  .command('enhance')\n  .description('üöÄ Interactively enhance a migration file with safety and performance improvements')\n  .argument('[file]', 'Migration file to enhance (auto-detects latest if not specified)')\n  .option('-p, --project <path>', 'Path to project directory')\n  .action(async (file: string | undefined, options: any) => {\n    try {\n      intro(pc.cyan('Starting Flow Enhancement Process'));\n      const { enhanceCommand } = await getEnhanceCommand();\n      await enhanceCommand({ file, project: options.project }, program.opts());\n      outro(pc.green('Enhancement completed! üéâ'));\n    } catch (error) {\n      handleError(error);\n    }\n  });\n\nprogram\n  .command('validate')\n  .description('üîç Validate a migration file for potential issues')\n  .argument('[file]', 'Migration file to validate (auto-detects latest if not specified)')\n  .option('-p, --project <path>', 'Path to project directory')\n  .action(async (file: string | undefined, options: any) => {\n    try {\n      intro(pc.cyan('Starting Migration Validation'));\n      const { validateCommand } = await getValidateCommand();\n      await validateCommand({ file, project: options.project }, program.opts());\n      outro(pc.green('Validation completed! ‚úÖ'));\n    } catch (error) {\n      handleError(error);\n    }\n  });\n\nprogram\n  .command('plan')\n  .description('üìã Plan enhancement changes for a migration file')\n  .argument('[file]', 'Migration file to plan (auto-detects latest if not specified)')\n  .option('-p, --project <path>', 'Path to project directory')\n  .action(async (file: string | undefined, options: any) => {\n    try {\n      intro(pc.cyan('Creating Enhancement Plan'));\n      const { planCommand } = await getPlanCommand();\n      await planCommand({ file, project: options.project }, program.opts());\n      outro(pc.green('Plan created! üìã'));\n    } catch (error) {\n      handleError(error);\n    }\n  });\n\nprogram\n  .command('rollback')\n  .description('‚Ü©Ô∏è  Rollback changes to a migration file')\n  .argument('[file]', 'Migration file to rollback (auto-detects latest if not specified)')\n  .option('-p, --project <path>', 'Path to project directory')\n  .action(async (file: string | undefined, options: any) => {\n    try {\n      intro(pc.cyan('Starting Rollback Process'));\n      const { rollbackCommand } = await getRollbackCommand();\n      await rollbackCommand({ file, project: options.project }, program.opts());\n      outro(pc.green('Rollback completed! ‚Ü©Ô∏è'));\n    } catch (error) {\n      handleError(error);\n    }\n  });\n\n// Management commands - these manage the Flow tool itself\nprogram\n  .command('init')\n  .description('üöÄ Initialize Flow in your project')\n  .option('-p, --project <path>', 'Path to project directory')\n  .action(async (options: any) => {\n    try {\n      intro(pc.cyan('Initializing Flow'));\n      const { initCommand } = await getInitCommand();\n      await initCommand({ project: options.project }, program.opts());\n      outro(pc.green('Flow initialized successfully! üöÄ'));\n    } catch (error) {\n      handleError(error);\n    }\n  });\n\nprogram\n  .command('config')\n  .description('‚öôÔ∏è  Configure Flow settings')\n  .option('-p, --project <path>', 'Path to project directory')\n  .option('-s, --show', 'Show current configuration')\n  .option('-e, --edit', 'Edit configuration interactively')\n  .action(async (options: any) => {\n    try {\n      intro(pc.cyan('Managing Flow Configuration'));\n      const { configCommand } = await getConfigCommand();\n      await configCommand(options, program.opts());\n      outro(pc.green('Configuration updated! ‚öôÔ∏è'));\n    } catch (error) {\n      handleError(error);\n    }\n  });\n\nprogram\n  .command('status')\n  .description('üìä Show Flow status and statistics')\n  .option('-p, --project <path>', 'Path to project directory')\n  .action(async (options: any) => {\n    try {\n      intro(pc.cyan('Getting Flow Status'));\n      const { statusCommand } = await getStatusCommand();\n      await statusCommand({ project: options.project }, program.opts());\n      outro(pc.green('Status retrieved! üìä'));\n    } catch (error) {\n      handleError(error);\n    }\n  });\n\n// Show enhanced help if no arguments provided\nif (process.argv.length === 2) {\n  showBanner();\n  console.log(pc.dim('\\nüí° Tip: Run'), pc.cyan('flow --help'), pc.dim('to see available commands'));\n  console.log(pc.dim('   Start with:'), pc.cyan('flow init'), pc.dim('to initialize Flow in your project'));\n  console.log(pc.dim('   Then use:'), pc.cyan('flow enhance'), pc.dim('to enhance your latest migration'));\n  console.log('');\n}\n\n// Parse command line arguments\nprogram.parse(); "],"mappings":";;;;;;;;;;;;;;;;;;AAMA,OAAO,aAAa;AACpB,SAAS,SAAS,eAAe;AAMjC,eAAsB,cAAc,QAAuB,aAAsB;AAC/E,QAAM,aAAa,MAAM,eAAe,eAAe,QAAQ,IAAI,GAAG,OAAO,MAAM;AACnF,SAAO,KAAK,MAAM,MAAM,QAAQ,SAAS,YAAY,MAAM,CAAC;AAC9D;AAEA,eAAe,eAAe,UAAkB,UAAoC;AAClF,MAAI,UAAU;AACZ,UAAM,IAAI,QAAQ,QAAQ;AAC1B,QAAI,MAAM,QAAQ,WAAW,CAAC,EAAG,QAAO;AACxC,UAAM,IAAI,MAAM,4BAA4B,CAAC,EAAE;AAAA,EACjD;AAEA,MAAI,MAAM;AACV,SAAO,MAAM;AACX,UAAM,YAAY,QAAQ,KAAK,kBAAkB;AACjD,QAAI,MAAM,QAAQ,WAAW,SAAS,EAAG,QAAO;AAChD,UAAM,SAAS,QAAQ,GAAG;AAC1B,QAAI,WAAW,IAAK;AACpB,UAAM;AAAA,EACR;AACA,QAAM,IAAI,MAAM,4BAA4B;AAC9C;AAlCA;AAAA;AAAA;AAAA;AAAA;;;ACIA,SAAS,SAAS,QAAQ,aAAa,MAAM,SAAS,WAAW;AACjE,OAAO,YAAY;AAYnB,eAAsB,cACpB,SACA,UAAe,CAAC,GACE;AAClB,SAAO,MAAM,QAAQ;AAAA,IACnB,SAAS,OAAO,KAAK,OAAO;AAAA,IAC5B,GAAG;AAAA,EACL,CAAC;AACH;AA4CA,eAAsB,UACpB,SACA,UAAe,CAAC,GACC;AACjB,SAAO,MAAM,KAAK;AAAA,IAChB,SAAS,OAAO,KAAK,OAAO;AAAA,IAC5B,GAAG;AAAA,EACL,CAAC;AACH;AAqEO,SAAS,cAAc,SAAiB;AAC7C,QAAM,IAAI,QAAQ;AAElB,SAAO;AAAA,IACL,OAAO,CAAC,QAAiB;AACvB,QAAE,MAAM,OAAO,KAAK,aAAM,OAAO,OAAO,EAAE,CAAC;AAC3C,aAAO;AAAA,QACL,QAAQ,CAAC,eAAuB,EAAE,QAAQ,OAAO,KAAK,aAAM,UAAU,EAAE,CAAC;AAAA,QACzE,SAAS,CAAC,mBAA4B,EAAE,KAAK,OAAO,MAAM,UAAK,kBAAkB,UAAU,EAAE,CAAC;AAAA,QAC9F,MAAM,CAAC,iBAA0B,EAAE,KAAK,OAAO,IAAI,UAAK,gBAAgB,QAAQ,EAAE,CAAC;AAAA,QACnF,MAAM,CAAC,iBAA0B,EAAE,KAAK,eAAe,OAAO,KAAK,YAAY,IAAI,EAAE;AAAA,QACrF,SAAS,CAACA,SAAgB,EAAE,QAAQ,OAAO,KAAK,aAAMA,IAAG,EAAE,CAAC;AAAA,MAC9D;AAAA,IACF;AAAA,EACF;AACF;AAKO,SAAS,oBAAoB;AAClC,QAAM,IAAI,QAAQ;AAClB,MAAI,YAAY;AAEhB,SAAO;AAAA,IACL,OAAO,CAAC,YAAoB;AAC1B,UAAI,CAAC,WAAW;AACd,UAAE,MAAM,OAAO,KAAK,aAAM,OAAO,EAAE,CAAC;AACpC,oBAAY;AAAA,MACd;AACA,aAAO;AAAA,QACL,QAAQ,CAAC,QAAgB,EAAE,QAAQ,OAAO,KAAK,aAAM,GAAG,EAAE,CAAC;AAAA,QAC3D,SAAS,CAAC,QAAiB;AACzB,YAAE,KAAK,OAAO,MAAM,UAAK,OAAO,UAAU,EAAE,CAAC;AAC7C,sBAAY;AAAA,QACd;AAAA,QACA,MAAM,CAAC,QAAiB;AACtB,YAAE,KAAK,OAAO,IAAI,UAAK,OAAO,QAAQ,EAAE,CAAC;AACzC,sBAAY;AAAA,QACd;AAAA,QACA,MAAM,CAAC,QAAiB;AACtB,YAAE,KAAK,MAAM,OAAO,KAAK,GAAG,IAAI,EAAE;AAClC,sBAAY;AAAA,QACd;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AAKO,SAAS,eAAe,SAAiB,SAA0B;AACxE,MAAI,QAAQ,OAAO,MAAM,UAAK,OAAO,EAAE,CAAC;AACxC,MAAI,WAAW,QAAQ,SAAS,GAAG;AACjC,YAAQ,QAAQ,YAAU;AACxB,UAAI,KAAK,OAAO,IAAI,aAAQ,MAAM,EAAE,CAAC;AAAA,IACvC,CAAC;AAAA,EACH;AACF;AAKO,SAAS,aAAa,SAAiB,SAA0B;AACtE,MAAI,MAAM,OAAO,IAAI,UAAK,OAAO,EAAE,CAAC;AACpC,MAAI,WAAW,QAAQ,SAAS,GAAG;AACjC,YAAQ,QAAQ,YAAU;AACxB,UAAI,KAAK,OAAO,IAAI,aAAQ,MAAM,EAAE,CAAC;AAAA,IACvC,CAAC;AAAA,EACH;AACF;AAKO,SAAS,eAAe,SAAiB,SAA0B;AACxE,MAAI,KAAK,OAAO,OAAO,iBAAO,OAAO,EAAE,CAAC;AACxC,MAAI,WAAW,QAAQ,SAAS,GAAG;AACjC,YAAQ,QAAQ,YAAU;AACxB,UAAI,KAAK,OAAO,IAAI,aAAQ,MAAM,EAAE,CAAC;AAAA,IACvC,CAAC;AAAA,EACH;AACF;AAKO,SAAS,YAAY,SAAiB,SAA0B;AACrE,MAAI,KAAK,OAAO,KAAK,iBAAO,OAAO,EAAE,CAAC;AACtC,MAAI,WAAW,QAAQ,SAAS,GAAG;AACjC,YAAQ,QAAQ,YAAU;AACxB,UAAI,KAAK,OAAO,IAAI,aAAQ,MAAM,EAAE,CAAC;AAAA,IACvC,CAAC;AAAA,EACH;AACF;AAjPA;AAAA;AAAA;AAAA;AAAA;;;ACAA,IAOM,aAUA,4BAwFA,8BAyCO;AAlJb;AAAA;AAAA;AAOA,IAAM,cAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,eAAe,aAAa,YAAY,UAAU;AAAA,IAC3D;AAEA,IAAM,6BAAN,MAAgE;AAAA,MAC9D,MAAM,OAAO,WAA4C;AAEvD,cAAM,UAAU,UAAU,GAAG,YAAY;AAGzC,YAAI,QAAQ,SAAS,OAAO,KAAK,QAAQ,SAAS,mBAAmB,KAAK,QAAQ,SAAS,QAAQ,GAAG;AACpG,iBAAO;AAAA,QACT;AAGA,cAAM,kBAAkB;AAAA,UACtB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAEA,eAAO,gBAAgB,KAAK,QAAM,QAAQ,SAAS,EAAE,CAAC;AAAA,MACxD;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,cAAM,aAAa,MAAM,KAAK,OAAO,SAAS;AAE9C,YAAI,CAAC,YAAY;AACf,iBAAO;AAAA,YACL,YAAY;AAAA,YACZ,YAAY;AAAA,YACZ,QAAQ,CAAC;AAAA,YACT,QAAQ;AAAA,cACN,eAAe;AAAA,cACf,wBAAwB;AAAA,cACxB,iBAAiB;AAAA,cACjB,aAAa;AAAA,YACf;AAAA,UACF;AAAA,QACF;AAEA,cAAM,SAAS,CAAC;AAChB,cAAM,UAAU,UAAU,GAAG,YAAY;AAEzC,YAAI,QAAQ,SAAS,YAAY,GAAG;AAClC,iBAAO,KAAK;AAAA,YACV,UAAU;AAAA,YACV,aAAa;AAAA,YACb,UAAU;AAAA,YACV,MAAM,KAAK,eAAe,UAAU,IAAI,eAAe;AAAA,YACvD,gBAAgB;AAAA,UAClB,CAAC;AAAA,QACH;AAEA,YAAI,QAAQ,SAAS,aAAa,GAAG;AACnC,iBAAO,KAAK;AAAA,YACV,UAAU;AAAA,YACV,aAAa;AAAA,YACb,UAAU;AAAA,YACV,MAAM,KAAK,eAAe,UAAU,IAAI,gBAAgB;AAAA,YACxD,gBAAgB;AAAA,UAClB,CAAC;AAAA,QACH;AAEA,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ;AAAA,UACA,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,MAEQ,eAAe,SAAiB,SAAyB;AAC/D,cAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,iBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,cAAI,QAAQ,KAAK,MAAM,CAAC,CAAC,GAAG;AAC1B,mBAAO,IAAI;AAAA,UACb;AAAA,QACF;AACA,eAAO;AAAA,MACT;AAAA,IACF;AAEA,IAAM,+BAAN,MAAoE;AAAA,MAClE,MAAM,MAAM,SAAiB,WAAsD;AACjF,YAAI;AAEF,gBAAM,kBAAkB;AAAA;AAAA;AAAA;AAAA,EAI5B,QAAQ,KAAK,CAAC;AAAA;AAAA;AAAA;AAAA;AAMV,iBAAO;AAAA,YACL;AAAA,YACA,SAAS;AAAA,YACT;AAAA,YACA,UAAU,CAAC;AAAA,YACX,SAAS;AAAA,cACP;AAAA,gBACE,MAAM;AAAA,gBACN,UAAU,QAAQ,KAAK;AAAA,gBACvB,UAAU;AAAA,gBACV,MAAM;AAAA,gBACN,QAAQ;AAAA,cACV;AAAA,YACF;AAAA,UACF;AAAA,QACF,SAAS,OAAO;AACd,iBAAO;AAAA,YACL;AAAA,YACA,SAAS;AAAA,YACT,iBAAiB;AAAA,YACjB,UAAU,CAAC,wCAAwC,iBAAiB,QAAQ,MAAM,UAAU,eAAe,EAAE;AAAA,YAC7G,SAAS,CAAC;AAAA,UACZ;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEO,IAAM,2BAA8C;AAAA,MACzD;AAAA,MACA,UAAU,IAAI,2BAA2B;AAAA,MACzC,YAAY,IAAI,6BAA6B;AAAA,IAC/C;AAAA;AAAA;;;ACtJA,IAOMC,cAUA,4BA0DA,8BAkEO;AA7Ib;AAAA;AAAA;AAOA,IAAMA,eAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,cAAc,mBAAmB,UAAU,UAAU;AAAA,IAC9D;AAEA,IAAM,6BAAN,MAAgE;AAAA,MAC9D,MAAM,OAAO,WAA4C;AACvD,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,eAAO,QAAQ,SAAS,YAAY;AAAA,MACtC;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,cAAM,aAAa,MAAM,KAAK,OAAO,SAAS;AAE9C,YAAI,CAAC,YAAY;AACf,iBAAO;AAAA,YACL,YAAY;AAAA,YACZ,YAAY;AAAA,YACZ,QAAQ,CAAC;AAAA,YACT,QAAQ;AAAA,cACN,eAAe;AAAA,cACf,wBAAwB;AAAA,cACxB,iBAAiB;AAAA,cACjB,aAAa;AAAA,YACf;AAAA,UACF;AAAA,QACF;AAEA,cAAM,SAA2D,CAAC;AAClE,cAAM,QAAQ,UAAU,GAAG,MAAM,IAAI;AAErC,cAAM,QAAQ,CAAC,MAAM,UAAU;AAC7B,cAAI,gBAAgB,KAAK,IAAI,GAAG;AAC9B,kBAAM,YAAY,KAAK,iBAAiB,IAAI;AAC5C,mBAAO,KAAK;AAAA,cACV,UAAU;AAAA,cACV,aAAa,kCAAkC,SAAS;AAAA,cACxD,UAAU,KAAK,KAAK;AAAA,cACpB,MAAM,QAAQ;AAAA,cACd,gBAAgB;AAAA,YAClB,CAAC;AAAA,UACH;AAAA,QACF,CAAC;AAED,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ;AAAA,UACA,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,MAEQ,iBAAiB,MAAsB;AAC7C,cAAM,QAAQ,KAAK,MAAM,mDAAmD;AAC5E,eAAO,QAAQ,MAAM,CAAC,IAAI;AAAA,MAC5B;AAAA,IACF;AAEA,IAAM,+BAAN,MAAoE;AAAA,MAClE,MAAM,MAAM,SAAiB,WAAsD;AACjF,YAAI;AACF,gBAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,gBAAM,gBAA0B,CAAC;AACjC,gBAAM,UAA6D,CAAC;AAEpE,mBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,kBAAM,OAAO,MAAM,CAAC;AAEpB,gBAAI,gBAAgB,KAAK,IAAI,GAAG;AAC9B,oBAAM,YAAY,KAAK,iBAAiB,IAAI;AAG5C,oBAAM,mBAAmB;AAAA,YACvB,SAAS;AAAA;AAAA;AAAA;AAAA,uBAIE,KAAK,KAAK,CAAC;AAExB,4BAAc,KAAK,gBAAgB;AAGnC,oBAAM,mBAAmB,KAAK,QAAQ,oBAAoB,uBAAuB;AACjF,4BAAc,KAAK,gBAAgB;AAEnC,sBAAQ,KAAK;AAAA,gBACX,MAAM;AAAA,gBACN,UAAU;AAAA,gBACV,UAAU,mBAAmB,OAAO;AAAA,gBACpC,MAAM,IAAI;AAAA,gBACV,QAAQ;AAAA,cACV,CAAC;AAAA,YACH,OAAO;AACL,4BAAc,KAAK,IAAI;AAAA,YACzB;AAAA,UACF;AAEA,iBAAO;AAAA,YACL,aAAAA;AAAA,YACA,SAAS;AAAA,YACT,iBAAiB,cAAc,KAAK,IAAI;AAAA,YACxC,UAAU;AAAA,cACR;AAAA,cACA;AAAA,YACF;AAAA,YACA;AAAA,UACF;AAAA,QACF,SAAS,OAAO;AACd,iBAAO;AAAA,YACL,aAAAA;AAAA,YACA,SAAS;AAAA,YACT,iBAAiB;AAAA,YACjB,UAAU,CAAC,yCAAyC,iBAAiB,QAAQ,MAAM,UAAU,eAAe,EAAE;AAAA,YAC9G,SAAS,CAAC;AAAA,UACZ;AAAA,QACF;AAAA,MACF;AAAA,MAEQ,iBAAiB,MAAsB;AAC7C,cAAM,QAAQ,KAAK,MAAM,mDAAmD;AAC5E,eAAO,QAAQ,MAAM,CAAC,IAAI;AAAA,MAC5B;AAAA,IACF;AAEO,IAAM,2BAA8C;AAAA,MACzD,aAAAA;AAAA,MACA,UAAU,IAAI,2BAA2B;AAAA,MACzC,YAAY,IAAI,6BAA6B;AAAA,IAC/C;AAAA;AAAA;;;ACjJA,IAOMC,cAUA,8BAoBA,gCAYO;AAjDb;AAAA;AAAA;AAOA,IAAMA,eAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,eAAe,cAAc,YAAY;AAAA,IAClD;AAEA,IAAM,+BAAN,MAAkE;AAAA,MAChE,MAAM,OAAO,WAA4C;AACvD,eAAO,UAAU,GAAG,YAAY,EAAE,SAAS,aAAa;AAAA,MAC1D;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,eAAO;AAAA,UACL,YAAY,MAAM,KAAK,OAAO,SAAS;AAAA,UACvC,YAAY;AAAA,UACZ,QAAQ,CAAC;AAAA,UACT,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,IAAM,iCAAN,MAAsE;AAAA,MACpE,MAAM,MAAM,SAAiB,WAAsD;AACjF,eAAO;AAAA,UACL,aAAAA;AAAA,UACA,SAAS;AAAA,UACT,iBAAiB;AAAA,UACjB,UAAU,CAAC,wDAAwD;AAAA,UACnE,SAAS,CAAC;AAAA,QACZ;AAAA,MACF;AAAA,IACF;AAEO,IAAM,6BAAgD;AAAA,MAC3D,aAAAA;AAAA,MACA,UAAU,IAAI,6BAA6B;AAAA,MAC3C,YAAY,IAAI,+BAA+B;AAAA,IACjD;AAAA;AAAA;;;ACrDA,IAMMC,cAUA,wBAuDA,0BA0EO;AAjJb;AAAA;AAAA;AAMA,IAAMA,eAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,YAAY,UAAU,UAAU,aAAa;AAAA,IACtD;AAEA,IAAM,yBAAN,MAA4D;AAAA,MAC1D,MAAM,OAAO,WAA4C;AACvD,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,eACE,QAAQ,SAAS,cAAc,KAAK,QAAQ,SAAS,MAAM,KAC3D,QAAQ,SAAS,UAAU,KAC3B,QAAQ,SAAS,UAAU,KAC3B,QAAQ,SAAS,eAAe;AAAA,MAEpC;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,cAAM,aAAa,MAAM,KAAK,OAAO,SAAS;AAC9C,YAAI,CAAC,YAAY;AACf,iBAAO,EAAE,YAAY,OAAO,YAAY,GAAG,QAAQ,CAAC,GAAG,QAAQ,EAAE,eAAe,GAAG,wBAAwB,GAAG,iBAAiB,GAAG,aAAa,yCAAyC,EAAE;AAAA,QAC5L;AAEA,cAAM,SAAS,CAAC;AAChB,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,cAAM,QAAQ,UAAU,GAAG,MAAM,IAAI;AAErC,YAAI,QAAQ,SAAS,UAAU,KAAK,CAAC,QAAQ,SAAS,SAAS,GAAG;AAChE,iBAAO,KAAK;AAAA,YACV,UAAU;AAAA,YACV,aAAa;AAAA,YACb,UAAU;AAAA,YACV,MAAM,MAAM,UAAU,UAAQ,KAAK,YAAY,EAAE,SAAS,UAAU,CAAC,IAAI;AAAA,YACzE,gBAAgB;AAAA,UAClB,CAAC;AAAA,QACH;AAEA,YAAI,QAAQ,SAAS,eAAe,GAAG;AACrC,iBAAO,KAAK;AAAA,YACV,UAAU;AAAA,YACV,aAAa;AAAA,YACb,UAAU;AAAA,YACV,MAAM,MAAM,UAAU,UAAQ,KAAK,YAAY,EAAE,SAAS,eAAe,CAAC,IAAI;AAAA,YAC9E,gBAAgB;AAAA,UAClB,CAAC;AAAA,QACH;AAEA,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ;AAAA,UACA,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,IAAM,2BAAN,MAAgE;AAAA,MAC9D,MAAM,MAAM,SAAiB,WAAsD;AACjF,YAAI,kBAAkB;AACtB,cAAM,UAAU,CAAC;AAGjB,YAAI,QAAQ,YAAY,EAAE,SAAS,UAAU,KAAK,CAAC,QAAQ,YAAY,EAAE,SAAS,SAAS,GAAG;AAC5F,gBAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,cAAI,WAAW;AAEf,mBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,kBAAM,OAAO,MAAM,CAAC;AACpB,gBAAI,KAAK,YAAY,EAAE,SAAS,cAAc,KAAK,KAAK,YAAY,EAAE,SAAS,UAAU,GAAG;AAE1F,oBAAM,gBAAgB;AACtB,oBAAM,gBAAgB;AACtB,oBAAM,OAAO,GAAG,GAAG,aAAa;AAChC,oBAAM,OAAO,IAAI,GAAG,GAAG,aAAa;AACpC,sBAAQ,KAAK;AAAA,gBACX,MAAM;AAAA,gBACN,UAAU;AAAA,gBACV,UAAU,GAAG,aAAa;AAAA,EAAK,aAAa;AAAA,EAAK,IAAI;AAAA,gBACrD,MAAM,IAAI;AAAA,gBACV,QAAQ;AAAA,cACV,CAAC;AACD,mBAAK;AACL,yBAAW;AAAA,YACb;AAAA,UACF;AAEA,cAAI,UAAU;AACZ,8BAAkB,MAAM,KAAK,IAAI;AAAA,UACnC;AAAA,QACF;AAGA,YAAI,QAAQ,YAAY,EAAE,SAAS,eAAe,GAAG;AACnD,gBAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,cAAI,WAAW;AAEf,mBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,kBAAM,OAAO,MAAM,CAAC;AACpB,gBAAI,KAAK,YAAY,EAAE,SAAS,eAAe,GAAG;AAChD,oBAAM,mBAAmB;AACzB,oBAAM,oBAAoB;AAC1B,oBAAM,OAAO,GAAG,GAAG,gBAAgB;AACnC,oBAAM,OAAO,IAAI,GAAG,GAAG,iBAAiB;AACxC,sBAAQ,KAAK;AAAA,gBACX,MAAM;AAAA,gBACN,UAAU;AAAA,gBACV,UAAU,GAAG,gBAAgB;AAAA,EAAK,iBAAiB;AAAA,EAAK,IAAI;AAAA,gBAC5D,MAAM,IAAI;AAAA,gBACV,QAAQ;AAAA,cACV,CAAC;AACD,mBAAK;AACL,yBAAW;AAAA,YACb;AAAA,UACF;AAEA,cAAI,UAAU;AACZ,8BAAkB,MAAM,KAAK,IAAI;AAAA,UACnC;AAAA,QACF;AAEA,eAAO;AAAA,UACL,aAAAA;AAAA,UACA,SAAS,QAAQ,SAAS;AAAA,UAC1B;AAAA,UACA,UAAU,QAAQ,WAAW,IAAI,CAAC,qDAAqD,IAAI,CAAC;AAAA,UAC5F;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEO,IAAM,uBAA0C;AAAA,MACrD,aAAAA;AAAA,MACA,UAAU,IAAI,uBAAuB;AAAA,MACrC,YAAY,IAAI,yBAAyB;AAAA,IAC3C;AAAA;AAAA;;;ACrJA,IACMC,cACA,cAIA,gBAGO;AATb;AAAA;AAAA;AACA,IAAMA,eAA2B,EAAE,IAAI,yBAAyB,MAAM,yBAAyB,aAAa,QAAQ,UAAU,UAAU,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,MAAM,EAAE;AACjM,IAAM,eAAN,MAAkD;AAAA,MAChD,MAAM,OAAO,WAA4C;AAAE,eAAO;AAAA,MAAO;AAAA,MACzE,MAAM,QAAQ,WAAwD;AAAE,eAAO,EAAE,YAAY,OAAO,YAAY,GAAG,QAAQ,CAAC,GAAG,QAAQ,EAAE,eAAe,GAAG,wBAAwB,GAAG,iBAAiB,GAAG,aAAa,OAAO,EAAE;AAAA,MAAG;AAAA,IACrO;AACA,IAAM,iBAAN,MAAsD;AAAA,MACpD,MAAM,MAAM,SAAiB,WAAsD;AAAE,eAAO,EAAE,aAAAA,cAAa,SAAS,OAAO,iBAAiB,SAAS,UAAU,CAAC,iBAAiB,GAAG,SAAS,CAAC,EAAE;AAAA,MAAG;AAAA,IACrM;AACO,IAAM,sBAAyC,EAAE,aAAAA,cAAa,UAAU,IAAI,aAAa,GAAG,YAAY,IAAI,eAAe,EAAE;AAAA;AAAA;;;ACTpI,IAMMC,cAUA,wBA2DA,0BA0CO;AArHb;AAAA;AAAA;AAMA,IAAMA,eAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,aAAa,cAAc,UAAU,mBAAmB;AAAA,IACjE;AAEA,IAAM,yBAAN,MAA4D;AAAA,MAC1D,MAAM,OAAO,WAA4C;AACvD,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,eACE,QAAQ,SAAS,cAAc,KAAK,QAAQ,SAAS,MAAM,KAC3D,QAAQ,SAAS,aAAa,KAAK,QAAQ,SAAS,cAAc,KAClE,QAAQ,SAAS,eAAe;AAAA,MAEpC;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,cAAM,aAAa,MAAM,KAAK,OAAO,SAAS;AAC9C,YAAI,CAAC,YAAY;AACf,iBAAO;AAAA,YACL,YAAY;AAAA,YACZ,YAAY;AAAA,YACZ,QAAQ,CAAC;AAAA,YACT,QAAQ,EAAE,eAAe,GAAG,wBAAwB,GAAG,iBAAiB,GAAG,aAAa,gCAAgC;AAAA,UAC1H;AAAA,QACF;AAEA,cAAM,SAAS,CAAC;AAChB,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,cAAM,QAAQ,UAAU,GAAG,MAAM,IAAI;AAGrC,cAAM,mBAAmB;AAAA,UACvB,EAAE,MAAM,WAAW,IAAI,OAAO,MAAM,OAAO;AAAA,UAC3C,EAAE,MAAM,QAAQ,IAAI,WAAW,MAAM,SAAS;AAAA,UAC9C,EAAE,MAAM,WAAW,IAAI,OAAO,MAAM,OAAO;AAAA,UAC3C,EAAE,MAAM,aAAa,IAAI,QAAQ,MAAM,SAAS;AAAA,QAClD;AAEA,mBAAW,cAAc,kBAAkB;AACzC,cAAI,QAAQ,SAAS,WAAW,EAAE,GAAG;AACnC,mBAAO,KAAK;AAAA,cACV,UAAU,WAAW;AAAA,cACrB,aAAa,iBAAiB,WAAW,EAAE;AAAA,cAC3C,UAAU;AAAA,cACV,MAAM,MAAM,UAAU,UAAQ,KAAK,YAAY,EAAE,SAAS,MAAM,CAAC,IAAI,KAAK;AAAA,cAC1E,gBAAgB,kDAAkD,WAAW,EAAE;AAAA,YACjF,CAAC;AAAA,UACH;AAAA,QACF;AAEA,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ;AAAA,UACA,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,IAAM,2BAAN,MAAgE;AAAA,MAC9D,MAAM,MAAM,SAAiB,WAAsD;AACjF,YAAI,kBAAkB;AACtB,cAAM,UAAU,CAAC;AAGjB,YAAI,QAAQ,YAAY,EAAE,SAAS,cAAc,KAAK,QAAQ,YAAY,EAAE,SAAS,MAAM,GAAG;AAC5F,gBAAM,QAAQ,QAAQ,MAAM,IAAI;AAChC,cAAI,WAAW;AAEf,mBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,kBAAM,OAAO,MAAM,CAAC;AACpB,gBAAI,KAAK,YAAY,EAAE,SAAS,cAAc,KAAK,KAAK,YAAY,EAAE,SAAS,MAAM,GAAG;AACtF,oBAAM,OAAO,GAAG,GAAG,qEAAqE;AACxF,oBAAM,OAAO,IAAI,GAAG,GAAG,oEAAoE;AAC3F,sBAAQ,KAAK,4CAA4C;AACzD,mBAAK;AACL,yBAAW;AAAA,YACb;AAAA,UACF;AAEA,cAAI,UAAU;AACZ,8BAAkB,MAAM,KAAK,IAAI;AAAA,UACnC;AAAA,QACF;AAEA,eAAO;AAAA,UACL,aAAAA;AAAA,UACA,SAAS,QAAQ,SAAS;AAAA,UAC1B;AAAA,UACA,UAAU,QAAQ,WAAW,IAAI,CAAC,sDAAsD,IAAI,CAAC;AAAA,UAC7F,SAAS,QAAQ,IAAI,aAAW;AAAA,YAC9B,MAAM;AAAA,YACN,UAAU;AAAA,YACV,UAAU;AAAA,YACV,MAAM;AAAA,YACN,QAAQ;AAAA,UACV,EAAE;AAAA,QACJ;AAAA,MACF;AAAA,IACF;AAEO,IAAM,uBAA0C;AAAA,MACrD,aAAAA;AAAA,MACA,UAAU,IAAI,uBAAuB;AAAA,MACrC,YAAY,IAAI,yBAAyB;AAAA,IAC3C;AAAA;AAAA;;;ACzHA,IAMMC,cAUA,wBA8CA,0BA6CO;AA3Gb;AAAA;AAAA;AAMA,IAAMA,eAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,UAAU,UAAU,iBAAiB,iBAAiB;AAAA,IAC/D;AAEA,IAAM,yBAAN,MAA4D;AAAA,MAC1D,MAAM,OAAO,WAA4C;AACvD,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,eAAO,QAAQ,SAAS,eAAe,KAChC,QAAQ,SAAS,cAAc,KAAK,QAAQ,SAAS,WAAW;AAAA,MACzE;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,cAAM,aAAa,MAAM,KAAK,OAAO,SAAS;AAC9C,YAAI,CAAC,YAAY;AACf,iBAAO;AAAA,YACL,YAAY;AAAA,YACZ,YAAY;AAAA,YACZ,QAAQ,CAAC;AAAA,YACT,QAAQ,EAAE,eAAe,GAAG,wBAAwB,GAAG,iBAAiB,GAAG,aAAa,8BAA8B;AAAA,UACxH;AAAA,QACF;AAEA,cAAM,SAAS,CAAC;AAChB,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,cAAM,QAAQ,UAAU,GAAG,MAAM,IAAI;AAErC,YAAI,QAAQ,SAAS,eAAe,GAAG;AACrC,iBAAO,KAAK;AAAA,YACV,UAAU;AAAA,YACV,aAAa;AAAA,YACb,UAAU;AAAA,YACV,MAAM,MAAM,UAAU,UAAQ,KAAK,YAAY,EAAE,SAAS,eAAe,CAAC,IAAI,KAAK;AAAA,YACnF,gBAAgB;AAAA,UAClB,CAAC;AAAA,QACH;AAEA,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ;AAAA,UACA,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,IAAM,2BAAN,MAAgE;AAAA,MAC9D,MAAM,MAAM,SAAiB,WAAsD;AACjF,YAAI,kBAAkB;AACtB,cAAM,UAAU,CAAC;AACjB,cAAM,QAAQ,QAAQ,MAAM,IAAI;AAEhC,iBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,gBAAM,OAAO,MAAM,CAAC;AACpB,cAAI,KAAK,YAAY,EAAE,SAAS,eAAe,GAAG;AAChD,kBAAM,WAAW;AAAA,cACf;AAAA,cACA;AAAA,cACA;AAAA,cACA;AAAA,cACA;AAAA,cACA;AAAA,cACA;AAAA,YACF;AAEA,kBAAM,OAAO,GAAG,GAAG,GAAG,QAAQ;AAC9B,oBAAQ,KAAK,sCAAsC;AACnD,iBAAK,SAAS;AAAA,UAChB;AAAA,QACF;AAEA,YAAI,QAAQ,SAAS,GAAG;AACtB,4BAAkB,MAAM,KAAK,IAAI;AAAA,QACnC;AAEA,eAAO;AAAA,UACL,aAAAA;AAAA,UACA,SAAS,QAAQ,SAAS;AAAA,UAC1B;AAAA,UACA,UAAU,QAAQ,WAAW,IAAI,CAAC,qCAAqC,IAAI,CAAC;AAAA,UAC5E,SAAS,QAAQ,IAAI,aAAW;AAAA,YAC9B,MAAM;AAAA,YACN,UAAU;AAAA,YACV,UAAU;AAAA,YACV,MAAM;AAAA,YACN,QAAQ;AAAA,UACV,EAAE;AAAA,QACJ;AAAA,MACF;AAAA,IACF;AAEO,IAAM,uBAA0C;AAAA,MACrD,aAAAA;AAAA,MACA,UAAU,IAAI,uBAAuB;AAAA,MACrC,YAAY,IAAI,yBAAyB;AAAA,IAC3C;AAAA;AAAA;;;AC/GA,IAMMC,cAUA,uBA6CA,yBA4CO;AAzGb;AAAA;AAAA;AAMA,IAAMA,eAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,WAAW,UAAU,eAAe,QAAQ;AAAA,IACrD;AAEA,IAAM,wBAAN,MAA2D;AAAA,MACzD,MAAM,OAAO,WAA4C;AACvD,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,eAAO,QAAQ,SAAS,mBAAmB,KAAK,QAAQ,SAAS,gBAAgB;AAAA,MACnF;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,cAAM,aAAa,MAAM,KAAK,OAAO,SAAS;AAC9C,YAAI,CAAC,YAAY;AACf,iBAAO;AAAA,YACL,YAAY;AAAA,YACZ,YAAY;AAAA,YACZ,QAAQ,CAAC;AAAA,YACT,QAAQ,EAAE,eAAe,GAAG,wBAAwB,GAAG,iBAAiB,GAAG,aAAa,wCAAwC;AAAA,UAClI;AAAA,QACF;AAEA,cAAM,SAAS,CAAC;AAChB,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,cAAM,QAAQ,UAAU,GAAG,MAAM,IAAI;AAErC,YAAI,QAAQ,SAAS,mBAAmB,GAAG;AACzC,iBAAO,KAAK;AAAA,YACV,UAAU;AAAA,YACV,aAAa;AAAA,YACb,UAAU;AAAA,YACV,MAAM,MAAM,UAAU,UAAQ,KAAK,YAAY,EAAE,SAAS,mBAAmB,CAAC,IAAI,KAAK;AAAA,YACvF,gBAAgB;AAAA,UAClB,CAAC;AAAA,QACH;AAEA,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ;AAAA,UACA,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,IAAM,0BAAN,MAA+D;AAAA,MAC7D,MAAM,MAAM,SAAiB,WAAsD;AACjF,YAAI,kBAAkB;AACtB,cAAM,UAAU,CAAC;AACjB,cAAM,QAAQ,QAAQ,MAAM,IAAI;AAEhC,iBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,gBAAM,OAAO,MAAM,CAAC;AACpB,cAAI,KAAK,YAAY,EAAE,SAAS,mBAAmB,GAAG;AACpD,kBAAM,WAAW;AAAA,cACf;AAAA,cACA;AAAA,cACA;AAAA,cACA;AAAA,cACA;AAAA,cACA;AAAA,YACF;AAEA,kBAAM,OAAO,GAAG,GAAG,GAAG,QAAQ;AAC9B,oBAAQ,KAAK,qCAAqC;AAClD,iBAAK,SAAS;AAAA,UAChB;AAAA,QACF;AAEA,YAAI,QAAQ,SAAS,GAAG;AACtB,4BAAkB,MAAM,KAAK,IAAI;AAAA,QACnC;AAEA,eAAO;AAAA,UACL,aAAAA;AAAA,UACA,SAAS,QAAQ,SAAS;AAAA,UAC1B;AAAA,UACA,UAAU,QAAQ,WAAW,IAAI,CAAC,oCAAoC,IAAI,CAAC;AAAA,UAC3E,SAAS,QAAQ,IAAI,aAAW;AAAA,YAC9B,MAAM;AAAA,YACN,UAAU;AAAA,YACV,UAAU;AAAA,YACV,MAAM;AAAA,YACN,QAAQ;AAAA,UACV,EAAE;AAAA,QACJ;AAAA,MACF;AAAA,IACF;AAEO,IAAM,sBAAyC;AAAA,MACpD,aAAAA;AAAA,MACA,UAAU,IAAI,sBAAsB;AAAA,MACpC,YAAY,IAAI,wBAAwB;AAAA,IAC1C;AAAA;AAAA;;;AC7GA,IAMMC,cAUA,0BA6CA,4BAyCO;AAtGb;AAAA;AAAA;AAMA,IAAMA,eAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,UAAU,cAAc,UAAU,gBAAgB;AAAA,IAC3D;AAEA,IAAM,2BAAN,MAA8D;AAAA,MAC5D,MAAM,OAAO,WAA4C;AACvD,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,eAAO,QAAQ,SAAS,QAAQ,MAAM,QAAQ,SAAS,YAAY,KAAK,QAAQ,SAAS,YAAY,KAAK,QAAQ,SAAS,eAAe;AAAA,MAC5I;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,cAAM,aAAa,MAAM,KAAK,OAAO,SAAS;AAC9C,YAAI,CAAC,YAAY;AACf,iBAAO;AAAA,YACL,YAAY;AAAA,YACZ,YAAY;AAAA,YACZ,QAAQ,CAAC;AAAA,YACT,QAAQ,EAAE,eAAe,GAAG,wBAAwB,GAAG,iBAAiB,GAAG,aAAa,iCAAiC;AAAA,UAC3H;AAAA,QACF;AAEA,cAAM,SAAS,CAAC;AAChB,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,cAAM,QAAQ,UAAU,GAAG,MAAM,IAAI;AAErC,YAAI,QAAQ,SAAS,YAAY,KAAK,QAAQ,SAAS,gBAAgB,KAAK,QAAQ,SAAS,QAAQ,GAAG;AACtG,iBAAO,KAAK;AAAA,YACV,UAAU;AAAA,YACV,aAAa;AAAA,YACb,UAAU;AAAA,YACV,MAAM,MAAM,UAAU,UAAQ,KAAK,YAAY,EAAE,SAAS,QAAQ,CAAC,IAAI,KAAK;AAAA,YAC5E,gBAAgB;AAAA,UAClB,CAAC;AAAA,QACH;AAEA,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ;AAAA,UACA,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,IAAM,6BAAN,MAAkE;AAAA,MAChE,MAAM,MAAM,SAAiB,WAAsD;AACjF,YAAI,kBAAkB;AACtB,cAAM,UAAU,CAAC;AACjB,cAAM,QAAQ,QAAQ,MAAM,IAAI;AAEhC,iBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,gBAAM,OAAO,MAAM,CAAC;AACpB,cAAI,KAAK,YAAY,EAAE,SAAS,QAAQ,MAAM,KAAK,YAAY,EAAE,SAAS,YAAY,KAAK,KAAK,YAAY,EAAE,SAAS,YAAY,IAAI;AACrI,kBAAM,WAAW;AAAA,cACf;AAAA,cACA;AAAA,cACA;AAAA,YACF;AAEA,kBAAM,OAAO,GAAG,GAAG,GAAG,QAAQ;AAC9B,oBAAQ,KAAK,sCAAsC;AACnD,iBAAK,SAAS;AAAA,UAChB;AAAA,QACF;AAEA,YAAI,QAAQ,SAAS,GAAG;AACtB,4BAAkB,MAAM,KAAK,IAAI;AAAA,QACnC;AAEA,eAAO;AAAA,UACL,aAAAA;AAAA,UACA,SAAS,QAAQ,SAAS;AAAA,UAC1B;AAAA,UACA,UAAU,QAAQ,WAAW,IAAI,CAAC,6BAA6B,IAAI,CAAC;AAAA,UACpE,SAAS,QAAQ,IAAI,aAAW;AAAA,YAC9B,MAAM;AAAA,YACN,UAAU;AAAA,YACV,UAAU;AAAA,YACV,MAAM;AAAA,YACN,QAAQ;AAAA,UACV,EAAE;AAAA,QACJ;AAAA,MACF;AAAA,IACF;AAEO,IAAM,yBAA4C;AAAA,MACvD,aAAAA;AAAA,MACA,UAAU,IAAI,yBAAyB;AAAA,MACvC,YAAY,IAAI,2BAA2B;AAAA,IAC7C;AAAA;AAAA;;;AC1GA,IAMMC,eAUA,yBA6CA,2BAyCO;AAtGb;AAAA;AAAA;AAMA,IAAMA,gBAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,SAAS,cAAc,cAAc,QAAQ;AAAA,IACtD;AAEA,IAAM,0BAAN,MAA6D;AAAA,MAC3D,MAAM,OAAO,WAA4C;AACvD,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,eAAO,QAAQ,SAAS,OAAO,KAAK,QAAQ,SAAS,YAAY;AAAA,MACnE;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,cAAM,aAAa,MAAM,KAAK,OAAO,SAAS;AAC9C,YAAI,CAAC,YAAY;AACf,iBAAO;AAAA,YACL,YAAY;AAAA,YACZ,YAAY;AAAA,YACZ,QAAQ,CAAC;AAAA,YACT,QAAQ,EAAE,eAAe,GAAG,wBAAwB,GAAG,iBAAiB,GAAG,aAAa,gCAAgC;AAAA,UAC1H;AAAA,QACF;AAEA,cAAM,SAAS,CAAC;AAChB,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,cAAM,QAAQ,UAAU,GAAG,MAAM,IAAI;AAErC,YAAI,QAAQ,SAAS,gBAAgB,KAAK,QAAQ,SAAS,OAAO,GAAG;AACnE,iBAAO,KAAK;AAAA,YACV,UAAU;AAAA,YACV,aAAa;AAAA,YACb,UAAU;AAAA,YACV,MAAM,MAAM,UAAU,UAAQ,KAAK,YAAY,EAAE,SAAS,OAAO,CAAC,IAAI,KAAK;AAAA,YAC3E,gBAAgB;AAAA,UAClB,CAAC;AAAA,QACH;AAEA,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ;AAAA,UACA,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,IAAM,4BAAN,MAAiE;AAAA,MAC/D,MAAM,MAAM,SAAiB,WAAsD;AACjF,YAAI,kBAAkB;AACtB,cAAM,UAAU,CAAC;AACjB,cAAM,QAAQ,QAAQ,MAAM,IAAI;AAEhC,iBAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK;AACrC,gBAAM,OAAO,MAAM,CAAC;AACpB,cAAI,KAAK,YAAY,EAAE,SAAS,OAAO,KAAK,KAAK,YAAY,EAAE,SAAS,YAAY,GAAG;AACrF,kBAAM,WAAW;AAAA,cACf;AAAA,cACA;AAAA,cACA;AAAA,YACF;AAEA,kBAAM,OAAO,GAAG,GAAG,GAAG,QAAQ;AAC9B,oBAAQ,KAAK,2CAA2C;AACxD,iBAAK,SAAS;AAAA,UAChB;AAAA,QACF;AAEA,YAAI,QAAQ,SAAS,GAAG;AACtB,4BAAkB,MAAM,KAAK,IAAI;AAAA,QACnC;AAEA,eAAO;AAAA,UACL,aAAAA;AAAA,UACA,SAAS,QAAQ,SAAS;AAAA,UAC1B;AAAA,UACA,UAAU,QAAQ,WAAW,IAAI,CAAC,4BAA4B,IAAI,CAAC;AAAA,UACnE,SAAS,QAAQ,IAAI,aAAW;AAAA,YAC9B,MAAM;AAAA,YACN,UAAU;AAAA,YACV,UAAU;AAAA,YACV,MAAM;AAAA,YACN,QAAQ;AAAA,UACV,EAAE;AAAA,QACJ;AAAA,MACF;AAAA,IACF;AAEO,IAAM,wBAA2C;AAAA,MACtD,aAAAA;AAAA,MACA,UAAU,IAAI,wBAAwB;AAAA,MACtC,YAAY,IAAI,0BAA0B;AAAA,IAC5C;AAAA;AAAA;;;AC1GA,IAMMC,eAUA,8BAiEA,gCAgCO;AAjHb;AAAA;AAAA;AAMA,IAAMA,gBAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,UAAU,UAAU,mBAAmB,iBAAiB;AAAA,IACjE;AAEA,IAAM,+BAAN,MAAkE;AAAA,MAChE,MAAM,OAAO,WAA4C;AACvD,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,cAAM,kBAAkB;AAAA,UACtB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF;AAEA,eAAO,gBAAgB,KAAK,QAAM,QAAQ,SAAS,EAAE,CAAC;AAAA,MACxD;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,cAAM,aAAa,MAAM,KAAK,OAAO,SAAS;AAC9C,YAAI,CAAC,YAAY;AACf,iBAAO;AAAA,YACL,YAAY;AAAA,YACZ,YAAY;AAAA,YACZ,QAAQ,CAAC;AAAA,YACT,QAAQ,EAAE,eAAe,GAAG,wBAAwB,GAAG,iBAAiB,GAAG,aAAa,+BAA+B;AAAA,UACzH;AAAA,QACF;AAEA,cAAM,SAAS,CAAC;AAChB,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,cAAM,QAAQ,UAAU,GAAG,MAAM,IAAI;AAErC,cAAM,kBAAkB;AAAA,UACtB,EAAE,WAAW,cAAc,UAAU,YAAY,aAAa,+CAA+C;AAAA,UAC7G,EAAE,WAAW,eAAe,UAAU,QAAQ,aAAa,4CAA4C;AAAA,UACvG,EAAE,WAAW,YAAY,UAAU,YAAY,aAAa,qCAAqC;AAAA,UACjG,EAAE,WAAW,eAAe,UAAU,QAAQ,aAAa,oDAAoD;AAAA,QACjH;AAEA,mBAAW,MAAM,iBAAiB;AAChC,cAAI,QAAQ,SAAS,GAAG,SAAS,GAAG;AAClC,mBAAO,KAAK;AAAA,cACV,UAAU,GAAG;AAAA,cACb,aAAa,GAAG;AAAA,cAChB,UAAU,GAAG,UAAU,YAAY;AAAA,cACnC,MAAM,MAAM,UAAU,UAAQ,KAAK,YAAY,EAAE,SAAS,GAAG,SAAS,CAAC,IAAI,KAAK;AAAA,cAChF,gBAAgB;AAAA,YAClB,CAAC;AAAA,UACH;AAAA,QACF;AAEA,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ;AAAA,UACA,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,IAAM,iCAAN,MAAsE;AAAA,MACpE,MAAM,MAAM,SAAiB,WAAsD;AACjF,cAAM,UAAU,CAAC;AAGjB,cAAM,gBAAgB;AAAA,UACpB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF,EAAE,KAAK,IAAI;AAEX,cAAM,kBAAkB,gBAAgB,OAAO;AAC/C,gBAAQ,KAAK,qCAAqC;AAElD,eAAO;AAAA,UACL,aAAAA;AAAA,UACA,SAAS;AAAA,UACT;AAAA,UACA,UAAU,CAAC;AAAA,UACX,SAAS,QAAQ,IAAI,aAAW;AAAA,YAC9B,MAAM;AAAA,YACN,UAAU;AAAA,YACV,UAAU;AAAA,YACV,MAAM;AAAA,YACN,QAAQ;AAAA,UACV,EAAE;AAAA,QACJ;AAAA,MACF;AAAA,IACF;AAEO,IAAM,6BAAgD;AAAA,MAC3D,aAAAA;AAAA,MACA,UAAU,IAAI,6BAA6B;AAAA,MAC3C,YAAY,IAAI,+BAA+B;AAAA,IACjD;AAAA;AAAA;;;ACrHA,IAMMC,eAUA,wBAoDA,0BAiCO;AArGb;AAAA;AAAA;AAMA,IAAMA,gBAA2B;AAAA,MAC/B,IAAI;AAAA,MACJ,MAAM;AAAA,MACN,aAAa;AAAA,MACb,UAAU;AAAA,MACV,UAAU;AAAA,MACV,sBAAsB;AAAA,MACtB,MAAM,CAAC,SAAS,YAAY,gBAAgB,QAAQ;AAAA,IACtD;AAEA,IAAM,yBAAN,MAA4D;AAAA,MAC1D,MAAM,OAAO,WAA4C;AACvD,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,eAAQ,QAAQ,SAAS,MAAM,KAAK,QAAQ,SAAS,QAAQ,KACrD,QAAQ,SAAS,OAAO,KAAK,QAAQ,SAAS,KAAK,KACnD,QAAQ,SAAS,QAAQ,KAAK,QAAQ,SAAS,QAAQ;AAAA,MACjE;AAAA,MAEA,MAAM,QAAQ,WAAwD;AACpE,cAAM,aAAa,MAAM,KAAK,OAAO,SAAS;AAC9C,YAAI,CAAC,YAAY;AACf,iBAAO;AAAA,YACL,YAAY;AAAA,YACZ,YAAY;AAAA,YACZ,QAAQ,CAAC;AAAA,YACT,QAAQ,EAAE,eAAe,GAAG,wBAAwB,GAAG,iBAAiB,GAAG,aAAa,yCAAyC;AAAA,UACnI;AAAA,QACF;AAEA,cAAM,SAAS,CAAC;AAChB,cAAM,UAAU,UAAU,GAAG,YAAY;AACzC,cAAM,QAAQ,UAAU,GAAG,MAAM,IAAI;AAErC,YAAI,QAAQ,SAAS,QAAQ,KAAK,QAAQ,SAAS,cAAc,GAAG;AAClE,gBAAM,cAAc,MAAM,UAAU,UAAQ,KAAK,YAAY,EAAE,SAAS,QAAQ,CAAC;AACjF,gBAAM,cAAc,MAAM,UAAU,UAAQ,KAAK,YAAY,EAAE,SAAS,cAAc,CAAC;AAEvF,cAAI,eAAe,KAAK,eAAe,KAAK,cAAc,aAAa;AACrE,mBAAO,KAAK;AAAA,cACV,UAAU;AAAA,cACV,aAAa;AAAA,cACb,UAAU;AAAA,cACV,MAAM,cAAc;AAAA,cACpB,gBAAgB;AAAA,YAClB,CAAC;AAAA,UACH;AAAA,QACF;AAEA,eAAO;AAAA,UACL,YAAY;AAAA,UACZ,YAAY;AAAA,UACZ;AAAA,UACA,QAAQ;AAAA,YACN,eAAe;AAAA,YACf,wBAAwB;AAAA,YACxB,iBAAiB;AAAA,YACjB,aAAa;AAAA,UACf;AAAA,QACF;AAAA,MACF;AAAA,IACF;AAEA,IAAM,2BAAN,MAAgE;AAAA,MAC9D,MAAM,MAAM,SAAiB,WAAsD;AACjF,YAAI,kBAAkB;AACtB,cAAM,UAAU,CAAC;AAEjB,cAAM,oBAAoB;AAAA,UACxB;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,UACA;AAAA,QACF,EAAE,KAAK,IAAI;AAEX,0BAAkB,oBAAoB,OAAO;AAC7C,gBAAQ,KAAK,kCAAkC;AAE/C,eAAO;AAAA,UACL,aAAAA;AAAA,UACA,SAAS;AAAA,UACT;AAAA,UACA,UAAU,CAAC;AAAA,UACX,SAAS,QAAQ,IAAI,aAAW;AAAA,YAC9B,MAAM;AAAA,YACN,UAAU;AAAA,YACV,UAAU;AAAA,YACV,MAAM;AAAA,YACN,QAAQ;AAAA,UACV,EAAE;AAAA,QACJ;AAAA,MACF;AAAA,IACF;AAEO,IAAM,uBAA0C;AAAA,MACrD,aAAAA;AAAA,MACA,UAAU,IAAI,uBAAuB;AAAA,MACrC,YAAY,IAAI,yBAAyB;AAAA,IAC3C;AAAA;AAAA;;;AChFA,eAAsB,yBAAuD;AAC3E,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AAxCA;AAAA;AAAA;AAQA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAAA;AAAA;;;ACnBA,IAGMC,eAOAC,iBAOA,wBACO,mBAGP,yBACO,oBAGP,8BACO,yBAKP,4BACO,uBAGP,8BACO,yBAGP,uBACO,kBAGP,8BACO,yBAGP,0BACO,qBAGP,8BACO,yBAGP,wBACO,mBAGP,6BACO,wBAGP,8BACO;AAhEb;AAAA;AAAA;AAGA,IAAMD,gBAAN,MAAkD;AAAA,MAChD,MAAM,SAA2B;AAAE,eAAO;AAAA,MAAO;AAAA,MACjD,MAAM,UAAwC;AAC5C,eAAO,EAAE,YAAY,OAAO,YAAY,GAAG,QAAQ,CAAC,GAAG,QAAQ,EAAE,eAAe,GAAG,wBAAwB,GAAG,iBAAiB,GAAG,aAAa,OAAO,EAAE;AAAA,MAC1J;AAAA,IACF;AAEA,IAAMC,kBAAN,MAAsD;AAAA,MACpD,MAAM,MAAM,SAA6C;AACvD,eAAO,EAAE,aAAa,CAAC,GAAkB,SAAS,OAAO,iBAAiB,SAAS,UAAU,CAAC,iBAAiB,GAAG,SAAS,CAAC,EAAE;AAAA,MAChI;AAAA,IACF;AAGA,IAAM,yBAAsC,EAAE,IAAI,sBAAsB,MAAM,gBAAgB,aAAa,QAAQ,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,MAAM,EAAE;AACxL,IAAM,oBAAuC,EAAE,aAAa,wBAAwB,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAG1J,IAAM,0BAAuC,EAAE,IAAI,uBAAuB,MAAM,iBAAiB,aAAa,iDAAiD,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,UAAU,EAAE;AACxO,IAAM,qBAAwC,EAAE,aAAa,yBAAyB,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAG5J,IAAM,+BAA4C,EAAE,IAAI,4BAA4B,MAAM,sBAAsB,aAAa,iDAAiD,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,UAAU,EAAE;AACvP,IAAM,0BAA6C,EAAE,aAAa,8BAA8B,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAKtK,IAAM,6BAA0C,EAAE,IAAI,0BAA0B,MAAM,6BAA6B,aAAa,iDAAiD,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,UAAU,EAAE;AAC1P,IAAM,wBAA2C,EAAE,aAAa,4BAA4B,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAGlK,IAAM,+BAA4C,EAAE,IAAI,4BAA4B,MAAM,sBAAsB,aAAa,QAAQ,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,MAAM,EAAE;AAC1M,IAAM,0BAA6C,EAAE,aAAa,8BAA8B,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAGtK,IAAM,wBAAqC,EAAE,IAAI,qBAAqB,MAAM,eAAe,aAAa,QAAQ,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,MAAM,EAAE;AACrL,IAAM,mBAAsC,EAAE,aAAa,uBAAuB,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAGxJ,IAAM,+BAA4C,EAAE,IAAI,4BAA4B,MAAM,sBAAsB,aAAa,QAAQ,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,MAAM,EAAE;AAC1M,IAAM,0BAA6C,EAAE,aAAa,8BAA8B,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAGtK,IAAM,2BAAwC,EAAE,IAAI,wBAAwB,MAAM,kBAAkB,aAAa,QAAQ,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,MAAM,EAAE;AAC9L,IAAM,sBAAyC,EAAE,aAAa,0BAA0B,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAG9J,IAAM,+BAA4C,EAAE,IAAI,4BAA4B,MAAM,sBAAsB,aAAa,QAAQ,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,MAAM,EAAE;AAC1M,IAAM,0BAA6C,EAAE,aAAa,8BAA8B,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAGtK,IAAM,yBAAsC,EAAE,IAAI,qBAAqB,MAAM,eAAe,aAAa,QAAQ,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,MAAM,EAAE;AACtL,IAAM,oBAAuC,EAAE,aAAa,wBAAwB,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAG1J,IAAM,8BAA2C,EAAE,IAAI,2BAA2B,MAAM,qBAAqB,aAAa,QAAQ,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,MAAM,EAAE;AACvM,IAAM,yBAA4C,EAAE,aAAa,6BAA6B,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAGpK,IAAM,+BAA4C,EAAE,IAAI,4BAA4B,MAAM,sBAAsB,aAAa,QAAQ,UAAU,SAAS,UAAU,GAAG,sBAAsB,OAAO,MAAM,CAAC,MAAM,EAAE;AAC1M,IAAM,0BAA6C,EAAE,aAAa,8BAA8B,UAAU,IAAID,cAAa,GAAG,YAAY,IAAIC,gBAAe,EAAE;AAAA;AAAA;;;ACrCtK,eAAsB,wBAAsD;AAC1E,SAAO;AAAA,IACL;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AA1CA;AAAA;AAAA;AAQA;AAAA;AAAA;;;ACRA,IAUa;AAVb;AAAA;AAAA;AAOA;AACA;AAEO,IAAM,oBAAN,MAAwB;AAAA,MACrB,gBAAqC,CAAC;AAAA,MACtC,eAAoC,CAAC;AAAA,MACrC,cAAc;AAAA;AAAA,MAGd,gBAAgB,oBAAI,IAAiC;AAAA,MACrD,iBAAiB,oBAAI,IAAqB;AAAA,MAC1C,cAAc,oBAAI,IAA+B;AAAA;AAAA;AAAA;AAAA;AAAA,MAMzD,MAAM,aAA4B;AAChC,YAAI,KAAK,YAAa;AAEtB,YAAI;AAEF,gBAAM,CAAC,sBAAsB,mBAAmB,IAAI,MAAM,QAAQ,IAAI;AAAA,YACpE,uBAAuB;AAAA,YACvB,sBAAsB;AAAA,UACxB,CAAC;AAED,eAAK,gBAAgB;AACrB,eAAK,eAAe;AAGpB,eAAK,cAAc,KAAK,CAAC,GAAG,MAAM,EAAE,YAAY,WAAW,EAAE,YAAY,QAAQ;AACjF,eAAK,aAAa,KAAK,CAAC,GAAG,MAAM,EAAE,YAAY,WAAW,EAAE,YAAY,QAAQ;AAGhF,WAAC,GAAG,KAAK,eAAe,GAAG,KAAK,YAAY,EAAE,QAAQ,YAAU;AAC9D,iBAAK,YAAY,IAAI,OAAO,YAAY,IAAI,MAAM;AAAA,UACpD,CAAC;AAED,eAAK,cAAc;AAAA,QACrB,SAAS,OAAO;AACd,kBAAQ,MAAM,4CAA4C,KAAK;AAC/D,gBAAM;AAAA,QACR;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,MAAM,yBAAyB,WAAkD;AAC/E,cAAM,KAAK,WAAW;AAEtB,cAAM,yBAAwC,CAAC;AAC/C,cAAM,WAAW,UAAU,UAAU,IAAI,IAAI,UAAU,GAAG,MAAM;AAGhE,YAAI,KAAK,eAAe,IAAI,QAAQ,GAAG;AACrC,iBAAO,KAAK,sBAAsB,UAAU,KAAK,aAAa;AAAA,QAChE;AAGA,cAAM,oBAAoB,KAAK,cAAc,IAAI,OAAO,WAAW;AACjE,cAAI;AACF,kBAAM,eAAe,MAAM,OAAO,SAAS,OAAO,SAAS;AAC3D,mBAAO,EAAE,QAAQ,aAAa;AAAA,UAChC,SAAS,OAAO;AACd,oBAAQ,KAAK,+BAA+B,OAAO,YAAY,EAAE,KAAK,KAAK;AAC3E,mBAAO,EAAE,QAAQ,cAAc,MAAM;AAAA,UACvC;AAAA,QACF,CAAC;AAED,cAAM,UAAU,MAAM,QAAQ,IAAI,iBAAiB;AAEnD,gBAAQ,QAAQ,CAAC,EAAE,QAAQ,aAAa,MAAM;AAC5C,cAAI,cAAc;AAChB,mCAAuB,KAAK,OAAO,WAAW;AAAA,UAChD;AAAA,QACF,CAAC;AAGD,aAAK,kBAAkB,UAAU,sBAAsB;AAEvD,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,MAAM,wBAAwB,WAAkD;AAC9E,cAAM,KAAK,WAAW;AAEtB,cAAM,yBAAwC,CAAC;AAC/C,cAAM,WAAW,SAAS,UAAU,IAAI,IAAI,UAAU,GAAG,MAAM;AAG/D,YAAI,KAAK,eAAe,IAAI,QAAQ,GAAG;AACrC,iBAAO,KAAK,sBAAsB,UAAU,KAAK,YAAY;AAAA,QAC/D;AAGA,cAAM,oBAAoB,KAAK,aAAa,IAAI,OAAO,WAAW;AAChE,cAAI;AACF,kBAAM,eAAe,MAAM,OAAO,SAAS,OAAO,SAAS;AAC3D,mBAAO,EAAE,QAAQ,aAAa;AAAA,UAChC,SAAS,OAAO;AACd,oBAAQ,KAAK,+BAA+B,OAAO,YAAY,EAAE,KAAK,KAAK;AAC3E,mBAAO,EAAE,QAAQ,cAAc,MAAM;AAAA,UACvC;AAAA,QACF,CAAC;AAED,cAAM,UAAU,MAAM,QAAQ,IAAI,iBAAiB;AAEnD,gBAAQ,QAAQ,CAAC,EAAE,QAAQ,aAAa,MAAM;AAC5C,cAAI,cAAc;AAChB,mCAAuB,KAAK,OAAO,WAAW;AAAA,UAChD;AAAA,QACF,CAAC;AAGD,aAAK,kBAAkB,UAAU,sBAAsB;AAEvD,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAQA,MAAM,uBAAuB,eAAuB,WAA+D;AACjH,cAAM,KAAK,WAAW;AAEtB,cAAM,WAAW,YAAY,aAAa,IAAI,UAAU,IAAI,IAAI,UAAU,GAAG,MAAM;AAGnF,YAAI,KAAK,cAAc,IAAI,QAAQ,GAAG;AACpC,iBAAO,KAAK,cAAc,IAAI,QAAQ;AAAA,QACxC;AAEA,cAAM,SAAS,KAAK,YAAY,IAAI,aAAa;AACjD,YAAI,CAAC,OAAQ,QAAO;AAEpB,YAAI;AACF,gBAAM,WAAW,MAAM,OAAO,SAAS,QAAQ,SAAS;AAGxD,cAAI,UAAU;AACZ,iBAAK,cAAc,IAAI,UAAU,QAAQ;AAAA,UAC3C;AAEA,iBAAO;AAAA,QACT,SAAS,OAAO;AACd,kBAAQ,KAAK,+BAA+B,aAAa,KAAK,KAAK;AACnE,iBAAO;AAAA,QACT;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,MAAM,kBAAkB,SAAiB,WAA0B,cAA8C;AAC/G,cAAM,KAAK,WAAW;AAEtB,YAAI,kBAAkB;AACtB,cAAM,UAA+B,CAAC;AAGtC,cAAM,qBAAqB,CAAC,GAAG,YAAY,EAAE,KAAK,CAAC,GAAG,MAAM,EAAE,WAAW,EAAE,QAAQ;AAEnF,mBAAWC,iBAAe,oBAAoB;AAC5C,gBAAM,SAAS,KAAK,YAAY,IAAIA,cAAY,EAAE;AAClD,cAAI,CAAC,QAAQ;AACX,oBAAQ,KAAK,iCAAiCA,cAAY,EAAE,EAAE;AAC9D;AAAA,UACF;AAEA,cAAI;AAEF,kBAAM,mBAAmB,EAAE,GAAG,WAAW,IAAI,gBAAgB;AAE7D,kBAAM,SAAS,MAAM,OAAO,WAAW,MAAM,iBAAiB,gBAAgB;AAC9E,gBAAI,OAAO,SAAS;AAClB,gCAAkB,OAAO;AACzB,sBAAQ,KAAK,MAAM;AAAA,YACrB;AAAA,UACF,SAAS,OAAO;AACd,oBAAQ,KAAK,8BAA8BA,cAAY,EAAE,KAAK,KAAK;AAAA,UACrE;AAAA,QACF;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MASA,MAAM,uBAAuB,SAAiB,WAA0BA,eAAsD;AAC5H,cAAM,KAAK,WAAW;AAEtB,cAAM,SAAS,KAAK,YAAY,IAAIA,cAAY,EAAE;AAClD,YAAI,CAAC,QAAQ;AACX,gBAAM,IAAI,MAAM,iCAAiCA,cAAY,EAAE,EAAE;AAAA,QACnE;AAEA,eAAO,MAAM,OAAO,WAAW,MAAM,SAAS,SAAS;AAAA,MACzD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOQ,sBAAsB,eAAsD;AAClF,eAAO,KAAK,YAAY,IAAI,aAAa;AAAA,MAC3C;AAAA;AAAA;AAAA;AAAA,MAKQ,kBAAkB,UAAkB,cAAmC;AAE7E,cAAM,iBAAiB,aAAa,IAAI,OAAK,EAAE,EAAE;AACjD,aAAK,eAAe,IAAI,UAAU,eAAe,SAAS,CAAC;AAAA,MAC7D;AAAA;AAAA;AAAA;AAAA,MAKQ,sBAAsB,UAAkB,SAA6C;AAG3F,eAAO,CAAC;AAAA,MACV;AAAA;AAAA;AAAA;AAAA,MAKA,aAAmB;AACjB,aAAK,cAAc,MAAM;AACzB,aAAK,eAAe,MAAM;AAAA,MAC5B;AAAA;AAAA;AAAA;AAAA,MAKA,gBAAmE;AACjE,eAAO;AAAA,UACL,eAAe,KAAK,cAAc;AAAA,UAClC,gBAAgB,KAAK,eAAe;AAAA,QACtC;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,MAAM,eAAe,eAAyC;AAC5D,cAAM,KAAK,WAAW;AACtB,eAAO,KAAK,YAAY,IAAI,aAAa;AAAA,MAC3C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,MAAM,eAAe,eAAyD;AAC5E,cAAM,KAAK,WAAW;AACtB,cAAM,SAAS,KAAK,YAAY,IAAI,aAAa;AACjD,eAAO,QAAQ;AAAA,MACjB;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAM,2BAAmD;AACvD,cAAM,KAAK,WAAW;AACtB,eAAO,KAAK,cAAc,IAAI,YAAU,OAAO,WAAW;AAAA,MAC5D;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAM,0BAAkD;AACtD,cAAM,KAAK,WAAW;AACtB,eAAO,KAAK,aAAa,IAAI,YAAU,OAAO,WAAW;AAAA,MAC3D;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAM,qBAA6C;AACjD,cAAM,KAAK,WAAW;AACtB,eAAO;AAAA,UACL,GAAG,KAAK,cAAc,IAAI,YAAU,OAAO,WAAW;AAAA,UACtD,GAAG,KAAK,aAAa,IAAI,YAAU,OAAO,WAAW;AAAA,QACvD;AAAA,MACF;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,MAOA,MAAM,iBAAiB,WAA2C;AAChE,cAAM,MAAM,UAAU;AACtB,cAAM,WAAW,IAAI,YAAY;AAEjC,YAAI,SAAS,SAAS,aAAa,KAAK,SAAS,SAAS,YAAY,GAAG;AACvE,gBAAM,aAAa,IAAI,MAAM,wBAAwB;AACrD,gBAAM,cAAc,IAAI,MAAM,uBAAuB;AACrD,cAAI,cAAc,aAAa;AAC7B,mBAAO,eAAe,WAAW,CAAC,CAAC,gBAAgB,YAAY,CAAC,CAAC;AAAA,UACnE;AAAA,QACF;AAEA,YAAI,SAAS,SAAS,cAAc,GAAG;AACrC,gBAAM,aAAa,IAAI,MAAM,6CAA6C;AAC1E,cAAI,YAAY;AACd,mBAAO,cAAc,WAAW,CAAC,CAAC;AAAA,UACpC;AAAA,QACF;AAEA,YAAI,SAAS,SAAS,aAAa,KAAK,SAAS,SAAS,gBAAgB,GAAG;AAC3E,gBAAM,aAAa,IAAI,MAAM,wBAAwB;AACrD,gBAAM,kBAAkB,IAAI,MAAM,2BAA2B;AAC7D,cAAI,cAAc,iBAAiB;AACjC,mBAAO,eAAe,WAAW,CAAC,CAAC,oBAAoB,gBAAgB,CAAC,CAAC;AAAA,UAC3E;AAAA,QACF;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA;AAAA,MAMA,MAAM,WAMH;AACD,cAAM,KAAK,WAAW;AAEtB,cAAM,kBAAkB,MAAM,KAAK,mBAAmB;AACtD,cAAM,yBAAiD,CAAC;AAExD,wBAAgB,QAAQ,CAAAA,kBAAe;AACrC,iCAAuBA,cAAY,QAAQ,KAAK,uBAAuBA,cAAY,QAAQ,KAAK,KAAK;AAAA,QACvG,CAAC;AAED,eAAO;AAAA,UACL,mBAAmB,gBAAgB;AAAA,UACnC,oBAAoB,KAAK,cAAc;AAAA,UACvC,mBAAmB,KAAK,aAAa;AAAA,UACrC;AAAA,UACA,YAAY,KAAK,cAAc;AAAA,QACjC;AAAA,MACF;AAAA,IACF;AAAA;AAAA;;;AC9XA,OAAO,QAAQ;AACf,OAAO,UAAU;AACjB,OAAO,YAAY;AACnB,OAAO,SAAS;AAShB,eAAsB,oBAAoB,eAA+C;AACvF,MAAI;AACF,UAAM,QAAQ,MAAM,GAAG,QAAQ,aAAa;AAC5C,UAAM,iBAAiB,MACpB,OAAO,UAAQ,KAAK,SAAS,MAAM,CAAC,EACpC,KAAK,CAAC,GAAG,MAAM;AAEd,YAAM,UAAU,EAAE,MAAM,GAAG,EAAE,CAAC;AAC9B,YAAM,UAAU,EAAE,MAAM,GAAG,EAAE,CAAC;AAC9B,aAAO,QAAQ,cAAc,OAAO;AAAA,IACtC,CAAC;AAEH,WAAO,eAAe,SAAS,IAAI,eAAe,CAAC,IAAI;AAAA,EACzD,SAAS,OAAO;AACd,WAAO;AAAA,EACT;AACF;AAOA,eAAsB,mBAAmB,UAA0C;AACjF,QAAM,UAAU,MAAM,GAAG,SAAS,UAAU,OAAO;AACnD,QAAM,WAAW,KAAK,SAAS,QAAQ;AAGvC,QAAM,WAAW,OAAO,WAAW,QAAQ,EAAE,OAAO,OAAO,EAAE,OAAO,KAAK;AAGzE,QAAM,YAAY,6BAA6B,QAAQ;AAGvD,QAAM,aAAa,MAAM,mBAAmB,OAAO;AAInD,QAAM,YAAY;AAClB,QAAM,cAAc;AAEpB,SAAO;AAAA,IACL,MAAM;AAAA,IACN,MAAM;AAAA,IACN,IAAI;AAAA,IACJ,MAAM;AAAA,IACN;AAAA,IACA;AAAA,IACA;AAAA,EACF;AACF;AAOA,SAAS,6BAA6B,UAAwB;AAE5D,QAAM,iBAAiB,SAAS,MAAM,WAAW;AACjD,MAAI,gBAAgB;AAElB,UAAM,QAAO,oBAAI,KAAK,GAAE,YAAY;AACpC,UAAM,SAAQ,oBAAI,KAAK,GAAE,SAAS;AAClC,UAAM,OAAM,oBAAI,KAAK,GAAE,QAAQ;AAC/B,WAAO,IAAI,KAAK,MAAM,OAAO,KAAK,GAAG,GAAG,GAAG,SAAS,eAAe,CAAC,CAAC,CAAC;AAAA,EACxE;AAGA,SAAO,oBAAI,KAAK;AAClB;AAOA,eAAsB,mBAAmB,SAA0C;AACjF,QAAM,aAA6B,CAAC;AACpC,QAAM,SAAS,IAAI,OAAO;AAG1B,QAAM,aAAa,QAChB,MAAM,+BAA+B,EACrC,IAAI,UAAQ,KAAK,KAAK,CAAC,EACvB,OAAO,UAAQ,QAAQ,CAAC,KAAK,MAAM,6BAA6B,KAAK,SAAS,GAAG;AAEpF,MAAI,aAAa;AAEjB,aAAW,aAAa,YAAY;AAClC,QAAI,CAAC,UAAU,KAAK,EAAG;AAEvB,QAAI;AAEF,YAAM,MAAM,OAAO,OAAO,WAAW,EAAE,UAAU,SAAS,CAAC;AAC3D,YAAM,YAAY,wBAAwB,KAAK,WAAW,UAAU;AACpE,UAAI,WAAW;AACb,mBAAW,KAAK,SAAS;AAAA,MAC3B;AAAA,IACF,SAAS,OAAO;AAEd,iBAAW,KAAK;AAAA,QACd,MAAM;AAAA,QACN,KAAK;AAAA,QACL,MAAM;AAAA,MACR,CAAC;AAAA,IACH;AAGA,mBAAe,UAAU,MAAM,KAAK,KAAK,CAAC,GAAG,SAAS;AAAA,EACxD;AAEA,SAAO;AACT;AASA,SAAS,wBAAwB,KAAU,KAAa,MAAmC;AACzF,MAAI,CAAC,OAAO,CAAC,IAAI,KAAM,QAAO;AAE9B,QAAM,YAA0B;AAAA,IAC9B,MAAM;AAAA,IACN;AAAA,IACA;AAAA,EACF;AAEA,UAAQ,IAAI,MAAM,YAAY,GAAG;AAAA,IAC/B,KAAK;AACH,UAAI,IAAI,YAAY,SAAS;AAC3B,kBAAU,OAAO;AACjB,kBAAU,QAAQ,IAAI,QAAQ,CAAC,GAAG,SAAS,wBAAwB,GAAG;AAAA,MACxE,WAAW,IAAI,YAAY,SAAS;AAClC,kBAAU,OAAO;AACjB,kBAAU,QAAQ,IAAI,SAAS,wBAAwB,GAAG;AAC1D,kBAAU,QAAQ,IAAI,QAAQ,CAAC,GAAG,SAAS,6BAA6B,GAAG;AAAA,MAC7E;AACA;AAAA,IAEF,KAAK;AACH,UAAI,IAAI,YAAY,SAAS;AAC3B,kBAAU,OAAO;AACjB,kBAAU,QAAQ,IAAI,OAAO,CAAC,GAAG,SAAS,wBAAwB,GAAG;AAAA,MACvE,WAAW,IAAI,YAAY,SAAS;AAClC,kBAAU,OAAO;AACjB,kBAAU,QAAQ,IAAI,QAAQ,wBAAwB,GAAG;AAAA,MAC3D;AACA;AAAA,IAEF,KAAK;AACH,gBAAU,OAAO;AACjB,gBAAU,QAAQ,IAAI,QAAQ,CAAC,GAAG,SAAS,wBAAwB,GAAG;AACtE;AAAA,IAEF,KAAK;AACH,gBAAU,OAAO;AACjB,gBAAU,QAAQ,IAAI,QAAQ,CAAC,GAAG,SAAS,wBAAwB,GAAG;AACtE;AAAA,IAEF,KAAK;AACH,gBAAU,OAAO;AACjB,gBAAU,QAAQ,IAAI,QAAQ,CAAC,GAAG,SAAS,wBAAwB,GAAG;AACtE;AAAA,IAEF,KAAK;AACH,gBAAU,OAAO;AACjB,gBAAU,QAAQ,IAAI,QAAQ,CAAC,GAAG,SAAS,wBAAwB,GAAG;AACtE;AAAA,EACJ;AAEA,SAAO;AACT;AAOA,SAAS,wBAAwB,KAAiC;AAEhE,QAAM,WAAW;AAAA,IACf;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,aAAW,WAAW,UAAU;AAC9B,UAAM,QAAQ,IAAI,MAAM,OAAO;AAC/B,QAAI,OAAO;AACT,aAAO,MAAM,CAAC;AAAA,IAChB;AAAA,EACF;AAEA,SAAO;AACT;AAOA,SAAS,wBAAwB,KAAiC;AAChE,QAAM,WAAW;AAAA,IACf;AAAA,IACA;AAAA,EACF;AAEA,aAAW,WAAW,UAAU;AAC9B,UAAM,QAAQ,IAAI,MAAM,OAAO;AAC/B,QAAI,OAAO;AACT,aAAO,MAAM,CAAC;AAAA,IAChB;AAAA,EACF;AAEA,SAAO;AACT;AAOA,SAAS,6BAA6B,KAAiC;AACrE,QAAM,QAAQ,IAAI,MAAM,uBAAuB;AAC/C,SAAO,QAAQ,MAAM,CAAC,IAAI;AAC5B;AAwBO,SAAS,gBAAgB,UAA2B;AACzD,SAAO,KAAK,QAAQ,QAAQ,EAAE,YAAY,MAAM;AAClD;AAQA,eAAsB,sBAAsB,UAAkB,eAAwC;AACpG,MAAI;AAEJ,MAAI,KAAK,WAAW,QAAQ,GAAG;AAC7B,mBAAe;AAAA,EACjB,OAAO;AACL,mBAAe,KAAK,QAAQ,eAAe,QAAQ;AAAA,EACrD;AAEA,MAAI,CAAC,MAAM,GAAG,WAAW,YAAY,GAAG;AACtC,UAAM,IAAI,MAAM,6BAA6B,YAAY,EAAE;AAAA,EAC7D;AAEA,MAAI,CAAC,gBAAgB,YAAY,GAAG;AAClC,UAAM,IAAI,MAAM,iCAAiC,YAAY,EAAE;AAAA,EACjE;AAEA,SAAO;AACT;AA5SA,IAQQ;AARR;AAAA;AAAA;AAQA,KAAM,EAAE,WAAW;AAAA;AAAA;;;ACRnB;AAAA;AAAA;AAAA;AAKA,SAAS,WAAAC,UAAS,OAAAC,YAAW;AAG7B,OAAOC,SAAQ;AACf,OAAOC,WAAU;AACjB,OAAO,QAAQ;AASf,eAAsB,eAAe,SAAyB,eAA6C;AAEzG,QAAMC,WAAU,kBAAkB;AAElC,MAAI;AACF,UAAM,cAAc,QAAQ,UAAUD,MAAK,QAAQ,QAAQ,OAAO,IAAI,QAAQ,IAAI;AAClF,UAAM,MAAM,MAAM,cAAc,eAAe,WAAW;AAC1D,UAAM,SAAS,IAAI,aAAa,IAAI,kBAAkB;AACtD,UAAM,gBAAgB,OAAO,kBAAkB;AAC/C,UAAM,wBAAwBA,MAAK,QAAQ,aAAa,aAAa;AAErE,QAAI,gBAAgB,QAAQ;AAG5B,QAAI,CAAC,eAAe;AAClB,YAAM,aAAa,MAAM,oBAAoB,qBAAqB;AAClE,UAAI,CAAC,YAAY;AACf,qBAAa,4BAA4B,CAAC,cAAc,qBAAqB,EAAE,CAAC;AAChF;AAAA,MACF;AACA,sBAAgB;AAChB,kBAAY,kCAAkC,GAAG,KAAK,aAAa,CAAC,EAAE;AAAA,IACxE;AAGA,QAAI;AACJ,QAAI;AACF,iBAAW,MAAM,sBAAsB,eAAe,qBAAqB;AAAA,IAC7E,SAAS,OAAO;AACd,mBAAa,oCAAoC,CAAC,iBAAiB,QAAQ,MAAM,UAAU,0BAA0B,CAAC;AACtH;AAAA,IACF;AAGA,UAAM,cAAcC,SAAQ,MAAM,2BAA2B;AAC7D,QAAI,WAAW;AAEf,QAAI;AACF,OAAC,WAAW,MAAM,IAAI,MAAM,QAAQ,IAAI;AAAA,QACtC,mBAAmB,QAAQ;AAAA,QAC3B,IAAI,QAAQ,CAAAC,aAAW;AACrB,gBAAM,MAAM,IAAI,kBAAkB;AAClC,UAAAA,SAAQ,GAAG;AAAA,QACb,CAAC;AAAA,MACH,CAAC;AACD,kBAAY,QAAQ,oCAAoC;AAAA,IAC1D,SAAS,OAAO;AACd,kBAAY,KAAK,+BAA+B;AAChD,mBAAa,eAAe,CAAC,iBAAiB,QAAQ,MAAM,UAAU,eAAe,CAAC;AACtF;AAAA,IACF;AAEA,IAAAJ,KAAI,KAAK,EAAE;AACX,gBAAY,8CAAuC,GAAG,KAAK,UAAU,IAAI,CAAC,EAAE;AAC5E,IAAAA,KAAI,KAAK,EAAE;AAGX,IAAAA,KAAI,KAAK,GAAG,KAAK,GAAG,KAAK,oEAAsC,CAAC,CAAC;AACjE,UAAM,gBAAgBG,SAAQ,MAAM,+BAA+B;AAEnE,QAAI;AACF,YAAM,qBAAqB,MAAO,OAAe,yBAAyB,SAAS;AAEnF,UAAI,mBAAmB,SAAS,GAAG;AACjC,sBAAc,QAAQ,SAAS,mBAAmB,MAAM,kBAAkB;AAG1E,mBAAWE,iBAAe,oBAAoB;AAC5C,gBAAM,WAAW,MAAO,OAAe,uBAAuBA,cAAY,IAAI,SAAS;AACvF,cAAI,YAAY,SAAS,OAAO,SAAS,GAAG;AAC1C,2BAAe,GAAGA,cAAY,IAAI,IAAI,CAACA,cAAY,WAAW,CAAC;AAC/D,uBAAW,SAAS,SAAS,QAAQ;AACnC,cAAAL,KAAI,KAAK,OAAO,GAAG,IAAI,QAAG,CAAC,IAAI,MAAM,WAAW,IAAI,GAAG,KAAK,SAAS,MAAM,IAAI,GAAG,CAAC,EAAE;AACrF,cAAAA,KAAI,KAAK,OAAO,GAAG,KAAK,YAAO,MAAM,cAAc,CAAC,EAAE;AAAA,YACxD;AACA,YAAAA,KAAI,KAAK,EAAE;AAAA,UACb,OAAO;AACL,wBAAY,GAAGK,cAAY,IAAI,IAAI,CAACA,cAAY,WAAW,CAAC;AAAA,UAC9D;AAAA,QACF;AAGA,cAAM,cAAc,MAAMN,SAAQ;AAAA,UAChC,SAAS,GAAG,KAAK,wCAAwC;AAAA,UACzD,cAAc;AAAA,QAChB,CAAC;AAED,YAAI,aAAa;AACf,gBAAM,eAAeI,SAAQ,MAAM,iCAAiC;AACpE,cAAI;AACF,kBAAM,kBAAkB,MAAO,OAAe,kBAAkB,UAAU,IAAI,WAAW,kBAAkB;AAC3G,kBAAMF,IAAG,UAAU,UAAU,iBAAiB,OAAO;AAGrD,sBAAU,KAAK;AAEf,yBAAa,QAAQ,0CAA0C;AAC/D,2BAAe,iCAAiC,CAAC,WAAW,mBAAmB,MAAM,iBAAiB,CAAC;AAAA,UACzG,SAAS,OAAO;AACd,yBAAa,KAAK,qCAAqC;AACvD,yBAAa,qBAAqB,CAAC,iBAAiB,QAAQ,MAAM,UAAU,eAAe,CAAC;AAC5F;AAAA,UACF;AAAA,QACF,OAAO;AACL,sBAAY,8BAA8B;AAAA,QAC5C;AAAA,MACF,OAAO;AACL,sBAAc,QAAQ,gDAAgD;AAAA,MACxE;AAAA,IACF,SAAS,OAAO;AACd,oBAAc,KAAK,8BAA8B;AACjD,mBAAa,mBAAmB,CAAC,iBAAiB,QAAQ,MAAM,UAAU,eAAe,CAAC;AAC1F;AAAA,IACF;AAEA,IAAAD,KAAI,KAAK,EAAE;AAGX,IAAAA,KAAI,KAAK,GAAG,KAAK,GAAG,MAAM,mEAAqC,CAAC,CAAC;AACjE,UAAM,eAAeG,SAAQ,MAAM,qDAAqD;AAExF,QAAI;AACF,YAAM,oBAAoB,MAAO,OAAe,wBAAwB,SAAS;AAEjF,UAAI,kBAAkB,SAAS,GAAG;AAChC,qBAAa,QAAQ,SAAS,kBAAkB,MAAM,gCAAgC;AAGtF,mBAAWE,iBAAe,mBAAmB;AAC3C,gBAAM,WAAW,MAAO,OAAe,uBAAuBA,cAAY,IAAI,SAAS;AACvF,cAAI,YAAY,SAAS,OAAO,SAAS,GAAG;AAC1C,wBAAY,GAAGA,cAAY,IAAI,IAAI,CAACA,cAAY,WAAW,CAAC;AAC5D,uBAAW,SAAS,SAAS,QAAQ;AACnC,cAAAL,KAAI,KAAK,OAAO,GAAG,OAAO,QAAG,CAAC,IAAI,MAAM,WAAW,IAAI,GAAG,KAAK,SAAS,MAAM,IAAI,GAAG,CAAC,EAAE;AACxF,cAAAA,KAAI,KAAK,OAAO,GAAG,KAAK,YAAO,MAAM,cAAc,CAAC,EAAE;AAAA,YACxD;AACA,YAAAA,KAAI,KAAK,EAAE;AAAA,UACb,OAAO;AACL,wBAAY,GAAGK,cAAY,IAAI,IAAI,CAACA,cAAY,WAAW,CAAC;AAAA,UAC9D;AAAA,QACF;AAGA,cAAM,aAAa,MAAMN,SAAQ;AAAA,UAC/B,SAAS,GAAG,KAAK,uCAAuC;AAAA,UACxD,cAAc;AAAA,QAChB,CAAC;AAED,YAAI,YAAY;AACd,gBAAM,eAAeI,SAAQ,MAAM,gCAAgC;AACnE,cAAI;AACF,kBAAM,kBAAkB,MAAO,OAAe,kBAAkB,UAAU,IAAI,WAAW,iBAAiB;AAC1G,kBAAMF,IAAG,UAAU,UAAU,iBAAiB,OAAO;AAErD,yBAAa,QAAQ,yCAAyC;AAC9D,2BAAe,uCAAuC,CAAC,WAAW,kBAAkB,MAAM,iBAAiB,CAAC;AAAA,UAC9G,SAAS,OAAO;AACd,yBAAa,KAAK,oCAAoC;AACtD,yBAAa,qBAAqB,CAAC,iBAAiB,QAAQ,MAAM,UAAU,eAAe,CAAC;AAC5F;AAAA,UACF;AAAA,QACF,OAAO;AACL,sBAAY,6BAA6B;AAAA,QAC3C;AAAA,MACF,OAAO;AACL,qBAAa,QAAQ,gEAAgE;AAAA,MACvF;AAAA,IACF,SAAS,OAAO;AACd,mBAAa,KAAK,6BAA6B;AAC/C,mBAAa,mBAAmB,CAAC,iBAAiB,QAAQ,MAAM,UAAU,eAAe,CAAC;AAC1F;AAAA,IACF;AAEA,IAAAD,KAAI,KAAK,EAAE;AACX,mBAAe,sDAAiD;AAAA,MAC9D,4BAA4B,GAAG,KAAKE,MAAK,SAAS,aAAa,QAAQ,CAAC,CAAC;AAAA,IAC3E,CAAC;AAAA,EAEH,SAAS,OAAO;AACd,iBAAa,8BAA8B,CAAC,iBAAiB,QAAQ,MAAM,UAAU,eAAe,CAAC;AAAA,EACvG;AACF;AAxMA;AAAA;AAAA;AAMA;AACA;AAIA;AACA;AAAA;AAAA;;;ACZA;AAAA;AAAA;AAAA;AAIA,SAAS,OAAO,aAAa;AAG7B,OAAOI,SAAQ;AACf,OAAOC,WAAU;AACjB,OAAOC,SAAQ;AAQf,eAAsB,gBAAgB,SAA0B,eAA6C;AAC3G,QAAM,cAAc,QAAQ,UAAUD,MAAK,QAAQ,QAAQ,OAAO,IAAI,QAAQ,IAAI;AAClF,QAAM,MAAM,MAAM,cAAc,eAAe,WAAW;AAC1D,QAAM,SAAS,IAAI,aAAa,IAAI,kBAAkB;AACtD,QAAM,gBAAgB,OAAO,kBAAkB;AAC/C,QAAM,wBAAwBA,MAAK,QAAQ,aAAa,aAAa;AAErE,MAAI,gBAAgB,QAAQ;AAE5B,MAAI,CAAC,eAAe;AAClB,UAAM,QAAQ,MAAMD,IAAG,QAAQ,qBAAqB;AACpD,UAAM,iBAAiB,MAAM,OAAO,UAAQ,KAAK,SAAS,MAAM,CAAC,EAAE,KAAK;AACxE,QAAI,eAAe,WAAW,GAAG;AAC/B,cAAQ,IAAIE,IAAG,OAAO,2BAA2B,CAAC;AAClD;AAAA,IACF;AACA,oBAAgB,eAAe,eAAe,SAAS,CAAC;AAAA,EAC1D;AAEA,QAAM,WAAWD,MAAK,KAAK,uBAAuB,aAAa;AAC/D,MAAI,CAAC,MAAMD,IAAG,WAAW,QAAQ,GAAG;AAClC,YAAQ,IAAIE,IAAG,IAAI,mBAAmB,QAAQ,EAAE,CAAC;AACjD;AAAA,EACF;AAEA,QAAM,UAAU,MAAMF,IAAG,SAAS,UAAU,OAAO;AACnD,QAAM,SAAS,IAAI,kBAAkB;AAErC,QAAM,uCAAgC;AAEtC,QAAM,gBAAgB,cAAc,+BAA+B,EAAE,MAAM;AAC3E,QAAM,qBAAqB,MAAM,OAAO,yBAAyB;AAAA,IAC/D,MAAM;AAAA,IACN,MAAM;AAAA,IACN,IAAI;AAAA,IACJ,MAAM;AAAA,IACN,WAAW,oBAAI,KAAK;AAAA,IACpB,YAAY,CAAC;AAAA,IACb,UAAU;AAAA,EACZ,CAAC;AAED,MAAI,mBAAmB,SAAS,GAAG;AACjC,kBAAc,KAAK,gCAAyB;AAC5C,uBAAmB,QAAQ,OAAK;AAC9B,cAAQ,IAAI,OAAOE,IAAG,OAAO,EAAE,IAAI,CAAC,KAAK,EAAE,WAAW,EAAE;AAAA,IAC1D,CAAC;AAAA,EACH,OAAO;AACL,kBAAc,QAAQ,gCAA2B;AAAA,EACnD;AAEA,QAAM,6BAAwB;AAChC;AApEA;AAAA;AAAA;AAKA;AACA;AAIA;AAAA;AAAA;;;ACVA;AAAA;AAAA;AAAA;AAIA,SAAS,SAAAC,QAAO,SAAAC,cAAa;AAG7B,OAAOC,SAAQ;AACf,OAAOC,WAAU;AACjB,OAAOC,SAAQ;AAEf,SAAS,iBAAiB;AAO1B,eAAsB,YAAY,SAAsB,eAA6C;AACnG,QAAM,cAAc,QAAQ,UAAUD,MAAK,QAAQ,QAAQ,OAAO,IAAI,QAAQ,IAAI;AAClF,QAAM,MAAM,MAAM,cAAc,eAAe,WAAW;AAC1D,QAAM,SAAS,IAAI,aAAa,IAAI,kBAAkB;AACtD,QAAM,gBAAgB,OAAO,kBAAkB;AAC/C,QAAM,wBAAwBA,MAAK,QAAQ,aAAa,aAAa;AAErE,MAAI,gBAAgB,QAAQ;AAE5B,MAAI,CAAC,eAAe;AAClB,UAAM,QAAQ,MAAMD,IAAG,QAAQ,qBAAqB;AACpD,UAAM,iBAAiB,MAAM,OAAO,UAAQ,KAAK,SAAS,MAAM,CAAC,EAAE,KAAK;AACxE,QAAI,eAAe,WAAW,GAAG;AAC/B,cAAQ,IAAIE,IAAG,OAAO,2BAA2B,CAAC;AAClD;AAAA,IACF;AACA,oBAAgB,eAAe,eAAe,SAAS,CAAC;AAAA,EAC1D;AAEA,QAAM,WAAWD,MAAK,KAAK,uBAAuB,aAAa;AAC/D,MAAI,CAAC,MAAMD,IAAG,WAAW,QAAQ,GAAG;AAClC,YAAQ,IAAIE,IAAG,IAAI,mBAAmB,QAAQ,EAAE,CAAC;AACjD;AAAA,EACF;AAEA,QAAM,UAAU,MAAMF,IAAG,SAAS,UAAU,OAAO;AACnD,QAAM,SAAS,IAAI,kBAAkB;AAErC,EAAAF,OAAM,gCAAyB;AAE/B,QAAM,YAAY;AAAA,IAChB,MAAM;AAAA,IACN,MAAM;AAAA,IACN,IAAI;AAAA,IACJ,MAAM;AAAA,IACN,WAAW,oBAAI,KAAK;AAAA,IACpB,YAAY,CAAC;AAAA,IACb,UAAU;AAAA,EACZ;AAEA,QAAM,qBAAqB,MAAM,OAAO,yBAAyB,SAAS;AAC1E,QAAM,oBAAoB,MAAM,OAAO,wBAAwB,SAAS;AAExE,QAAM,kBAAkB,CAAC,GAAG,oBAAoB,GAAG,iBAAiB;AAEpE,MAAI,gBAAgB,SAAS,GAAG;AAC9B,UAAM,aAAa,MAAM,OAAO,kBAAkB,SAAS,WAAW,eAAe;AACrF,UAAM,OAAO,UAAU,SAAS,UAAU;AAE1C,YAAQ,IAAII,IAAG,KAAK;AAAA,cACV,aAAa;AAAA,CAC1B,CAAC;AAEE,SAAK,QAAQ,UAAQ;AACnB,YAAM,QAAQ,KAAK,QAAQA,IAAG,QAAQ,KAAK,UAAUA,IAAG,MAAMA,IAAG;AACjE,cAAQ,OAAO,MAAM,MAAM,KAAK,KAAK,CAAC;AAAA,IACxC,CAAC;AAED,YAAQ,IAAI;AAAA,EACd,OAAO;AACL,YAAQ,IAAIA,IAAG,MAAM,kCAA6B,CAAC;AAAA,EACrD;AAEA,EAAAH,OAAM,0BAAmB;AAC3B;AAlFA;AAAA;AAAA;AAKA;AAKA;AAAA;AAAA;;;ACVA;AAAA;AAAA;AAAA;AAIA,SAAS,SAAAI,QAAO,SAAAC,cAAa;AAG7B,OAAOC,SAAQ;AACf,OAAOC,WAAU;AACjB,OAAOC,SAAQ;AAQf,eAAsB,gBAAgB,SAA0B,eAA6C;AAC3G,QAAM,cAAc,QAAQ,UAAUD,MAAK,QAAQ,QAAQ,OAAO,IAAI,QAAQ,IAAI;AAClF,QAAM,MAAM,MAAM,cAAc,eAAe,WAAW;AAC1D,QAAM,SAAS,IAAI,aAAa,IAAI,kBAAkB;AACtD,QAAM,gBAAgB,OAAO,kBAAkB;AAC/C,QAAM,wBAAwBA,MAAK,QAAQ,aAAa,aAAa;AAErE,MAAI,gBAAgB,QAAQ;AAE5B,MAAI,CAAC,eAAe;AAClB,UAAM,QAAQ,MAAMD,IAAG,QAAQ,qBAAqB;AACpD,UAAM,iBAAiB,MAAM,OAAO,UAAQ,KAAK,SAAS,MAAM,CAAC,EAAE,KAAK;AACxE,QAAI,eAAe,WAAW,GAAG;AAC/B,cAAQ,IAAIE,IAAG,OAAO,2BAA2B,CAAC;AAClD;AAAA,IACF;AACA,oBAAgB,eAAe,eAAe,SAAS,CAAC;AAAA,EAC1D;AAEA,QAAM,WAAWD,MAAK,KAAK,uBAAuB,aAAa;AAC/D,MAAI,CAAC,MAAMD,IAAG,WAAW,QAAQ,GAAG;AAClC,YAAQ,IAAIE,IAAG,IAAI,mBAAmB,QAAQ,EAAE,CAAC;AACjD;AAAA,EACF;AAEA,QAAM,UAAU,MAAMF,IAAG,SAAS,UAAU,OAAO;AACnD,QAAM,SAAS,IAAI,kBAAkB;AAErC,EAAAF,OAAM,mCAA8B;AAEpC,QAAM,iBAAiB,MAAM,OAAO,iBAAiB;AAAA,IACnD,MAAM;AAAA,IACN,MAAM;AAAA,IACN,IAAI;AAAA,IACJ,MAAM;AAAA,IACN,WAAW,oBAAI,KAAK;AAAA,IACpB,YAAY,CAAC;AAAA,IACb,UAAU;AAAA,EACZ,CAAC;AAED,UAAQ,IAAII,IAAG,KAAK;AAAA,sBACA,aAAa;AAAA,CAClC,CAAC;AACA,UAAQ,IAAIA,IAAG,KAAK,cAAc,CAAC;AAEnC,EAAAH,OAAM,mCAA8B;AACtC;AA/DA;AAAA;AAAA;AAKA;AAKA;AAAA;AAAA;;;ACVA;AAAA;AAAA;AAAA;AAAA;;;ACAA;AAAA;AAAA;AAAA;AAAA;;;ACAA;AAAA;AAAA;AAAA;AAAA;;;ACAA;AAAA;AAAA;AAAA;AAAA;;;ACAA,IAAAI,eAAA;AAAA;AAAA;AAAA;AAAA;;;ACAA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA,IAAAC;AAAA;AAAA;;;ACDA,OAAOC,SAAQ;AAEf,SAAS,MAAM,WAAAC,UAAS,gBAAyB;AAMjD,eAAsB,OAAOC,OAAgC;AAC3D,MAAI;AACF,UAAM,OAAOA,KAAI;AACjB,WAAO;AAAA,EACT,QAAQ;AACN,WAAO;AAAA,EACT;AACF;AAKA,eAAsB,eAAeA,OAAc,WAAmB,QAAQ,IAAI,GAAsB;AACtG,QAAM,eAAeD,SAAQ,UAAUC,KAAI;AAC3C,QAAM,eAAe,SAAS,UAAU,YAAY;AACpD,QAAM,aAAa,MAAM,OAAO,YAAY;AAE5C,SAAO;AAAA,IACL,UAAU;AAAA,IACV,UAAU;AAAA,IACV,QAAQ;AAAA,EACV;AACF;AAKA,eAAsB,gBAAgBA,OAAuC;AAC3E,MAAI;AACF,UAAM,UAAU,MAAM,SAASA,OAAM,OAAO;AAC5C,WAAO,EAAE,SAAS,MAAM,MAAM,QAAQ;AAAA,EACxC,SAAS,OAAO;AACd,WAAO;AAAA,MACL,SAAS;AAAA,MACT,OAAO,iBAAiB,QAAQ,QAAQ,IAAI,MAAM,4BAA4B;AAAA,IAChF;AAAA,EACF;AACF;AA0CA,eAAsB,UACpB,WACA,SACA,YAAqB,MACF;AACnB,QAAM,QAAkB,CAAC;AAEzB,MAAI;AACF,UAAM,QAAQ,MAAM,QAAQ,WAAW,EAAE,eAAe,KAAK,CAAC;AAE9D,eAAW,QAAQ,OAAO;AACxB,YAAM,WAAW,KAAK,WAAW,KAAK,IAAI;AAE1C,UAAI,KAAK,YAAY,KAAK,WAAW;AACnC,cAAM,WAAW,MAAM,UAAU,UAAU,SAAS,SAAS;AAC7D,cAAM,KAAK,GAAG,QAAQ;AAAA,MACxB,WAAW,KAAK,OAAO,KAAK,QAAQ,KAAK,KAAK,IAAI,GAAG;AACnD,cAAM,KAAK,QAAQ;AAAA,MACrB;AAAA,IACF;AAAA,EACF,QAAQ;AAAA,EAER;AAEA,SAAO;AACT;AAaA,eAAsB,aAAsBA,OAAkC;AAC5E,QAAM,aAAa,MAAM,gBAAgBA,KAAI;AAE7C,MAAI,CAAC,WAAW,SAAS;AACvB,WAAO;AAAA,EACT;AAEA,MAAI;AACF,UAAM,OAAO,KAAK,MAAM,WAAW,IAAI;AACvC,WAAO,EAAE,SAAS,MAAM,KAAK;AAAA,EAC/B,SAAS,OAAO;AACd,WAAO;AAAA,MACL,SAAS;AAAA,MACT,OAAO,IAAI,MAAM,wBAAwBA,KAAI,KAAK,iBAAiB,QAAQ,MAAM,UAAU,eAAe,EAAE;AAAA,IAC9G;AAAA,EACF;AACF;AAjJA,IAKQ,UAAU,WAAW,QAAQ,MAAM;AAL3C;AAAA;AAAA;AAKA,KAAM,EAAE,UAAU,WAAW,QAAQ,MAAM,YAAYF;AAAA;AAAA;;;ACLvD;AAAA;AAAA;AAAA;AAAA;;;ACAA;AAAA;AAAA;AAAA;AAAA;;;ACAA,OAAOG,SAAQ;AACf,OAAOC,WAAU;AADjB,IAAAC,eAAA;AAAA;AAAA;AAGA;AAAA;AAAA;;;ACHA;AAAA;AAAA;AACA;AACA;AACA;AACA,IAAAC;AAAA;AAAA;;;ACJA;AAAA;AAAA;AACA;AACA;AAAA;AAAA;;;ACEA,SAAS,QAAAC,aAAY;AAJrB,IASsB;AATtB;AAAA;AAAA;AAOA;AAEO,IAAe,kBAAf,MAAsD;AAAA;AAAA;AAAA;AAAA,MAqB3D,MAAgB,6BACd,aACA,cACiD;AACjD,cAAM,kBAAkBA,MAAK,aAAa,cAAc;AACxD,cAAM,gBAAgB,MAAM,aAAkG,eAAe;AAE7I,YAAI,CAAC,cAAc,SAAS;AAC1B,iBAAO,EAAE,OAAO,CAAC,GAAG,SAAS,aAAa;AAAA,QAC5C;AAEA,cAAM,UAAU;AAAA,UACd,GAAG,cAAc,KAAK;AAAA,UACtB,GAAG,cAAc,KAAK;AAAA,QACxB;AAEA,cAAM,QAAQ,aAAa,OAAO,SAAO,OAAO,OAAO;AACvD,cAAM,UAAU,aAAa,OAAO,SAAO,EAAE,OAAO,QAAQ;AAE5D,eAAO,EAAE,OAAO,QAAQ;AAAA,MAC1B;AAAA;AAAA;AAAA;AAAA,MAKA,MAAgB,WACd,aACA,WACsD;AACtD,cAAM,WAAuB,CAAC;AAC9B,cAAM,UAAoB,CAAC;AAE3B,mBAAW,YAAY,WAAW;AAChC,gBAAM,WAAWA,MAAK,aAAa,QAAQ;AAC3C,gBAAM,aAAa,MAAM,OAAO,QAAQ;AAExC,cAAI,YAAY;AACd,qBAAS,KAAK,MAAM,eAAe,UAAU,WAAW,CAAC;AAAA,UAC3D,OAAO;AACL,oBAAQ,KAAK,QAAQ;AAAA,UACvB;AAAA,QACF;AAEA,eAAO,EAAE,UAAU,QAAQ;AAAA,MAC7B;AAAA;AAAA;AAAA;AAAA,MAKA,MAAgB,mBACd,aACA,UACA,cAAwB,CAAC,GAAG,GACT;AACnB,cAAM,WAAqB,CAAC;AAE5B,mBAAW,aAAa,aAAa;AACnC,gBAAM,gBAAgBA,MAAK,aAAa,SAAS;AAEjD,qBAAW,WAAW,UAAU;AAC9B,kBAAM,QAAQ,MAAM,UAAU,eAAe,SAAS,IAAI;AAC1D,qBAAS,KAAK,GAAG,KAAK;AAAA,UACxB;AAAA,QACF;AAEA,eAAO;AAAA,MACT;AAAA;AAAA;AAAA;AAAA,MAKU,oBAAoB,UAInB;AACT,YAAI,SAAS,SAAS,UAAU,GAAG;AACjC,iBAAO;AAAA,QACT;AAEA,cAAM,gBAAgB,SAAS,SAAS,QAAQ,SAAS,SAAS;AAClE,cAAM,gBAAgB,SAAS,SAAS,QAAQ,IAC5C,SAAS,SAAS,QAAQ,SAAS,SAAS,QAC5C;AAGJ,cAAM,YAAY,gBAAgB;AAGlC,cAAM,aAAa,gBAAgB;AAGnC,cAAM,UAAU,KAAK,IAAI,SAAS,WAAW,KAAK,GAAG;AAErD,eAAO,KAAK,IAAI,GAAG,KAAK,IAAI,GAAG,YAAY,aAAa,OAAO,CAAC;AAAA,MAClE;AAAA;AAAA;AAAA;AAAA,MAKU,iBAAiB,KAAoC;AAC7D,YAAI;AACF,gBAAM,SAAS,IAAI,IAAI,GAAG;AAE1B,cAAI;AAEJ,kBAAQ,OAAO,UAAU;AAAA,YACvB,KAAK;AAAA,YACL,KAAK;AACH,qBAAO;AACP;AAAA,YACF,KAAK;AACH,qBAAO;AACP;AAAA,YACF,KAAK;AACH,qBAAO;AACP;AAAA,YACF;AACE,qBAAO;AAAA,UACX;AAEA,iBAAO;AAAA,YACL;AAAA,YACA,MAAM,OAAO,YAAY;AAAA,YACzB,MAAM,OAAO,OAAO,SAAS,OAAO,IAAI,IAAI;AAAA,YAC5C,UAAU,OAAO,SAAS,MAAM,CAAC;AAAA;AAAA,YACjC,UAAU,OAAO,YAAY;AAAA,YAC7B,UAAU,OAAO,YAAY;AAAA,YAC7B;AAAA,UACF;AAAA,QACF,QAAQ;AACN,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,IACF;AAAA;AAAA;;;ACpKA,IAUa;AAVb;AAAA;AAAA;AAKA;AAGA;AAEO,IAAM,iBAAN,cAA6B,gBAAgB;AAAA,MAClD,OAAO;AAAA;AAAA;AAAA;AAAA,MAKP,MAAM,OAAO,aAA+C;AAC1D,cAAM,WAAqB,CAAC;AAC5B,cAAM,WAAqB,CAAC;AAG5B,cAAM,EAAE,OAAO,WAAW,SAAS,YAAY,IAAI,MAAM,KAAK;AAAA,UAC5D;AAAA,UACA,CAAC,UAAU,gBAAgB;AAAA,QAC7B;AAEA,iBAAS,KAAK,GAAG,UAAU,IAAI,SAAO,qBAAqB,GAAG,EAAE,CAAC;AAGjE,cAAM,EAAE,UAAU,YAAY,IAAI,MAAM,KAAK,WAAW,aAAa;AAAA,UACnE;AAAA,UACA;AAAA,QACF,CAAC;AAED,YAAI,YAAY,SAAS,GAAG;AAC1B,mBAAS,KAAK,sBAAsB,YAAY,CAAC,EAAE,QAAQ,EAAE;AAAA,QAC/D;AAGA,cAAM,EAAE,UAAU,cAAc,IAAI,MAAM,KAAK,WAAW,aAAa;AAAA,UACrE;AAAA,QACF,CAAC;AAED,YAAI,cAAc,SAAS,GAAG;AAC5B,mBAAS,KAAK,+BAA+B,cAAc,CAAC,EAAE,QAAQ,EAAE;AAAA,QAC1E;AAGA,cAAM,iBAAiB,MAAM,KAAK;AAAA,UAChC;AAAA,UACA,CAAC,+BAA+B;AAAA,UAChC,CAAC,cAAc;AAAA,QACjB;AAEA,YAAI,eAAe,SAAS,GAAG;AAC7B,mBAAS,KAAK,+BAA+B;AAAA,QAC/C;AAGA,cAAM,aAAa,KAAK,oBAAoB;AAAA,UAC1C,UAAU,EAAE,OAAO,UAAU,QAAQ,OAAO,EAAE;AAAA;AAAA,UAC9C,UAAU,EAAE,OAAO,YAAY,SAAS,cAAc,QAAQ,OAAO,EAAE;AAAA,UACvE,UAAU;AAAA,QACZ,CAAC;AAGD,YAAI,UAAU,SAAS,KAAK,YAAY,WAAW,GAAG;AACpD,mBAAS,KAAK,4DAA4D;AAAA,QAC5E;AAEA,YAAI,YAAY,SAAS,KAAK,CAAC,UAAU,SAAS,gBAAgB,GAAG;AACnE,mBAAS,KAAK,oDAAoD;AAAA,QACpE;AAEA,eAAO;AAAA,UACL,OAAO,aAAa;AAAA,UACpB;AAAA,UACA;AAAA,UACA,UAAU,SAAS,SAAS,IAAI,WAAW;AAAA,QAC7C;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,MAAM,cAAc,aAAmD;AAErE,cAAM,EAAE,UAAU,YAAY,IAAI,MAAM,KAAK,WAAW,aAAa;AAAA,UACnE;AAAA,UACA;AAAA,QACF,CAAC;AAED,YAAI,YAAY,WAAW,GAAG;AAC5B,iBAAO;AAAA,QACT;AAEA,cAAM,aAAa,YAAY,CAAC;AAChC,cAAM,qBAAqB,MAAM,eAAe,qBAAqB,WAAW;AAGhF,cAAM,eAAe,MAAM,gBAAgB,WAAW,QAAQ;AAC9D,YAAI,CAAC,aAAa,SAAS;AACzB,iBAAO;AAAA,QACT;AAGA,YAAI;AACJ,cAAM,iBAAiB,aAAa,KAAK,MAAM,iCAAiC;AAChF,YAAI,gBAAgB;AAClB,gBAAM,kBAAkB,eAAe,CAAC;AACxC,gBAAM,gBAAgB,gBAAgB,MAAM,0BAA0B;AACtE,gBAAM,cAAc,gBAAgB,MAAM,wBAAwB;AAElE,4BAAkB;AAAA,YAChB,UAAU,gBAAgB,CAAC,KAAK;AAAA,YAChC,QAAQ,cAAc,CAAC;AAAA,UACzB;AAAA,QACF;AAEA,eAAO;AAAA,UACL,MAAM;AAAA,UACN,YAAY;AAAA,UACZ;AAAA,UACA;AAAA,UACA,cAAc,CAAC,UAAU,gBAAgB;AAAA,UACzC;AAAA,QACF;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKA,MAAM,kBAAkB,aAAqD;AAC3E,cAAM,SAAS,MAAM,KAAK,cAAc,WAAW;AACnD,YAAI,CAAC,QAAQ;AACX,iBAAO;AAAA,QACT;AAGA,cAAM,eAAe,MAAM,gBAAgB,OAAO,WAAW,QAAQ;AACrE,YAAI,CAAC,aAAa,SAAS;AACzB,iBAAO;AAAA,QACT;AAGA,cAAM,kBAAkB,aAAa,KAAK,MAAM,+BAA+B;AAC/E,YAAI,CAAC,iBAAiB;AACpB,iBAAO;AAAA,QACT;AAEA,cAAM,mBAAmB,gBAAgB,CAAC;AAG1C,cAAM,gBAAgB,iBAAiB,MAAM,0BAA0B;AACvE,cAAM,WAAW,gBAAgB,CAAC;AAGlC,cAAM,WAAW,iBAAiB,MAAM,4BAA4B,KACpD,iBAAiB,MAAM,qBAAqB;AAE5D,YAAI,CAAC,UAAU;AACb,iBAAO;AAAA,QACT;AAEA,YAAI;AACJ,YAAI,SAAS,CAAC,EAAE,SAAS,MAAM,GAAG;AAEhC,gBAAM,SAAS,SAAS,CAAC;AACzB,wBAAc,QAAQ,IAAI,MAAM,KAAK;AAErC,cAAI,CAAC,aAAa;AAEhB,mBAAO;AAAA,cACL,MAAM,KAAK,wBAAwB,QAAQ;AAAA,cAC3C,UAAU;AAAA,YACZ;AAAA,UACF;AAAA,QACF,OAAO;AAEL,wBAAc,SAAS,CAAC;AAAA,QAC1B;AAGA,cAAM,WAAW,KAAK,iBAAiB,WAAW;AAClD,YAAI,UAAU;AACZ,iBAAO;AAAA,QACT;AAGA,eAAO;AAAA,UACL,MAAM,KAAK,wBAAwB,QAAQ;AAAA,UAC3C,UAAU;AAAA,QACZ;AAAA,MACF;AAAA;AAAA;AAAA;AAAA,MAKQ,wBAAwB,UAA2C;AACzE,gBAAQ,UAAU;AAAA,UAChB,KAAK;AACH,mBAAO;AAAA,UACT,KAAK;AACH,mBAAO;AAAA,UACT,KAAK;AACH,mBAAO;AAAA,UACT;AACE,mBAAO;AAAA,QACX;AAAA,MACF;AAAA,IACF;AAAA;AAAA;;;AC1MA,OAAOC,WAAU;AACjB,OAAOC,SAAQ;AATf,IAWa;AAXb;AAAA;AAAA;AAKA;AAMO,IAAM,kBAAN,cAA8B,gBAAgB;AAAA,MACnD,OAAO;AAAA,MAEP,MAAM,OAAO,aAA+C;AAC1D,cAAM,WAAqB,CAAC;AAE5B,YAAI;AAEF,gBAAM,mBAAmB,MAAM,KAAK,2BAA2B,WAAW;AAC1E,mBAAS,KAAK,GAAG,iBAAiB,IAAI,OAAK,sBAAsB,EAAE,QAAQ,EAAE,CAAC;AAG7E,cAAI,OAAO,MAAM,KAAK,6BAA6B,aAAa,CAAC,eAAe,aAAa,CAAC;AAC9F,mBAAS,KAAK,GAAG,KAAK,MAAM,IAAI,SAAO,qBAAqB,GAAG,SAAS,CAAC;AAGzE,qBAAW,cAAc,kBAAkB;AACzC,kBAAM,YAAYD,MAAK,QAAQ,WAAW,QAAQ;AAClD,kBAAM,aAAa,MAAM,KAAK,6BAA6B,WAAW,CAAC,eAAe,aAAa,CAAC;AACpG,qBAAS,KAAK,GAAG,WAAW,MAAM,IAAI,SAAO,qBAAqB,GAAG,KAAK,WAAW,QAAQ,GAAG,CAAC;AAEjG,iBAAK,QAAQ,CAAC,GAAG,oBAAI,IAAI,CAAC,GAAG,KAAK,OAAO,GAAG,WAAW,KAAK,CAAC,CAAC;AAAA,UAChE;AAGA,gBAAM,iBAAiB;AAAA,YACrB;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,UACF;AAEA,gBAAM,EAAE,UAAU,YAAY,IAAI,MAAM,KAAK,WAAW,aAAa,cAAc;AACnF,mBAAS,KAAK,GAAG,YAAY,IAAI,OAAK,sBAAsB,EAAE,QAAQ,EAAE,CAAC;AAGzE,gBAAM,gBAAgB,CAAC,WAAW,cAAc,oBAAoB;AACpE,gBAAM,EAAE,UAAU,mBAAmB,IAAI,MAAM,KAAK,WAAW,aAAa,aAAa;AACzF,mBAAS,KAAK,GAAG,mBAAmB,IAAI,OAAK,8BAA8B,EAAE,QAAQ,EAAE,CAAC;AAGzF,gBAAM,kBAAkB;AAAA,YACtB,UAAU;AAAA,cACR,OAAO,KAAK,MAAM,SAAS,IAAI,IAAI;AAAA,cACnC,OAAO;AAAA,YACT;AAAA,YACA,UAAU;AAAA,cACR,QAAQ,iBAAiB,SAAS,IAAI,IAAI,MAAM,YAAY,SAAS,IAAI,IAAI,MAAM,mBAAmB,SAAS,IAAI,IAAI;AAAA,cACvH,OAAO;AAAA;AAAA,YACT;AAAA,YACA,UAAU;AAAA,UACZ;AAEA,gBAAM,aAAa,KAAK,oBAAoB,eAAe;AAE3D,iBAAO;AAAA,YACL,OAAO,aAAa;AAAA,YACpB,YAAY,KAAK,MAAM,aAAa,GAAG;AAAA,YACvC;AAAA,UACF;AAAA,QACF,SAAS,OAAO;AACd,iBAAO;AAAA,YACL,OAAO;AAAA,YACP,YAAY;AAAA,YACZ,UAAU,CAAC,4BAA4B,KAAK,EAAE;AAAA,UAChD;AAAA,QACF;AAAA,MACF;AAAA,MAEA,MAAM,cAAc,aAAoD;AACtE,YAAI;AAEF,gBAAM,mBAAmB,MAAM,KAAK,2BAA2B,WAAW;AAC1E,cAAI,iBAAiB,WAAW,GAAG;AACjC,mBAAO;AAAA,UACT;AAEA,gBAAM,aAAa,iBAAiB,CAAC;AACrC,gBAAM,gBAAgB,MAAMC,IAAG,SAAS,WAAW,UAAU,OAAO;AAGpE,gBAAM,SAAS,KAAK,mBAAmB,eAAe,SAAS,KAAK;AACpE,gBAAM,eAAe,CAAC,MAAM,UAAU,kBAAkB,QAAQ;AAChE,gBAAM,eAAe,aAAa,SAAS,MAAa,IAAI,SAAwC;AACpG,gBAAM,SAAS,KAAK,mBAAmB,eAAe,KAAK,KAAK;AAChE,gBAAM,uBAAuBD,MAAK,QAAQ,aAAa,MAAM;AAE7D,gBAAM,SAAwB;AAAA,YAC5B,MAAM;AAAA,YACN,YAAY;AAAA,cACV,UAAU,WAAW;AAAA,cACrB,UAAU,WAAW;AAAA,cACrB,QAAQ,MAAMC,IAAG,WAAW,WAAW,QAAQ;AAAA,YACjD;AAAA,YACA,QAAQ;AAAA,YACR,YAAY,KAAK,mBAAmB,eAAe,QAAQ,KAAK;AAAA,YAChE;AAAA,YACA,oBAAoB;AAAA,cAClB,UAAU;AAAA,cACV,UAAU;AAAA,cACV,QAAQ,MAAMA,IAAG,WAAW,oBAAoB;AAAA,YAClD;AAAA,YACA,cAAc,CAAC,eAAe,aAAa;AAAA,UAC7C;AAEA,iBAAO;AAAA,QACT,SAAS,OAAO;AACd,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,MAEA,MAAM,kBAAkB,aAAqD;AAC3E,YAAI;AAEF,gBAAM,WAAW,CAAC,QAAQ,cAAc,kBAAkB;AAC1D,gBAAM,EAAE,UAAU,cAAc,IAAI,MAAM,KAAK,WAAW,aAAa,QAAQ;AAE/E,qBAAW,WAAW,eAAe;AACnC,kBAAM,aAAa,MAAMA,IAAG,SAAS,QAAQ,UAAU,OAAO;AAC9D,kBAAM,QAAQ,KAAK,gBAAgB,YAAY,cAAc;AAC7D,gBAAI,OAAO;AACT,oBAAM,SAAS,KAAK,iBAAiB,KAAK;AAC1C,kBAAI,OAAQ,QAAO;AAAA,YACrB;AAAA,UACF;AAGA,gBAAM,gBAAgB,MAAM,KAAK,cAAc,WAAW;AAC1D,cAAI,CAAC,cAAe,QAAO;AAG3B,gBAAM,YAA+D;AAAA,YACnE,MAAM;AAAA,YACN,UAAU;AAAA,YACV,kBAAkB;AAAA,UACpB;AAEA,gBAAM,SAAS,UAAU,cAAc,MAAM,KAAK;AAElD,iBAAO;AAAA,YACL,MAAM;AAAA,YACN,MAAM;AAAA,YACN,MAAM,WAAW,eAAe,OAAO,WAAW,UAAU,OAAO;AAAA,YACnE,UAAU;AAAA,UACZ;AAAA,QACF,SAAS,OAAO;AACd,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,MAEQ,mBAAmB,SAAiB,KAAiC;AAE3E,cAAM,QAAQ,IAAI,OAAO,GAAG,GAAG,uBAAuB;AACtD,cAAM,QAAQ,QAAQ,MAAM,KAAK;AACjC,eAAO,QAAQ,CAAC;AAAA,MAClB;AAAA,MAEQ,gBAAgB,SAAiB,KAAiC;AACxE,cAAM,QAAQ,IAAI,OAAO,IAAI,GAAG,kBAAkB,GAAG;AACrD,cAAM,QAAQ,QAAQ,MAAM,KAAK;AACjC,eAAO,QAAQ,CAAC,GAAG,QAAQ,SAAS,EAAE,EAAE,KAAK;AAAA,MAC/C;AAAA,MAEA,MAAc,2BAA2B,aAA2E;AAClH,cAAM,iBAAiB;AACvB,cAAM,aAA0D,CAAC;AAEjE,cAAM,kBAAkB,OAAO,KAAa,cAAsB,OAAO;AACvE,cAAI;AACF,kBAAM,QAAQ,MAAMA,IAAG,QAAQ,KAAK,EAAE,eAAe,KAAK,CAAC;AAE3D,uBAAW,QAAQ,OAAO;AACxB,oBAAM,WAAWD,MAAK,KAAK,KAAK,KAAK,IAAI;AACzC,oBAAM,eAAeA,MAAK,KAAK,aAAa,KAAK,IAAI;AAGrD,kBAAI,KAAK,YAAY,KAAK,CAAC,CAAC,gBAAgB,QAAQ,SAAS,QAAQ,OAAO,EAAE,SAAS,KAAK,IAAI,GAAG;AACjG,sBAAM,gBAAgB,UAAU,YAAY;AAAA,cAC9C,WAAW,KAAK,OAAO,KAAK,eAAe,KAAK,KAAK,IAAI,GAAG;AAC1D,2BAAW,KAAK;AAAA,kBACd,UAAU;AAAA,kBACV,UAAU;AAAA,gBACZ,CAAC;AAAA,cACH;AAAA,YACF;AAAA,UACF,QAAQ;AAAA,UAER;AAAA,QACF;AAEA,cAAM,gBAAgB,WAAW;AACjC,eAAO;AAAA,MACT;AAAA,IACF;AAAA;AAAA;;;ACpMA,OAAOE,SAAQ;AATf,IAWa;AAXb;AAAA;AAAA;AAKA;AAMO,IAAM,kBAAN,cAA8B,gBAAgB;AAAA,MACnD,OAAO;AAAA,MAEP,MAAM,OAAO,aAA+C;AAC1D,cAAM,WAAqB,CAAC;AAE5B,YAAI;AAEF,gBAAM,cAAc;AAAA,YAClB;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,UACF;AAEA,gBAAM,EAAE,UAAU,iBAAiB,IAAI,MAAM,KAAK,WAAW,aAAa,WAAW;AACrF,mBAAS,KAAK,GAAG,iBAAiB,IAAI,OAAK,sBAAsB,EAAE,QAAQ,EAAE,CAAC;AAG9E,gBAAM,OAAO,MAAM,KAAK,6BAA6B,aAAa,CAAC,WAAW,iBAAiB,CAAC;AAChG,mBAAS,KAAK,GAAG,KAAK,MAAM,IAAI,SAAO,qBAAqB,GAAG,EAAE,CAAC;AAGlE,gBAAM,iBAAiB,MAAM,KAAK;AAAA,YAChC;AAAA,YACA,CAAC,sBAAsB,WAAW;AAAA,YAClC,CAAC,OAAO,YAAY,QAAQ;AAAA,UAC9B;AACA,cAAI,eAAe,SAAS,GAAG;AAC7B,qBAAS,KAAK,SAAS,eAAe,MAAM,eAAe;AAAA,UAC7D;AAGA,gBAAM,gBAAgB,CAAC,kBAAkB,cAAc,qBAAqB;AAC5E,gBAAM,EAAE,UAAU,mBAAmB,IAAI,MAAM,KAAK,WAAW,aAAa,aAAa;AACzF,mBAAS,KAAK,GAAG,mBAAmB,IAAI,OAAK,8BAA8B,EAAE,QAAQ,EAAE,CAAC;AAGxF,gBAAM,oBAAoB,MAAM,KAAK;AAAA,YACnC;AAAA,YACA,CAAC,iBAAiB;AAAA,YAClB,CAAC,kBAAkB,cAAc,qBAAqB;AAAA,UACxD;AACA,cAAI,kBAAkB,SAAS,GAAG;AAChC,qBAAS,KAAK,SAAS,kBAAkB,MAAM,kBAAkB;AAAA,UACnE;AAGA,gBAAM,aAAa,KAAK,oBAAoB;AAAA,YAC1C,UAAU;AAAA,cACR,OAAO,KAAK,MAAM,SAAS,IAAI,IAAI;AAAA,cACnC,OAAO;AAAA,YACT;AAAA,YACA,UAAU;AAAA,cACR,OAAO,iBAAiB,UAAU,eAAe,SAAS,IAAI,IAAI,KAAK,mBAAmB,UAAU,kBAAkB,SAAS,IAAI,IAAI;AAAA,cACvI,OAAO;AAAA,YACT;AAAA,YACA,UAAU;AAAA,UACZ,CAAC;AAED,iBAAO;AAAA,YACL,OAAO,aAAa;AAAA,YACpB,YAAY,KAAK,MAAM,aAAa,GAAG;AAAA,YACvC;AAAA,UACF;AAAA,QACF,SAAS,OAAO;AACd,iBAAO;AAAA,YACL,OAAO;AAAA,YACP,YAAY;AAAA,YACZ,UAAU,CAAC,4BAA4B,KAAK,EAAE;AAAA,UAChD;AAAA,QACF;AAAA,MACF;AAAA,MAEA,MAAM,cAAc,aAAoD;AACtE,YAAI;AAEF,gBAAM,cAAc;AAAA,YAClB;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,YACA;AAAA,UACF;AAEA,gBAAM,EAAE,UAAU,iBAAiB,IAAI,MAAM,KAAK,WAAW,aAAa,WAAW;AACrF,cAAI,iBAAiB,WAAW,GAAG;AACjC,mBAAO;AAAA,UACT;AAEA,gBAAM,aAAa,iBAAiB,CAAC;AACrC,cAAI,WAAqB,CAAC;AAC1B,cAAI,aAAuB,CAAC;AAE5B,cAAI,WAAW,SAAS,SAAS,OAAO,GAAG;AAEzC,kBAAM,gBAAgB,MAAMA,IAAG,SAAS,WAAW,UAAU,OAAO;AACpE,kBAAM,aAAa,KAAK,MAAM,aAAa;AAC3C,uBAAW,MAAM,QAAQ,WAAW,QAAQ,IAAI,WAAW,WAAW,CAAC,yBAAyB;AAChG,yBAAa,MAAM,QAAQ,WAAW,UAAU,IAAI,WAAW,aAAa,CAAC,0BAA0B;AAAA,UACzG,OAAO;AAEL,kBAAM,gBAAgB,MAAMA,IAAG,SAAS,WAAW,UAAU,OAAO;AACpE,uBAAW,KAAK,kBAAkB,eAAe,UAAU,KAAK,CAAC,yBAAyB;AAC1F,yBAAa,KAAK,kBAAkB,eAAe,YAAY,KAAK,CAAC,0BAA0B;AAAA,UACjG;AAEA,gBAAM,SAAwB;AAAA,YAC5B,MAAM;AAAA,YACN;AAAA,YACA;AAAA,YACA;AAAA,YACA,oBAAoB;AAAA;AAAA,YACpB,cAAc,CAAC,SAAS;AAAA,YACxB,KAAK;AAAA,cACH,eAAe;AAAA,cACf,aAAa;AAAA,YACf;AAAA,UACF;AAEA,iBAAO;AAAA,QACT,SAAS,OAAO;AACd,kBAAQ,KAAK,qCAAqC,KAAK,EAAE;AACzD,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,MAEA,MAAM,kBAAkB,aAAqD;AAC3E,YAAI;AAEF,gBAAM,WAAW,CAAC,QAAQ,cAAc,kBAAkB;AAC1D,gBAAM,EAAE,UAAU,cAAc,IAAI,MAAM,KAAK,WAAW,aAAa,QAAQ;AAE/E,qBAAW,WAAW,eAAe;AACnC,kBAAM,aAAa,MAAMA,IAAG,SAAS,QAAQ,UAAU,OAAO;AAC9D,kBAAM,QAAQ,KAAK,gBAAgB,YAAY,cAAc,KAC/C,KAAK,gBAAgB,YAAY,QAAQ,KACzC,KAAK,gBAAgB,YAAY,aAAa;AAC5D,gBAAI,OAAO;AACT,oBAAM,SAAS,KAAK,iBAAiB,KAAK;AAC1C,kBAAI,OAAQ,QAAO;AAAA,YACrB;AAAA,UACF;AAGA,gBAAM,gBAAgB,MAAM,KAAK,cAAc,WAAW;AAC1D,cAAI,eAAe,YAAY;AAC7B,kBAAM,gBAAgB,MAAMA,IAAG,SAAS,cAAc,WAAW,UAAU,OAAO;AAGlF,kBAAM,OAAO,KAAK,mBAAmB,eAAe,MAAM;AAC1D,kBAAM,OAAO,KAAK,mBAAmB,eAAe,MAAM;AAC1D,kBAAM,OAAO,KAAK,mBAAmB,eAAe,MAAM;AAC1D,kBAAM,WAAW,KAAK,mBAAmB,eAAe,UAAU;AAClE,kBAAM,WAAW,KAAK,mBAAmB,eAAe,UAAU;AAClE,kBAAM,WAAW,KAAK,mBAAmB,eAAe,UAAU;AAElE,gBAAI,QAAQ,UAAU;AACpB,oBAAM,YAA+D;AAAA,gBACnE,YAAY;AAAA,gBACZ,cAAc;AAAA,gBACd,SAAS;AAAA,gBACT,WAAW;AAAA,gBACX,UAAU;AAAA,cACZ;AAEA,oBAAM,aAAa,UAAU,IAAI,KAAK;AAEtC,qBAAO;AAAA,gBACL,MAAM;AAAA,gBACN,MAAM,QAAQ;AAAA,gBACd,MAAM,OAAO,SAAS,IAAI,IAAK,eAAe,eAAe,OAAO,eAAe,UAAU,OAAO;AAAA,gBACpG;AAAA,gBACA;AAAA,gBACA;AAAA,cACF;AAAA,YACF;AAAA,UACF;AAGA,iBAAO;AAAA,YACL,MAAM;AAAA,YACN,MAAM;AAAA,YACN,MAAM;AAAA,YACN,UAAU;AAAA,UACZ;AAAA,QACF,SAAS,OAAO;AACd,kBAAQ,KAAK,sCAAsC,KAAK,EAAE;AAC1D,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,MAEQ,mBAAmB,SAAiB,KAAiC;AAE3E,cAAM,QAAQ,IAAI,OAAO,GAAG,GAAG,uBAAuB;AACtD,cAAM,QAAQ,QAAQ,MAAM,KAAK;AACjC,eAAO,QAAQ,CAAC;AAAA,MAClB;AAAA,MAEQ,kBAAkB,SAAiB,KAAmC;AAE5E,cAAM,QAAQ,IAAI,OAAO,GAAG,GAAG,sBAAsB;AACrD,cAAM,QAAQ,QAAQ,MAAM,KAAK;AACjC,YAAI,CAAC,MAAO,QAAO;AAEnB,eAAO,MAAM,CAAC,EACX,MAAM,GAAG,EACT,IAAI,UAAQ,KAAK,KAAK,EAAE,QAAQ,SAAS,EAAE,CAAC,EAC5C,OAAO,UAAQ,KAAK,SAAS,CAAC;AAAA,MACnC;AAAA,MAEQ,gBAAgB,SAAiB,KAAiC;AACxE,cAAM,QAAQ,IAAI,OAAO,IAAI,GAAG,kBAAkB,GAAG;AACrD,cAAM,QAAQ,QAAQ,MAAM,KAAK;AACjC,eAAO,QAAQ,CAAC,GAAG,QAAQ,SAAS,EAAE,EAAE,KAAK;AAAA,MAC/C;AAAA,IACF;AAAA;AAAA;;;ACxOA;AAAA;AAAA;AACA;AACA;AACA;AACA;AAAA;AAAA;;;ACJA;AAAA;AAAA;AAAA;AAAA;;;ACAA;AAAA;AAAA;AAAA;AAAA;;;ACAA;AAAA;AAAA;AAAA;AAAA;;;ACAA,IAAAC,iBAAA;AAAA;AAAA;AACA;AACA;AACA;AAAA;AAAA;;;ACHA;AAAA;AAAA;AACA;AACA,IAAAC;AAAA;AAAA;;;ACFA;AAAA;AAAA;AAAA;AAMA,OAAOC,cAAa;AACpB,SAAS,WAAAC,gBAAe;AACxB,OAAO,YAAY;AAcnB,eAAe,gBAAgB,SAAiB,aAAsC;AACpF,QAAM,iBAA2B,CAAC;AAElC,iBAAe,KAAKA,SAAQ,aAAa,MAAM,CAAC;AAEhD,QAAM,QAAQ,YAAY,MAAM,GAAG;AACnC,WAAS,IAAI,MAAM,SAAS,GAAG,IAAI,GAAG,KAAK;AACzC,mBAAe,KAAK,MAAM,MAAM,GAAG,IAAI,CAAC,EAAE,KAAK,GAAG,IAAI,OAAO;AAAA,EAC/D;AAEA,QAAM,UAAUA,SAAQ,aAAa,MAAM;AAC3C,QAAM,UAAUA,SAAQ,aAAa,UAAU;AAC/C,MAAI,MAAMD,SAAQ,WAAW,OAAO,GAAG;AACrC,UAAM,MAAM,MAAMA,SAAQ,QAAQ,OAAO;AACzC,QAAI,QAAQ,CAAC,MAAM,eAAe,KAAKC,SAAQ,SAAS,GAAG,MAAM,CAAC,CAAC;AAAA,EACrE;AACA,MAAI,MAAMD,SAAQ,WAAW,OAAO,GAAG;AACrC,UAAM,MAAM,MAAMA,SAAQ,QAAQ,OAAO;AACzC,QAAI,QAAQ,CAAC,MAAM,eAAe,KAAKC,SAAQ,SAAS,GAAG,MAAM,CAAC,CAAC;AAAA,EACrE;AAEA,aAAW,QAAQ,gBAAgB;AACjC,QAAI,MAAMD,SAAQ,WAAW,IAAI,GAAG;AAClC,UAAI;AACF,cAAM,UAAU,OAAO,MAAM,MAAMA,SAAQ,SAAS,IAAI,CAAC;AACzD,cAAM,IACJ,QAAQ,gBAAgB,QAAQ,gBAAgB,QAAQ,YAAY,CAAC,EAAE;AACzE,YAAI,EAAG,QAAO;AAAA,MAChB,QAAQ;AAAA,MAAC;AAAA,IACX;AAAA,EACF;AACA,SAAO;AACT;AAEA,eAAe,oBAAoB,aAA6C;AAC9E,QAAM,aAAa;AAAA,IACjB;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF;AAEA,QAAM,qBAAqB,CAAC,qBAAqB,qBAAqB,sBAAsB,oBAAoB;AAChH,aAAW,KAAK,oBAAoB;AAClC,QAAI,MAAMA,SAAQ,WAAWC,SAAQ,aAAa,CAAC,CAAC,GAAG;AACrD,YAAM,UAAU,MAAMD,SAAQ,SAASC,SAAQ,aAAa,CAAC,GAAG,MAAM;AACtE,YAAM,QAAQ,QAAQ,MAAM,2BAA2B;AACvD,UAAI,OAAO;AACT,mBAAW,QAAQ,MAAM,CAAC,CAAC;AAAA,MAC7B;AAAA,IACF;AAAA,EACF;AACA,aAAW,OAAO,YAAY;AAC5B,QAAI,MAAMD,SAAQ,WAAWC,SAAQ,aAAa,GAAG,CAAC,EAAG,QAAO;AAAA,EAClE;AACA,SAAO;AACT;AAEA,eAAsB,YAAY,SAAsB,eAA6C;AACnG,QAAM,cAAcA,SAAQ,QAAQ,WAAW,QAAQ,IAAI,CAAC;AAC5D,QAAMC,WAAU,kBAAkB,EAAE,MAAM,gCAAgC;AAE1E,MAAI,SAAiB,aAAqB;AAE1C,MAAI,QAAQ,KAAK;AAEf,cAAU,QAAQ,WAAW;AAC7B,UAAM,aAAa,MAAM,gBAAgB,SAAS,WAAW;AAC7D,kBAAc,QAAQ,SAAS;AAE/B,QAAI,CAAC,aAAa;AAChB,MAAAA,SAAQ,KAAK,0EAA0E;AACvF,YAAM,IAAI,MAAM,iCAAiC;AAAA,IACnD;AAEA,UAAM,eAAe,MAAM,oBAAoB,WAAW;AAC1D,qBAAiB,QAAQ,kBAAkB,gBAAgB;AAAA,EAE7D,OAAO;AAEL,UAAM,eAAe,MAAM,UAAU,oBAAoB;AAAA,MACvD,aAAa;AAAA,MACb,cAAc;AAAA,IAChB,CAAC;AACD,cAAU,cAAc,KAAK,KAAK;AAElC,UAAM,YAAY,MAAM,gBAAgB,SAAS,WAAW;AAC5D,UAAM,WAAW;AACjB,UAAM,UAAU,MAAM,UAAU,UAAU;AAAA,MACxC,aAAa,aAAa;AAAA,MAC1B,cAAc;AAAA,IAChB,CAAC;AACD,mBAAe,SAAS,KAAK,KAAK,WAAW,KAAK;AAElD,QAAI,CAAC,aAAa;AAChB,MAAAA,SAAQ,KAAK,wCAAwC;AACrD,YAAM,IAAI,MAAM,iBAAiB;AAAA,IACnC;AAEA,UAAM,eAAgB,MAAM,oBAAoB,WAAW,KAAM;AACjE,UAAM,WAAW,MAAM,UAAU,6BAA6B;AAAA,MAC5D,aAAa;AAAA,MACb,cAAc;AAAA,IAChB,CAAC;AACD,qBAAiB,UAAU,KAAK,KAAK;AAErC,UAAM,UAAU,MAAM,cAAc,2CAA2C;AAC/E,QAAI,CAAC,SAAS;AACZ,MAAAA,SAAQ,KAAK,gBAAgB;AAC7B;AAAA,IACF;AAAA,EACF;AAEA,EAAAA,SAAQ,OAAO,wBAAwB;AAGvC,QAAM,YAAY;AAAA,IAChB,EAAE,MAAM,UAAU,UAAU,IAAI,eAAe,EAAE;AAAA,IACjD,EAAE,MAAM,WAAW,UAAU,IAAI,gBAAgB,EAAE;AAAA,IACnD,EAAE,MAAM,WAAW,UAAU,IAAI,gBAAgB,EAAE;AAAA,EACrD;AACA,MAAI,cAA6B;AACjC,aAAW,EAAE,MAAM,SAAS,KAAK,WAAW;AAC1C,UAAM,SAAS,MAAM,SAAS,OAAO,WAAW;AAChD,QAAI,OAAO,OAAO;AAChB,oBAAc;AACd;AAAA,IACF;AAAA,EACF;AAGA,QAAM,SAAc;AAAA,IAClB,SAAS;AAAA,IACT,oBAAoB;AAAA,IACpB,GAAI,eAAe,EAAE,KAAK,YAAY;AAAA,IACtC,cAAc;AAAA,MACZ,CAAC,OAAO,GAAG;AAAA,QACT,sBAAsB;AAAA,QACtB;AAAA,MACF;AAAA,IACF;AAAA,IACA,QAAQ;AAAA,MACN,gBAAgB;AAAA,MAChB,eAAe;AAAA,IACjB;AAAA,EACF;AAEA,QAAM,aAAaD,SAAQ,aAAa,cAAc,UAAU,kBAAkB;AAElF,MAAI,MAAMD,SAAQ,WAAW,UAAU,KAAK,CAAC,QAAQ,OAAO,CAAE,MAAM,cAAc,sBAAsB,UAAU,GAAG,GAAI;AACvH,IAAAE,SAAQ,KAAK,mCAA8B;AAC3C;AAAA,EACF;AAEA,MAAI,CAAC,cAAc,QAAQ;AACzB,UAAMF,SAAQ,UAAU,YAAY,KAAK,UAAU,QAAQ,MAAM,CAAC,CAAC;AACnE,IAAAE,SAAQ,QAAQ,4BAA4B,UAAU,EAAE;AAAA,EAC1D,OAAO;AACL,IAAAA,SAAQ,QAAQ,iDAA4C;AAC5D,YAAQ,IAAI,KAAK,UAAU,QAAQ,MAAM,CAAC,CAAC;AAAA,EAC7C;AAGA,MAAI;AACF,UAAM,UAAUD,SAAQ,aAAa,cAAc;AACnD,QAAI,MAAMD,SAAQ,WAAW,OAAO,GAAG;AAErC,YAAM,QAAa,MAAM,OAAO,UAAU;AAC1C,YAAM,QAAS,MAAM,WAAW;AAChC,YAAMG,OAAM,MAAM,MAAM,SAAS,OAAO;AACxC,MAAAA,KAAI,UAAUA,KAAI,WAAW,CAAC;AAC9B,UAAI,CAACA,KAAI,QAAQ,MAAM;AACrB,QAAAA,KAAI,QAAQ,OAAO;AACnB,cAAM,MAAM,UAAU,SAASA,MAAK,EAAE,QAAQ,EAAE,CAAC;AACjD,QAAAD,SAAQ,OAAO,qCAAqC;AAAA,MACtD;AAAA,IACF;AAAA,EACF,SAAS,KAAK;AAEZ,YAAQ,KAAK,gDAAsC,eAAe,QAAQ,IAAI,UAAU,GAAG;AAAA,EAC7F;AACF;AA5MA;AAAA;AAAA;AAIA;AAKA;AAAA;AAAA;;;ACTA;AAAA;AAAA;AAAA;AAIA,SAAS,SAAAE,QAAO,SAAAC,cAAa;AAE7B,OAAOC,SAAQ;AAMf,eAAsB,cAAc,SAAwB,eAA6C;AACvG,EAAAF,OAAM,iCAAuB;AAE7B,QAAM,cAAc,QAAQ,UAAU,UAAQ,MAAM,EAAE,QAAQ,QAAQ,OAAO,IAAI,QAAQ,IAAI;AAC7F,QAAM,MAAM,MAAM,cAAc,eAAe,WAAW;AAE1D,UAAQ,IAAIE,IAAG,KAAK,wBAAwB,CAAC;AAC7C,UAAQ,IAAI,KAAK,UAAU,KAAK,MAAM,CAAC,CAAC;AAExC,EAAAD,OAAM,4CAAkC;AAC1C;AAtBA,IAAAE,eAAA;AAAA;AAAA;AAKA;AAAA;AAAA;;;ACLA;AAAA;AAAA;AAAA;AAIA,SAAS,SAAAC,QAAO,SAAAC,cAAa;AAE7B,OAAOC,UAAQ;AACf,OAAOC,WAAU;AACjB,OAAOC,SAAQ;AAMf,eAAsB,cAAc,SAAwB,eAA6C;AACvG,QAAM,cAAc,QAAQ,UAAUD,MAAK,QAAQ,QAAQ,OAAO,IAAI,QAAQ,IAAI;AAClF,QAAM,MAAM,MAAM,cAAc,eAAe,WAAW;AAC1D,QAAM,SAAS,IAAI,aAAa,IAAI,kBAAkB;AACtD,QAAM,gBAAgB,OAAO,kBAAkB;AAC/C,QAAM,wBAAwBA,MAAK,QAAQ,aAAa,aAAa;AAErE,EAAAH,OAAM,4BAAqB;AAE3B,MAAI,CAAC,MAAME,KAAG,WAAW,qBAAqB,GAAG;AAC/C,YAAQ,IAAIE,IAAG,OAAO,iCAAiC,CAAC;AACxD;AAAA,EACF;AAEA,QAAM,QAAQ,MAAMF,KAAG,QAAQ,qBAAqB;AACpD,QAAM,iBAAiB,MAAM,OAAO,UAAQ,KAAK,SAAS,MAAM,CAAC,EAAE,KAAK;AAExE,MAAI,eAAe,WAAW,GAAG;AAC/B,YAAQ,IAAIE,IAAG,OAAO,2BAA2B,CAAC;AAAA,EACpD,OAAO;AACL,YAAQ,IAAIA,IAAG,KAAK,mBAAmB,CAAC;AACxC,mBAAe,QAAQ,UAAQ;AAC7B,cAAQ,IAAI,OAAOA,IAAG,KAAK,IAAI,CAAC,EAAE;AAAA,IACpC,CAAC;AAAA,EACH;AAEA,EAAAH,OAAM,kCAA2B;AACnC;AAzCA;AAAA;AAAA;AAKA;AAAA;AAAA;;;ACAA,SAAS,eAAe;AACxB,SAAS,SAAAI,QAAO,SAAAC,cAAkB;AAClC,OAAOC,SAAQ;AACf,OAAO,cAAc;AACrB,OAAO,WAAW;AAGlB,IAAM,aAAa,CAAC,aAAiC;AACnD,MAAI,eAAoB;AACxB,SAAO,YAAY;AACjB,QAAI,CAAC,cAAc;AACjB,qBAAe,MAAM,SAAS;AAAA,IAChC;AACA,WAAO;AAAA,EACT;AACF;AAEA,IAAM,oBAAoB,WAAW,MAAM,+DAA+B;AAC1E,IAAM,qBAAqB,WAAW,MAAM,iEAAgC;AAC5E,IAAM,iBAAiB,WAAW,MAAM,yDAA4B;AACpE,IAAM,qBAAqB,WAAW,MAAM,iEAAgC;AAC5E,IAAM,iBAAiB,WAAW,MAAM,yDAA4B;AACpE,IAAM,mBAAmB,WAAW,MAAM,8DAA8B;AACxE,IAAM,mBAAmB,WAAW,MAAM,6DAA8B;AAUxE,IAAI,eAA8B;AAElC,SAAS,YAAoB;AAC3B,MAAI,aAAc,QAAO;AAEzB,QAAM,YAAY,SAAS,WAAW,WAAW,SAAS,EAAE,MAAM;AAClE,QAAM,WAAWA,IAAG,IAAI,qCAAqC;AAE7D,iBAAe;AAAA,IACb,GAAG,SAAS;AAAA,EAAK,QAAQ;AAAA,IACzB;AAAA,MACE,SAAS,EAAE,KAAK,GAAG,QAAQ,GAAG,MAAM,GAAG,OAAO,EAAE;AAAA,MAChD,QAAQ,EAAE,KAAK,GAAG,QAAQ,EAAE;AAAA,MAC5B,aAAa;AAAA,MACb,aAAa;AAAA,MACb,iBAAiB;AAAA,MACjB,OAAO;AAAA,IACT;AAAA,EACF;AAEA,SAAO;AACT;AAEA,SAAS,aAAmB;AAC1B,UAAQ,IAAI,UAAU,CAAC;AACzB;AAGA,SAAS,YAAY,OAAkB;AACrC,UAAQ,MAAMA,IAAG,IAAI,iBAAY,GAAG,MAAM,WAAW,KAAK;AAC1D,MAAI,QAAQ,KAAK,EAAE,WAAW,MAAM,OAAO;AACzC,YAAQ,MAAMA,IAAG,IAAI,gBAAgB,CAAC;AACtC,YAAQ,MAAMA,IAAG,IAAI,MAAM,KAAK,CAAC;AAAA,EACnC;AACA,UAAQ,KAAK,CAAC;AAChB;AAGA,QAAQ,GAAG,qBAAqB,WAAW;AAC3C,QAAQ,GAAG,sBAAsB,WAAW;AAG5C,QACG,KAAK,MAAM,EACX,YAAY,sDAA+C,EAC3D,QAAQ,OAAO,EACf,OAAO,iBAAiB,qCAAqC,EAC7D,OAAO,uBAAuB,4BAA4B,EAC1D,OAAO,SAAS,wDAAwD,EACxE,KAAK,aAAa,MAAM;AAEvB,QAAM,UAAU,QAAQ,KAAK,CAAC;AAC9B,MAAI,WAAW,CAAC,CAAC,UAAU,MAAM,aAAa,IAAI,EAAE,SAAS,OAAO,GAAG;AACrE,eAAW;AAAA,EACb;AACF,CAAC;AAGH,QACG,QAAQ,SAAS,EACjB,YAAY,2FAAoF,EAChG,SAAS,UAAU,kEAAkE,EACrF,OAAO,wBAAwB,2BAA2B,EAC1D,OAAO,OAAO,MAA0B,YAAiB;AACxD,MAAI;AACF,IAAAF,OAAME,IAAG,KAAK,mCAAmC,CAAC;AAClD,UAAM,EAAE,gBAAAC,gBAAe,IAAI,MAAM,kBAAkB;AACnD,UAAMA,gBAAe,EAAE,MAAM,SAAS,QAAQ,QAAQ,GAAG,QAAQ,KAAK,CAAC;AACvE,IAAAF,OAAMC,IAAG,MAAM,kCAA2B,CAAC;AAAA,EAC7C,SAAS,OAAO;AACd,gBAAY,KAAK;AAAA,EACnB;AACF,CAAC;AAEH,QACG,QAAQ,UAAU,EAClB,YAAY,0DAAmD,EAC/D,SAAS,UAAU,mEAAmE,EACtF,OAAO,wBAAwB,2BAA2B,EAC1D,OAAO,OAAO,MAA0B,YAAiB;AACxD,MAAI;AACF,IAAAF,OAAME,IAAG,KAAK,+BAA+B,CAAC;AAC9C,UAAM,EAAE,iBAAAE,iBAAgB,IAAI,MAAM,mBAAmB;AACrD,UAAMA,iBAAgB,EAAE,MAAM,SAAS,QAAQ,QAAQ,GAAG,QAAQ,KAAK,CAAC;AACxE,IAAAH,OAAMC,IAAG,MAAM,8BAAyB,CAAC;AAAA,EAC3C,SAAS,OAAO;AACd,gBAAY,KAAK;AAAA,EACnB;AACF,CAAC;AAEH,QACG,QAAQ,MAAM,EACd,YAAY,yDAAkD,EAC9D,SAAS,UAAU,+DAA+D,EAClF,OAAO,wBAAwB,2BAA2B,EAC1D,OAAO,OAAO,MAA0B,YAAiB;AACxD,MAAI;AACF,IAAAF,OAAME,IAAG,KAAK,2BAA2B,CAAC;AAC1C,UAAM,EAAE,aAAAG,aAAY,IAAI,MAAM,eAAe;AAC7C,UAAMA,aAAY,EAAE,MAAM,SAAS,QAAQ,QAAQ,GAAG,QAAQ,KAAK,CAAC;AACpE,IAAAJ,OAAMC,IAAG,MAAM,yBAAkB,CAAC;AAAA,EACpC,SAAS,OAAO;AACd,gBAAY,KAAK;AAAA,EACnB;AACF,CAAC;AAEH,QACG,QAAQ,UAAU,EAClB,YAAY,oDAA0C,EACtD,SAAS,UAAU,mEAAmE,EACtF,OAAO,wBAAwB,2BAA2B,EAC1D,OAAO,OAAO,MAA0B,YAAiB;AACxD,MAAI;AACF,IAAAF,OAAME,IAAG,KAAK,2BAA2B,CAAC;AAC1C,UAAM,EAAE,iBAAAI,iBAAgB,IAAI,MAAM,mBAAmB;AACrD,UAAMA,iBAAgB,EAAE,MAAM,SAAS,QAAQ,QAAQ,GAAG,QAAQ,KAAK,CAAC;AACxE,IAAAL,OAAMC,IAAG,MAAM,kCAAwB,CAAC;AAAA,EAC1C,SAAS,OAAO;AACd,gBAAY,KAAK;AAAA,EACnB;AACF,CAAC;AAGH,QACG,QAAQ,MAAM,EACd,YAAY,2CAAoC,EAChD,OAAO,wBAAwB,2BAA2B,EAC1D,OAAO,OAAO,YAAiB;AAC9B,MAAI;AACF,IAAAF,OAAME,IAAG,KAAK,mBAAmB,CAAC;AAClC,UAAM,EAAE,aAAAK,aAAY,IAAI,MAAM,eAAe;AAC7C,UAAMA,aAAY,EAAE,SAAS,QAAQ,QAAQ,GAAG,QAAQ,KAAK,CAAC;AAC9D,IAAAN,OAAMC,IAAG,MAAM,0CAAmC,CAAC;AAAA,EACrD,SAAS,OAAO;AACd,gBAAY,KAAK;AAAA,EACnB;AACF,CAAC;AAEH,QACG,QAAQ,QAAQ,EAChB,YAAY,uCAA6B,EACzC,OAAO,wBAAwB,2BAA2B,EAC1D,OAAO,cAAc,4BAA4B,EACjD,OAAO,cAAc,kCAAkC,EACvD,OAAO,OAAO,YAAiB;AAC9B,MAAI;AACF,IAAAF,OAAME,IAAG,KAAK,6BAA6B,CAAC;AAC5C,UAAM,EAAE,eAAAM,eAAc,IAAI,MAAM,iBAAiB;AACjD,UAAMA,eAAc,SAAS,QAAQ,KAAK,CAAC;AAC3C,IAAAP,OAAMC,IAAG,MAAM,qCAA2B,CAAC;AAAA,EAC7C,SAAS,OAAO;AACd,gBAAY,KAAK;AAAA,EACnB;AACF,CAAC;AAEH,QACG,QAAQ,QAAQ,EAChB,YAAY,2CAAoC,EAChD,OAAO,wBAAwB,2BAA2B,EAC1D,OAAO,OAAO,YAAiB;AAC9B,MAAI;AACF,IAAAF,OAAME,IAAG,KAAK,qBAAqB,CAAC;AACpC,UAAM,EAAE,eAAAO,eAAc,IAAI,MAAM,iBAAiB;AACjD,UAAMA,eAAc,EAAE,SAAS,QAAQ,QAAQ,GAAG,QAAQ,KAAK,CAAC;AAChE,IAAAR,OAAMC,IAAG,MAAM,6BAAsB,CAAC;AAAA,EACxC,SAAS,OAAO;AACd,gBAAY,KAAK;AAAA,EACnB;AACF,CAAC;AAGH,IAAI,QAAQ,KAAK,WAAW,GAAG;AAC7B,aAAW;AACX,UAAQ,IAAIA,IAAG,IAAI,sBAAe,GAAGA,IAAG,KAAK,aAAa,GAAGA,IAAG,IAAI,2BAA2B,CAAC;AAChG,UAAQ,IAAIA,IAAG,IAAI,gBAAgB,GAAGA,IAAG,KAAK,WAAW,GAAGA,IAAG,IAAI,oCAAoC,CAAC;AACxG,UAAQ,IAAIA,IAAG,IAAI,cAAc,GAAGA,IAAG,KAAK,cAAc,GAAGA,IAAG,IAAI,kCAAkC,CAAC;AACvG,UAAQ,IAAI,EAAE;AAChB;AAGA,QAAQ,MAAM;","names":["msg","enhancement","enhancement","enhancement","enhancement","enhancement","enhancement","enhancement","enhancement","enhancement","enhancement","enhancement","StubDetector","StubApplicator","enhancement","confirm","log","fs","path","spinner","resolve","enhancement","fs","path","pc","intro","outro","fs","path","pc","intro","outro","fs","path","pc","init_config","init_config","fs","resolve","path","fs","path","init_config","init_config","join","path","fs","fs","init_database","init_database","fsExtra","resolve","spinner","pkg","intro","outro","pc","init_config","intro","outro","fs","path","pc","intro","outro","pc","enhanceCommand","validateCommand","planCommand","rollbackCommand","initCommand","configCommand","statusCommand"]}